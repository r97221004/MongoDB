{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4fa326c",
   "metadata": {},
   "source": [
    "# Building Indexes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b578749",
   "metadata": {},
   "source": [
    "Hi there.\n",
    "\n",
    "In this section, we're going to talk about the new hybrid index build feature in MongoDB 4.2 on how this feature removes database locks.\n",
    "\n",
    "In our quest to continually improve MongoDB, we've redesigned index builds to remove the trade-offs and limitations of the previous index build types.\n",
    "\n",
    "First let's have a look at why we've made these changes.\n",
    "\n",
    "In previous versions of MongoDB, we had two different methods of building indexes.\n",
    "\n",
    "The first was a foreground index build, which was the most performant but had the unfortunate side effect of locking the entire database for the duration of the index build.\n",
    "\n",
    "This meant that you could neither read from or write to the database for the duration of the index build.\n",
    "\n",
    "Let's try this in the mongo shell in 4.0 to see how this locking can affect operations on a database during an index build.\n",
    "\n",
    "As you can see, we cannot find or insert any documents while the index build is in flight.\n",
    "\n",
    "You can see how this could be problematic if triggered on a production database in error.\n",
    "\n",
    "Let's try this in MongoDB 4.2.\n",
    "\n",
    "First we're going to create an index.\n",
    "\n",
    "And while the index build is in flight, we're going to open a new shell and try and insert some documents.\n",
    "\n",
    "As you can see, there's no locking.\n",
    "\n",
    "Great.\n",
    "\n",
    "So in previous releases, we also had background index builds, which don't hold a lock on a database but aren't as performant as a foreground index build.\n",
    "\n",
    "The background index build uses an incremental approach that is slower than the foreground index build.\n",
    "\n",
    "That is to say that the background index build will periodically lock the database but will yield to incoming read and write operations, releasing resources to attend to incoming requests.\n",
    "\n",
    "If the index is larger than the available RAM, the incremental approach can take much longer than a foreground index build.\n",
    "\n",
    "The other downside of background indexes is that the index structure resulting from this type of index build is less efficient than foreground indexes, resulting in less optimal index traversal operations.\n",
    "\n",
    "In this latest release, we have addressed these trade-offs with our new hybrid index build feature.\n",
    "\n",
    "From 4.2 onwards, there will be no need for a background or a foreground index build-- only one hybrid mechanism that takes the best of both worlds.\n",
    "\n",
    "The new hybrid index build has both the performance of a foreground index build and the nonlocking properties of a background index build, meaning that all database operations can proceed uninhibited for the duration of the build.\n",
    "\n",
    "This is now the only way to build an index on MongoDB.\n",
    "\n",
    "It's the only option available.\n",
    "\n",
    "It's important to note that the index structure remains unchanged.\n",
    "\n",
    "However, the method we use to build the indexes has changed to allow database operations to continue as normal for the duration of the build.\n",
    "\n",
    "So let's recap.\n",
    "\n",
    "MongoDB has one index build type, which is lockless and performant.\n",
    "\n",
    "Our motivation for this was to address the trade-offs of building indexes using foreground and indexes using the background methods.\n",
    "\n",
    "We can now build indexes quickly and without the need to lock the entire database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212b117",
   "metadata": {},
   "source": [
    "# Query Plans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7653a",
   "metadata": {},
   "source": [
    "<img src=\"img/52.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c29279",
   "metadata": {},
   "source": [
    "<img src=\"img/53.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63eaa306",
   "metadata": {},
   "source": [
    "In this lesson, we're going to talk about query plans.\n",
    "\n",
    "By the end of this lesson, you should be familiar with what query plans are, how the query optimizer works with them, and how they're cashed.\n",
    "\n",
    "Let's go ahead and talk about what a query plan is.\n",
    "\n",
    "I think the best way to illustrate this is with an example.\n",
    "\n",
    "When a query comes into the database, a query plan is formed.\n",
    "\n",
    "Which is a series of stages that feed into one another.\n",
    "\n",
    "So in the case of this query, for this given index, we'd expect the query plan to look like this.\n",
    "\n",
    "Since we have an index on zip code and cuisine, we're able to fetch the record IDs of the documents that meet our query predicate.\n",
    "\n",
    "From there, those record IDs are passed up to the fetch stage.\n",
    "\n",
    "This is where the storage engine is going to convert the record IDs into documents.\n",
    "\n",
    "And then those documents are then passed up to the sort stage, where an in-memory sort will be performed on them.\n",
    "\n",
    "This is the only reasonable query plan for this query on this index.\n",
    "\n",
    "But for a given query, we can have many different query plans based on what indexes are available.\n",
    "\n",
    "So if we have an index like this, on a cuisine and stars, this could prevent an in-memory sort.\n",
    "\n",
    "So we'd have a query plan like this.\n",
    "\n",
    "Here we'd do an index scan.\n",
    "\n",
    "Where we fetch the record IDs of our documents in store order.\n",
    "\n",
    "We then pass this up to the fetch stage where they're converted into documents and then returned.\n",
    "\n",
    "So the available indexes will determine what possible query plans we can use to satisfy our query.\n",
    "\n",
    "Now that we know what a query plan is, let's talk a little bit about how they're chosen.\n",
    "\n",
    "When a fresh query comes into the database for the first time, the server is going to look at all the available indexes on the collection.\n",
    "\n",
    "From there, it will identify which indexes are viable to satisfy the query.\n",
    "\n",
    "We call these candidate indexes.\n",
    "\n",
    "From these candidate indexes, the query optimizer can generate candidate plans.\n",
    "\n",
    "Now MongoDB has what is called an empirical query planner, which means that there is going to be a trial period, where each of the candidate plans is executed over a short period of time.\n",
    "\n",
    "And the planner will then see which plan performed best.\n",
    "\n",
    "I don't want to get too into the weeds here, but best can be which plan returned all the results first.\n",
    "\n",
    "Or it might be, which returned a certain number of documents in store order fastest.\n",
    "\n",
    "There's a lot of different ways we can describe best, and the query optimizer will do it in different ways, depending on the query.\n",
    "\n",
    "And so for this run, this is the winning plan.\n",
    "\n",
    "If we were to run explain and look under the winning plan field, this is the plan it would be talking about.\n",
    "\n",
    "And so these other plans would fall under the rejected plans field.\n",
    "\n",
    "Now, it wouldn't make much sense to run a trial run for every query that came into the database.\n",
    "\n",
    "We're going to have a lot of the queries that are going to have the same shape and would benefit from the same query plans.\n",
    "\n",
    "Because of this, MongoDB caches which plan it should use for a given query shape.\n",
    "\n",
    "Now, over time, our collection is going to change in some [INAUDIBLE] indexes.\n",
    "\n",
    "What this means is, under different conditions, the plan cache will evict a plan.\n",
    "\n",
    "This can happen if the server is restarted.\n",
    "\n",
    "Or if the amount of work performed by the first portion of the query exceeds the amount of work performed by the winning plan by a factor of 10.\n",
    "\n",
    "Plans are also evicted when the indexes are rebuilt, or if an index is created or dropped.\n",
    "\n",
    "And that should give you a good overview of query plans.\n",
    "\n",
    "Let's recap what we've learned.\n",
    "\n",
    "We spent some time talking about what query plans are.\n",
    "\n",
    "We also discussed how the query optimizer works, and how it determines which plan is best.\n",
    "\n",
    "And we also discussed query plan caching so that we're not running trial periods for every query that comes into the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79816f08",
   "metadata": {},
   "source": [
    "### 範例01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16d515b6",
   "metadata": {},
   "source": [
    "# MongoDB's query optimizer is statistically based, where collection heuristics are used to determine which plan wins.\n",
    "\n",
    "No, MongoDB has an empirical query optimizer where query plans are ran against each other during a trial period.\n",
    "\n",
    "# Query plans are cached so that plans do not need to be generated and compared against each other every time a query is\n",
    "  executed.\n",
    "\n",
    "Yes, that is correct.\n",
    "\n",
    "# When query plans are generated, for a given query, every index generates at least one query plan.\n",
    "\n",
    "No, only a subset of the indexes are considered as candidates for planning.\n",
    "\n",
    "# If an index can't be used, then there is no query plan for that query.\n",
    "\n",
    "No, if there aren't any viable indexes for a given query, then a COLLSCAN stage will be the main stage of the query plan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee55f471",
   "metadata": {},
   "source": [
    "# Forcing Indexes with Hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c9001",
   "metadata": {},
   "source": [
    "<img src=\"img/54.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd5bc8",
   "metadata": {},
   "source": [
    "<img src=\"img/55.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee997a1",
   "metadata": {},
   "source": [
    "<img src=\"img/56.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06b10ec7",
   "metadata": {},
   "source": [
    "In this lesson, we're going to discuss how we can force indexes using the hint method.\n",
    "\n",
    "And specifically, we're going to discuss how we can force a query to use a particular index, therefore overriding MongoDB's default index selection by using the hint method.\n",
    "\n",
    "Throughout this course, we spent a lot of time discussing how to design the optimal index for a given query.\n",
    "\n",
    "Unfortunately, for one reason or another, the query optimizer might not always choose the index that we'd like to be chosen for a given query.\n",
    "\n",
    "In this case, maybe this query uses the name age index instead of the name zip code index, like we would like it to.\n",
    "\n",
    "Fortunately for us though, MongoDB provides an easy way to override the query optimizer's selection.\n",
    "\n",
    "And this of course, is done with hint.\n",
    "\n",
    "In this example, I'm appending the hint method to my query, so that we're forcing the usage of name ascending zip code ascending.\n",
    "\n",
    "And here, I am using the indexes shape to tell hint what index we want to use.\n",
    "\n",
    "Other than using the shape, we can also just pass the actual name of the index to hint, to let it know what index we want to use.\n",
    "\n",
    "And that's pretty much how hint works.\n",
    "\n",
    "I do want to point out that you should use hint with caution.\n",
    "\n",
    "MongoDB's query optimizer generally does a pretty good job of selecting the correct index for a given query.\n",
    "\n",
    "The times when it does fail to select the best index for a given query is generally when there are a lot of indexes on your collection.\n",
    "\n",
    "And in those cases, it's probably better to look at index utilization and determine if you have superfluous indexes that can be removed rather than using the hint method.\n",
    "\n",
    "So to quickly recap what we learned in this lesson, we discussed how we can use the hint method to override MongoDB's default index selection for our queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b300f60",
   "metadata": {},
   "source": [
    "# Resource Allocation(資源分配) for Indexes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a78e5b5",
   "metadata": {},
   "source": [
    "So far we've seen that indexes are important data structures.\n",
    "\n",
    "They will help us optimize our queries and, as a side effect, reduce our response time.\n",
    "\n",
    "If well designed, the usage of an index supporting a given query might reduce the response time in a few orders magnitude.\n",
    "\n",
    "Let's have a quick example.\n",
    "\n",
    "I have a database called London bikes.\n",
    "\n",
    "And in this London bikes database, I have these rides_other collection where I'm going to just express a query looking for all end stations around the MongoDB office in London, and see how that behaves.\n",
    "\n",
    "Now if I pull up my explain command, I can see that the execution time in milliseconds was quite alarming.\n",
    "\n",
    "It took me 7,426 milliseconds to execute.\n",
    "\n",
    "It did return a few amount of results, like almost 20,000 documents.\n",
    "\n",
    "But still, it did a lot of work just to find a few documents.\n",
    "\n",
    "And by that, also inadvertently got a lot of time to do that.\n",
    "\n",
    "Now after we create an index on that same field that we expressed a query on, and we write again the same query, and also expecting to look into the execution stats of our explain command, we can see that we come from 7,000 milliseconds to only 337.\n",
    "\n",
    "So the usage of a single index did reduce in an order of magnitude the amount of time that this query took to operate.\n",
    "\n",
    "However, indexes are not some sort of black magic.\n",
    "\n",
    "They are data structures that our databases use, that will in turn require resources to operate.\n",
    "\n",
    "Therefore, it is quite important to determine the index size, and what kind of resources will be involved in its allocation and operation.\n",
    "\n",
    "In some edge cases where we might compromise or do some compromising in terms of what we need, in terms of resources to operate with those particular indexes.\n",
    "\n",
    "Let's start by looking into how can we determine an index size.\n",
    "\n",
    "Using MongoDB Compass, we can have a clear understanding of the size of our indexes for each one of our databases.\n",
    "\n",
    "Once we select the database, we can look into the different collections and here, we will have the total index size for each collection.\n",
    "\n",
    "Now if we select, for example, this one over here, the collection we used before.\n",
    "\n",
    "And if we look into our indexes, we can see we have a breakdown(細目) between the different indexes that support this particular collection.\n",
    "\n",
    "We have our _ID, our primary key, and obviously the one that we recently created on endstation name.\n",
    "\n",
    "We can also, obviously, get that information from our MongoDB command db.stats, where we are going to have the full index size.\n",
    "\n",
    "And obviously, per collection(db.collection.stats), we can also see the index size of a given collection, and the different sizes for the different in indexes of this collection.\n",
    "\n",
    "Now indexes need two basic computational resources.\n",
    "\n",
    "We are going to need disk to store the index information, and, obviously, we are also going to need memory so we can operate with those data structures.\n",
    "\n",
    "In index terms, disks are generally not a big issue or they are generally not an issue at all.\n",
    "\n",
    "If we don't have space in our disk for our index file, apart from having larger problems, the indexes would end up not been created at all.\n",
    "\n",
    "So if you are restrained in terms of disk size, if you ask the system to create a particular index.\n",
    "\n",
    "If we don't have space for the indexed file, then you don't have a problem with the index, you have other, slightly more important problems.\n",
    "\n",
    "After the indexes have been created, the disk space requirements will be a function of your data.\n",
    "\n",
    "Which means that you will run out of disk space for collection data before having issues with space for your indexes.\n",
    "\n",
    "That said, if you are using different physical drives in one dedicated for your indexes, you do need to make sure we have enough resources for our indexes in that particular disk.\n",
    "\n",
    "So regardless of the amount of data that you put for your collections-- so let's say that you are using this disk over here for the index file.\n",
    "\n",
    "If you have other disks for your collection data, you might not run out of disk space on your collection data, but you might end up having issues allocating resources for your indexes if you don't pay close attention to that physical drive.\n",
    "\n",
    "Just keep an eye on this if you have this type of architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdf7e5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a0e39ce",
   "metadata": {},
   "source": [
    "The most intensive resource utilization by your indexes will be RAM or memory.\n",
    "\n",
    "Our deployments should be sized in order to accommodate our indexes in RAM.\n",
    "\n",
    "This means that we should have enough space in our memory to accommodate all of our indexes.\n",
    "\n",
    "That's a good role of thumb in terms of sizing.\n",
    "\n",
    "Now if we don't have enough space in our memory to accommodate our indexes, a great deal of disk access will be required to traverse your index file.\n",
    "\n",
    "If you have different pages on the index, they will be allocated to your memory.\n",
    "\n",
    "If you are traversing that space, it means that you will slide your pages into positions that are no longer in memory, so allocating those into memory, and flushing out information to disk.\n",
    "\n",
    "If you are constantly traversing your index, you will be doing a lot of page in and page out.\n",
    "\n",
    "Now the first assessment that you should do is make sure you understand the capacity of the server.\n",
    "\n",
    "In this case I'm using a virtual machine, and I have 4 gigabytes of RAM, 4 gigabytes of memory allocated to this virtual machine.\n",
    "\n",
    "And I'm already using 3.7.\n",
    "\n",
    "I have 177 megabytes of free memory.\n",
    "\n",
    "Some of that is going to be cached.\n",
    "\n",
    "Now if I start my MongoD with wiredTigerCacheSize of 1 gigabyte, for example, I know that the size of my memory is larger than that.\n",
    "\n",
    "But the amount of cache size that I'm allocating is only going to be of 1 gigabyte.\n",
    "\n",
    "So my indexes will be placed within that cache size of 1 gigabyte.\n",
    "\n",
    "Now that we see that we can have indexes, and the indexes can be quite large, but also that those indexes will occupy a significant amount of memory, it will be nice to know which percentage of that index actually is living in memory.\n",
    "\n",
    "How can we know that?\n",
    "\n",
    "How can we determine how much of our index is actually in memory or not?\n",
    "\n",
    "If we go back to our shell and connect to our londonbikes, we have this interesting command, which is the collection stats.\n",
    "\n",
    "Now with collection stats, we can also pass a flag saying that we are interested in knowing the index details.\n",
    "\n",
    "If we run this, we will see that we're going to get a bunch of information back.\n",
    "\n",
    "So there's a lot of quite nice information around how are our indexes set up, apart from the collection stats that the command gives us.\n",
    "\n",
    "So before cruising through all this block of text, lets do a little more of an ingenious way of dealing with this information, which is basically putting all of this information into a variable.\n",
    "\n",
    "And let's see about a couple of indexes that we are going to be interested on.\n",
    "\n",
    "Start by getting the index details.\n",
    "\n",
    "As you can see here, there's a bunch of index details for each individual index.\n",
    "\n",
    "And I'm mostly interested on one of them, the one that we just recently created, our endstation_name.\n",
    "\n",
    "Now if we look into this particular set of information, we can see some interesting information on this particular setup, especially the cache object.\n",
    "\n",
    "Inside the cache, we are going to get a clear view of how much bytes are currently in cache, how much bytes are read into cache, for example, or a bunch of other criteria about, for example, the number of pages requested from the cache, or pages read into cache.\n",
    "\n",
    "So if you are interested in determining how much information is currently allocated in RAM, we most certainly can get that information by looking into the amount of bytes currently in cache.\n",
    "\n",
    "We can also determine the hit and miss page ratios by analyzing pages read into cache and pages requested from cache.\n",
    "\n",
    "Currently we have zero.\n",
    "\n",
    "But if we run our query, the previous explain query here-- actually we don't even need the explain command here.\n",
    "\n",
    "We just need to run the query.\n",
    "\n",
    "We get some results.\n",
    "\n",
    "And then we can iterate on them, and so forth.\n",
    "\n",
    "If we send our command stats back again, if we rerun the rides other stats again, and if we look again into that particular index and the cache allocation values, we will see that some pages have been requested from cache.\n",
    "\n",
    "That is great.\n",
    "\n",
    "We did traverse the index and we needed a couple of pages from RAM.\n",
    "\n",
    "We need to read pages into cache, and the amount of data of this index currently in cache also [?\n",
    "\n",
    "erased, ?] because we needed to allocate more information than what we previously added since we had a clean restart of this particular MongoD.\n",
    "\n",
    "Now there's a bunch of information around this command.\n",
    "\n",
    "And we are not going to go deep into how to decipher all of this information.\n",
    "\n",
    "That is out of scope for this particular course.\n",
    "\n",
    "But do keep in mind that MongoDB does allow you to understand pretty well what goes into cache, what is allocated in RAM, and what isn't, using MongoDB WiredTiger's storage engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98236cd0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd970b71",
   "metadata": {},
   "source": [
    "Our rule of thumb says that we should always have enough memory to allocate our indexes.\n",
    "\n",
    "But there are some edge cases-- like, for example, the occasional reports that our beyond tools and reporting mechanisms do perform, and they might need an index to support those queries.\n",
    "\n",
    "And also situations where we would have a right-end-side index increment.\n",
    "\n",
    "Let's have a look into both of these and what kind of other solutions we have for these type of edge cases.\n",
    "\n",
    "Apart from the obvious situation where indexes are not being utilized should not be created or not present in a production environment anyway, there are two edge cases that do not need to have the full extent of the index size in RAM.\n",
    "\n",
    "Most of our queries are to support operational functionality-- means they are recurrently getting information and using those indexes to support operational workload.\n",
    "\n",
    "That means, as well, that any index that supports a particular query should be in RAM because we know that that data will be utilized to respond to an operational query.\n",
    "\n",
    "But let's imagine our reporting or BI tool mechanisms.\n",
    "\n",
    "If we do have indexes to support those queries, which we should, chances that you need this information to be always allocated in memory are very small because the recurrency by which these tools operate is not in the same amount or degree that our operational workload.\n",
    "\n",
    "One way of mitigating the effect of these particular tools is instead of running the queries in our primaries and having the indexes created on those primaries, we can have our secondaries be replying to requests of our BI tools, and therefore having the indexes that support those queries been created only on designated nodes.\n",
    "\n",
    "Another situation where the full amount of our indexes does not necessarily requires to be fully allocated in memory is when we have indexes on fields that grow monotonically, like counters, dates, and incremental IDs.\n",
    "\n",
    "If you take in consideration the index structures-- naively represented by this tree over here, which is a petrie.\n",
    "\n",
    "If we have monotonically increasing data, chances are that our index will eventually become unbalanced on the right-hand side of that index.\n",
    "\n",
    "Therefore, it will grow accordingly with the new data coming in.\n",
    "\n",
    "So if you have an incremental ID, you start with 0, and you end up with 100 every time that you add a new element to your data set.\n",
    "\n",
    "You only grow positively.\n",
    "\n",
    "That means that the tree will always grow in the right-hand side.\n",
    "\n",
    "If we add to that fact that we only need to query on the most recent data, then the amount of index that actually needs to be in RAM is always going to be the right-end side of your index.\n",
    "\n",
    "So here, in terms of memory allocation for this particular index, we only need to care about how much data-- from the recently added data-- how are we going to be needing to access all the time?\n",
    "\n",
    "This is a typical scenario of IOT kind of use cases where new data being created in index will be either time based or incremental data that always going to grow positively in our right-hand side of our index.\n",
    "\n",
    "Therefore, if your total index size is 10 gigabytes, but the most recent access data-- the one that we are using the index to query on-- is only 2 gigabytes of information, then that's the amount of size that you need to allocate a memory to support those queries.\n",
    "\n",
    "A typical case is, for example, when you have something like a checkout, that you have a field, and an ISODate.\n",
    "\n",
    "You create an index to support queries on date.\n",
    "\n",
    "And the queries that you operate from the application is looking to that date, like doing the exact same moment in time now, and sorting by date descending.\n",
    "\n",
    "So you are getting always the latest results on your query.\n",
    "\n",
    "Therefore, it is admissible that in these situations you might not need to allocate the full extent of your supporting index.\n",
    "\n",
    "To wrap it up, when thinking about the resource allocation for your indexes, and when dealing with indexes, we cannot forget about that these data structures do require a lot of resources.\n",
    "\n",
    "They are part of your database working sets, and we need to take them in consideration in our original sizing and maintenance practices.\n",
    "\n",
    "And this is all you need to know about resource allocation for indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa93e68d",
   "metadata": {},
   "source": [
    "### 範例01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0308ad90",
   "metadata": {},
   "source": [
    "Which of the following statements apply to index resource allocation?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8951bea7",
   "metadata": {},
   "source": [
    "(勾) For the fastest processing, we should ensure that our indexes fit entirely in RAM\n",
    "\n",
    "( ) Index information does not need to completely allocated in RAM since MongoDB only uses the right-end-side to the index\n",
    "    b-tree, regardless of the queries that use index.\n",
    "\n",
    "(勾) Indexes are not required to be entirely placed in RAM, however performance will be affected by constant disk access to\n",
    "     retrieve index information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade30a3",
   "metadata": {},
   "source": [
    "# Basic Benchmarking"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db09aac2",
   "metadata": {},
   "source": [
    "In this lesson, we are going to talk about benchmarking.\n",
    "\n",
    "Now we are not going to be going through the full process of benchmarking.\n",
    "\n",
    "But basically just highlighting some things that you should take in consideration if you are going to benchmark MongoDB.\n",
    "\n",
    "Once we start analyzing a given software product like a database, operating system, or application server we need to understand the benefits that such component brings to our application.\n",
    "\n",
    "And for that we use benchmarking.\n",
    "\n",
    "Now there are different types how to perform benchmarking.\n",
    "\n",
    "Also, there's the other concept of bench marketing.\n",
    "\n",
    "Now there's a big difference between benchmarking and bench marketing.\n",
    "\n",
    "Both have related value, depending on the audience.\n",
    "\n",
    "But we will be focusing on the first one.\n",
    "\n",
    "The one that allows us to correlate with performance indicators and metrics that we can use to assess if a given product is actually good for our system or not.\n",
    "\n",
    "Benchmarking assumes that you are going to perform some sort of comparison.\n",
    "\n",
    "You can use publicly available test suites, and we're going to talk about a bunch of those, or you can also perform your own private testing that correlates better with your use case or application.\n",
    "\n",
    "Now there are different types for each kind of performance benchmarking that get more specific or more broad aspects of the benchmarking that you might be trying to do.\n",
    "\n",
    "So let's have a look to a few of them.\n",
    "\n",
    "We can perform low level benchmarking.\n",
    "\n",
    "Now what I mean by low level benchmarking, our benchmarking that are designed to look into file I/O performance, or scheduler performance, or even memory allocation and transfer speeds.\n",
    "\n",
    "There are benchmarking that look into thread performance, database server performance, transaction isolation, and multiple of other parameters.\n",
    "\n",
    "Tools like sysbench, or even iibench are good tools that allow you to go very deep into the low level benchmarking kind of testing.\n",
    "\n",
    "Now there's also another type of benchmarking, which is the database server benchmarking.\n",
    "\n",
    "Now these tests are more concerned about things like data set load, writes per second, reads per second, balanced workloads, read and write ratios.\n",
    "\n",
    "Things that will allow you to understand how a database will react with generic data sets, but will take into consideration the output of a given node, and look into metrics to correlate if there's been some sort of advantage or disadvantage of using a specific product.\n",
    "\n",
    "Some tools like YCSB, originally developed by Yahoo, or even the TCP ones, which are industry benchmarks in all it's sorts and different variations, are good test base that you can submit a database to.\n",
    "\n",
    "Now do not forget that a bunch of these tools that do database server benchmarking have been original developed for relational systems.\n",
    "\n",
    "And if you are testing those with MongoDB in mind, some variations might need to be applied because a lot of the different functionality you might be expecting does not behave in the same way.\n",
    "\n",
    "So if you're looking for YCSB, make sure that you look for a variation that correlates better to MongoDB, or does it perfect what MongoDB does to actually get some solid results?\n",
    "\n",
    "And then we also have distributed systems benchmarking, which for MongoDB is a big thing because given that we are a distributed database, it is important not only to look into a particular node, but also how things react under a distributed system.\n",
    "\n",
    "Here, you want to do very, very hard tests like linearization, serialization, fault tolerance, where we will look into a bunch of different perspectives on how things occur over time, how we can deal with the serialization of requests, the linearization of reads and writes.\n",
    "\n",
    "And also, when we have different DataNodes.\n",
    "\n",
    "And if those nodes fail, how does the overall system behave under those conditions?\n",
    "\n",
    "You can do that your own set of testing for distributed systems.\n",
    "\n",
    "Now there are very good data sets out there like iBench, which is more related to Hadoop environments, and Jepsen, which actually does a very nice set of reports on how different databases react under a very specific setting of conditions.\n",
    "\n",
    "In this case, we actually include Jepsen tests in our MongoDB build continuous integration tooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589bedc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dc74ee8",
   "metadata": {},
   "source": [
    "Now, most of these tools can be run by you or you can just review the published results.\n",
    "\n",
    "That's all fine.\n",
    "\n",
    "You can pick a tool of choice and run tests on MongoDB or any other database.\n",
    "\n",
    "But let's make sure that you understand the conditions by which those tools and those tests are going to be run.\n",
    "\n",
    "Again, majority of the tooling for benchmarking existing today had been built with relational systems in mind.\n",
    "\n",
    "And those conditions not always apply to MongoDB and other modern databases.\n",
    "\n",
    "Now, if you're only interested on doing a small set of testing using read and write ratios from MongoDB, my good friend, John Page, this young, attractive fellow over here, built the POC driver.\n",
    "\n",
    "It's a small project written in Java that allows you to put to test your MondoDB cluster to a set of conditions and a set of different variations that you can set by yourself.\n",
    "\n",
    "All of the previous are great.\n",
    "\n",
    "You can run it yourself.\n",
    "\n",
    "You can just run the tests which are genetically available online, or even use John Page's POC driver.\n",
    "\n",
    "But sometimes they are not really what we need, perhaps because they do not capture the essence of your use case or they are missing out on some specific functionality of MongoDB that you are interested in.\n",
    "\n",
    "But let's not forget about benchmarking anti-patterns.\n",
    "\n",
    "Because if you're running you're testing yourself, let's make sure you do it right.\n",
    "\n",
    "Now, those anti-patterns can be things like database swap replace.\n",
    "\n",
    "Let's say, for example, that we are comparing MongoDB with a relational system where your relational system would be something like this where you have some sort of relations and tables and the relationships between those tables.\n",
    "\n",
    "Now, if you are expecting to replace the exact same schema from your relational world to MongoDB collection world, probably a one-by-one one relationship between tables and collections might not be the best way to go forward.\n",
    "\n",
    "This may not be reflecting MongoDB's capabilities and, therefore, will not be a truly comparison between two different systems.\n",
    "\n",
    "You need to think a little bit more about how you're going to operate data, how are you going to insert, how are you going to read, how you're going to structure your documents.\n",
    "\n",
    "All of that will be a great deal of concern if you do not do so.\n",
    "\n",
    "Also, using MongoDB tools to test performance of MongoDB is probably not a great idea.\n",
    "\n",
    "If you're building your application on top of the mongo shell, for example, where all requests of your code invoke the mongo shell and perform an operation, then yes.\n",
    "\n",
    "Then that will be the ideal scenario to test the performance using the mongo shell.\n",
    "\n",
    "And by that we mean by testing these sort of things where you can run some sort of cycle inside of mongo shell, insert a bunch of documents, and then you get a response at the end saying how much time did it execute.\n",
    "\n",
    "If that's your use case, where you invoke the mongo shell from your application, then go ahead.\n",
    "\n",
    "That's a good way of benchmarking.\n",
    "\n",
    "But I'm not really sure that that's exactly what you want.\n",
    "\n",
    "Also, using mongoimports to test write response of your MondoDB installation is also kind of dubious in terms of what you are really trying to achieve there.\n",
    "\n",
    "Your laptop might be great.\n",
    "\n",
    "I'm pretty sure it's a nice machine with a bunch of stickers on it and all of that.\n",
    "\n",
    "But assuming that any performance testing that you run from your laptop, aside from any unit tests or development testing that you might be interested on, might not be the best way to assess if MongoDB or any database by that matter actually performs accordingly with your expectations.\n",
    "\n",
    "Please use a purpose server to run your tests.\n",
    "\n",
    "And, finally, using MongoDB out-of-the-box parameters probably is not what you're going to find in production.\n",
    "\n",
    "That means that if you're going to run your application with MongoDB installed on it and the only thing that you do is download the binary and boot it up, that's great.\n",
    "\n",
    "That's how MongoDB works.\n",
    "\n",
    "But you might want to consider things like authentication.\n",
    "\n",
    "Now you may want to consider, how do you going to be dealing with the high availability.\n",
    "\n",
    "And testing, especially benchmarking for performance without those conditions in place, will be shooting yourselves in the foot.\n",
    "\n",
    "So be careful about that.\n",
    "\n",
    "And that drives to the benchmarking conditions.\n",
    "\n",
    "Make sure you're fair, you're fair in terms of the comparisons that you do concerning the hardware that you're utilizing the type of clients and the type of operations that you're doing, and the kind of load that you're going to be subjecting your systems to.\n",
    "\n",
    "Either different systems or different versions of the systems that you are testing, they should have a fair ground in all those three dimensions.\n",
    "\n",
    "Let's recap this lesson.\n",
    "\n",
    "So, in this lesson, we talked about the different types of benchmarking that you can do, either using publicly-available data sets and tools or building your own.\n",
    "\n",
    "There's different types like low-level, high-level, distributed, load, a bunch of different ones.\n",
    "\n",
    "You can even do your own specific benchmarking.\n",
    "\n",
    "There's obviously different public tools available out there that benchmark databases.\n",
    "\n",
    "But make sure that you are using the one that is more suited to the database that you are interested in testing.\n",
    "\n",
    "And don't forget about the anti-patterns of MongoDB benchmarking.\n",
    "\n",
    "These are very, very important to for you to get a truthful view of how the system is actually going to be behaving.\n",
    "\n",
    "And that's all we have for basic benchmarking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510d063",
   "metadata": {},
   "source": [
    "<img src=\"img/57.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f137801",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d317b8",
   "metadata": {},
   "source": [
    "### 範例01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5db2533",
   "metadata": {},
   "source": [
    "In this lab you're going to determine which index was used to satisfy a query given its explain output.\n",
    "\n",
    "The following query was ran:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd360d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "> var exp = db.restaurants.explain(\"executionStats\")\n",
    "> exp.find({ \"address.state\": \"NY\", stars: { $gt: 3, $lt: 4 } }).sort({ name: 1 }).hint(REDACTED)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df721472",
   "metadata": {},
   "source": [
    "Which resulted in the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"queryPlanner\": {\n",
    "    \"plannerVersion\": 1,\n",
    "    \"namespace\": \"m201.restaurants\",\n",
    "    \"indexFilterSet\": false,\n",
    "    \"parsedQuery\": \"REDACTED\",\n",
    "    \"winningPlan\": {\n",
    "      \"stage\": \"SORT\",\n",
    "      \"sortPattern\": {\n",
    "        \"name\": 1\n",
    "      },\n",
    "      \"inputStage\": {\n",
    "        \"stage\": \"SORT_KEY_GENERATOR\",\n",
    "        \"inputStage\": {\n",
    "          \"stage\": \"FETCH\",\n",
    "          \"inputStage\": {\n",
    "            \"stage\": \"IXSCAN\",\n",
    "            \"keyPattern\": \"REDACTED\",\n",
    "            \"indexName\": \"REDACTED\",\n",
    "            \"isMultiKey\": false,\n",
    "            \"isUnique\": false,\n",
    "            \"isSparse\": false,\n",
    "            \"isPartial\": false,\n",
    "            \"indexVersion\": 1,\n",
    "            \"direction\": \"forward\",\n",
    "            \"indexBounds\": \"REDACTED\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"rejectedPlans\": [ ]\n",
    "  },\n",
    "  \"executionStats\": {\n",
    "    \"executionSuccess\": true,\n",
    "    \"nReturned\": 3335,\n",
    "    \"executionTimeMillis\": 20,\n",
    "    \"totalKeysExamined\": 3335,\n",
    "    \"totalDocsExamined\": 3335,\n",
    "    \"executionStages\": \"REDACTED\"\n",
    "  },\n",
    "  \"serverInfo\": \"REDACTED\",\n",
    "  \"ok\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c99e7ff1",
   "metadata": {},
   "source": [
    "{ \"address.state\": 1, \"name\": 1, \"stars\": 1 }\n",
    "\n",
    "# No, if this index was used, then there would be no SORT stage.\n",
    "\n",
    "{ \"address.state\": 1, \"stars\": 1, \"name\": 1 }\n",
    "\n",
    "# Yes, this query wouldn't need to examine any extra index keys, so since nReturned and totalKeysExamined are both 3,335 we \n",
    "  know this index was used.\n",
    "\n",
    "{ \"address.state\": 1, \"name\": 1 }\n",
    "\n",
    "# No, if this index was used, then there would be no SORT stage.\n",
    "\n",
    "{ \"address.state\": 1 }\n",
    "\n",
    "# No, if this index was used, then we would expect that we'd have to examine some unnecessary documents and index keys.\n",
    "  Since there are 50 states in the US, and we have 1,000,000 documents we'd expect to examine about 20,000 documents, not\n",
    "  the 3,335 we see in the output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
