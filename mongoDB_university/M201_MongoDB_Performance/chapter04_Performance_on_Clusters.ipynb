{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1378e248",
   "metadata": {},
   "source": [
    "# Performance Considerations in Distributed Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf557a76",
   "metadata": {},
   "source": [
    "<img src=\"img/65.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1862368",
   "metadata": {},
   "source": [
    "<img src=\"img/66.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b74f10",
   "metadata": {},
   "source": [
    "<img src=\"img/67.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4788768",
   "metadata": {},
   "source": [
    "In this lesson, we are going to talk about some important considerations regarding Performance in a Distributed System.\n",
    "\n",
    "A distributed system in MongoDB includes both replica sets-- or Replica Clusters-- for a high availability solution, and Shard Clusters.\n",
    "\n",
    "Shard Clusters are our mechanism to allow horizontal scalability of our data.\n",
    "\n",
    "When working with a distributed system, we need to acknowledge a few things.\n",
    "\n",
    "When more than one machine talks to each other, latency will be involved.\n",
    "\n",
    "So we need to consider latency.\n",
    "\n",
    "Data is generally spread across different notes.\n",
    "\n",
    "It's either copies of the data or different sets of data in different charts.\n",
    "\n",
    "There will be read implications, so things will be performing in a different pace, and obviously, also, write implications.\n",
    "\n",
    "Now, regarding your replica sets, let me reinforce a message around this.\n",
    "\n",
    "Please do use them in production environments.\n",
    "\n",
    "High availability is key to guarantee that your service is not affected by any potential, and probable, system failure.\n",
    "\n",
    "Having a replica set in place is super, super important.\n",
    "\n",
    "Apart from the main purpose of providing high availability, in case of failure of a node, we will still have availability of a service provided by the remaining nodes, but replica sets can also provide a few other functions, like offloading ventral consistency data to secondaries, privileging your primary for operational workload, or having specific workload with target indexes configuration on secondary nodes.\n",
    "\n",
    "More on this topic to be covered in upcoming lessons.\n",
    "\n",
    "The other side of distributed systems in MongoDB, with a purpose of horizontal scalability, is our Shard Cluster.\n",
    "\n",
    "In our Shard Cluster, we will have our Mongo assets, responsible for routing our client application requests to designated nodes.\n",
    "\n",
    "We're going to have config servers.\n",
    "\n",
    "These nodes are responsible for holding the mapping of our Shard Cluster, where data sits at each point in time, but also the general configuration of our Shard Cluster in its own.\n",
    "\n",
    "And finally, we have our Shard Nodes.\n",
    "\n",
    "Shard Nodes are responsible for holding the application data.\n",
    "\n",
    "Databases, collections, indexes-- these will reside in these members, and it will be here that all major workload will be performed.\n",
    "\n",
    "Shard Nodes are in themselves replica sets.\n",
    "\n",
    "This is important since if a Shard Note will not be configured as a replica set, therefore with no high visibility for that node, we could eventually lose access in case of failure for a significant portion of our application data, and that's not cool.\n",
    "\n",
    "A Shard Cluster does require a few steps to be properly configured, but these are out of scope for this particular lesson.\n",
    "\n",
    "But we will be looking to what you need to know before you can figure your Shard Cluster.\n",
    "\n",
    "Sharding is our horizontal scalability solution, which is great scaling strategy for very large data sets.\n",
    "\n",
    "You'll eventually reach the limits of your vertical scaling either in terms of cost per performance gains.\n",
    "\n",
    "But before you jump into charting bandwagon, you need to consider if you're already reached those limits.\n",
    "\n",
    "If buying another box would not give you that gain in terms of performance and cost that you are expecting.\n",
    "\n",
    "Another important thing is that you need to understand how your data grows, and how your data is accessed.\n",
    "\n",
    "Since Sharding works by defining a key base ranges, knowing how your data grows, and knowing how your data is being constantly accessed allows you to get into a good shard key.\n",
    "\n",
    "And that's a very, very important exercise that you need to do.\n",
    "\n",
    "Before doing any sharding at all, is defining what will be a good shad key for your data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afad032",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79b58f4e",
   "metadata": {},
   "source": [
    "Now as you can see from this diagram, once you have a shard cluster in hand, there will be a bunch of different nodes that you need to consider.\n",
    "\n",
    "And with those nodes will come some communication, and therefore latency.\n",
    "\n",
    "The client application will talk to our MongoSes.\n",
    "\n",
    "The MongoSes themselves will establish connections with config servers to fetch all the configuration of all your shards, and obviously with the shard nodes to retrieve the information requested by the application.\n",
    "\n",
    "So there's a lot of communication between all different elements of this topology for a given shard cluster.\n",
    "\n",
    "Now, all of this communication and the fact that the nodes can be spread apart from each other, latency will have an impact in your application performance.\n",
    "\n",
    "As you can imagine, not only the fact that you're going to have different nodes talking to each other, but also within the replica sets themselves, there will be some entropy caused into the network by the replication mechanism.\n",
    "\n",
    "As you can imagine, having to talk to a single replica set, or with a different set of shard nodes, will have its latency consequences.\n",
    "\n",
    "There are architectures that try to minimize the impact of latency in your application given a shard cluster.\n",
    "\n",
    "Things like co-locating a MongoS within the same server as your application server to minimize the number of network hoops required to access the shard nodes are some of the strategies enforced to minimize the impact of latency.\n",
    "\n",
    "And if the nodes are correctly connected without passing through very slow or latent or even low-bandwidth network segments, then the effect of latency in your overall performance of a distributed system will be marginal.\n",
    "\n",
    "However, the speed of light limit is still there.\n",
    "\n",
    "And if your application server sits in Barcelona, tries to reach a shard node that is placed, for example, in Palo Alto, then this will not be done without paying the latency toll.\n",
    "\n",
    "And this drives us to another important aspect of working with distributed systems, especially in how reads are concerned.\n",
    "\n",
    "In MongoDB, there are two types of reads that we can perform in a shard cluster.\n",
    "\n",
    "Scattered gathered, where are we ping all nodes of our shard cluster for the information corresponding to a given query, or routed queries, where we ask one single shard node or a small amount of shard nodes for the data that your application is requesting.\n",
    "\n",
    "These two different types of reads, routed queries and scattered gathered will have two different performance profiles.\n",
    "\n",
    "With scattered gather, we will pay the price for asking everyone for the information that we need to reply for a single query, while in routed queries, we only need to ask one or a very small set of the elements for all the data that we need.\n",
    "\n",
    "The difference will be based on if we are using the shard key on our queries or not.\n",
    "\n",
    "If we are not using the shard key, we will be performing scattered gathered queries, where the system is not able to determine with exact precision which of the nodes contains the information that you need to satisfy your client request, while in routed queries, that's completely different, by using the shard key, our MongoSes can pinpoint exactly which shards contain the information relevant for our client query.\n",
    "\n",
    "Sorting in a sharded cluster involves a few hurdles.\n",
    "\n",
    "From the application perspective, this is totally transparent.\n",
    "\n",
    "It works exactly in the same way as a single node replica set.\n",
    "\n",
    "You do not need to change a single comma in your code.\n",
    "\n",
    "But from within the shard cluster, things change a little bit.\n",
    "\n",
    "After you [INAUDIBLE] the query that contains the sort, the MongoS will then drive the request to the designated shards and locally a sort will be performed.\n",
    "\n",
    "Once that local sort is performed, then a final sort merge will need to occur in the primary shards of our database.\n",
    "\n",
    "Once that sort merge is performed, then we return back the information to our clients.\n",
    "\n",
    "The same set of operations and logic will be applied with the skip or even with the limit.\n",
    "\n",
    "The application will send their query to MongoS.\n",
    "\n",
    "MongoS will select the designated shards, and local skip and limit will be performed.\n",
    "\n",
    "And once those results are done, a final merge of that result set is performed on the primary shard.\n",
    "\n",
    "And then the result is sent back to our clients through the MongoS.\n",
    "\n",
    "As you can see, there's a few more steps in the overall chain of requests that need to be attended by the shard cluster before providing back a correct answer in terms of limit and skip, but also in terms of sorting.\n",
    "\n",
    "Let's recap what we've learned today.\n",
    "\n",
    "There are a few things that you need to know before sharding.\n",
    "\n",
    "Have you reached the vertical scaling limit of your cluster?\n",
    "\n",
    "Have you considered how your data is growing, how it is accessed, and determined a good shard key.\n",
    "\n",
    "Latency will be involved in a distributed system.\n",
    "\n",
    "There's no way to avoid it.\n",
    "\n",
    "It might be minimized with good architectures to do so, but it will still be something that you need to consider from a performance perspective.\n",
    "\n",
    "Scattered gathered and routed queries are two completely different profiles in terms of read response in a distributed system, so pay close attention to that.\n",
    "\n",
    "Sorting, limit, and skip will also have its hurdles within a given distributed system for correctness and to reflect the exact request that our clients are asking for.\n",
    "\n",
    "And this is all we have on performance considerations for distributed systems."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc14bcfb",
   "metadata": {},
   "source": [
    "# In MongoDB 4.2, we can use any of the shards (or mongos) to do final sort, limit and skip steps. For more details, you\n",
    "  can refer to How mongos Handles Query Modifiers section in the documentation.\n",
    "# Latency in web\n",
    "  Latency 是效能的一環，它讓我們得以量化，有所依規的來訂定優化的標準。那以 Web 來說的話，Latency 指的就是使用者自發出請求後，等待伺服\n",
    "  器回應並回傳給使用者的總花費時間，也等同代表網站「被訪問的速度」\n",
    "# Throughput 吞吐量\n",
    "  以一個時間區間作為單位，單位時間內可以執行「幾次」操作，或運算的「次數」。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c1016",
   "metadata": {},
   "source": [
    "# Increasing Write Performance with Sharding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22fc61b1",
   "metadata": {},
   "source": [
    "In this lesson, we're going to talk about increasing your write performance with sharding.\n",
    "\n",
    "First, we're going to discuss the differences between horizontal and vertical scaling.\n",
    "\n",
    "After that, we'll talk about rules for picking a good shard key.\n",
    "\n",
    "And finally, we'll spend some time talking about bulk write operations in a sharded cluster.\n",
    "\n",
    "So there are going to be times when you have too much data or too much throughput for your database to handle.\n",
    "\n",
    "And this problem is solved by scaling.\n",
    "\n",
    "And there are two schools of thought when it comes to scaling.\n",
    "\n",
    "There's vertical scaling, and there's horizontal scaling.\n",
    "\n",
    "With vertical scaling.\n",
    "\n",
    "The idea is that your current server has too few resources and is being overworked.\n",
    "\n",
    "And to fix that issue, you're just going to buy a bigger, faster machine with more CPU, RAM, and disk.\n",
    "\n",
    "This approach will eventually reach a limit.\n",
    "\n",
    "There's a ceiling to how much CPU, RAM, and disk one single physical machine can have.\n",
    "\n",
    "Moreover, the cost to scale your machine vertically is not linear.\n",
    "\n",
    "When we buy a machine that is twice as fast and powerful as our current server, our cost doesn't double, it normally quadruples or even worse.\n",
    "\n",
    "With horizontal scaling, on the other hand, instead of increasing the resources of your server you just increase the total number of servers, effectively splitting the workload between many different machines.\n",
    "\n",
    "When we reach the limit of our current setup, we just add more machines.\n",
    "\n",
    "This is nice because we can use commodity machines, where we're simply buying more of the same machine.\n",
    "\n",
    "When we do this, our costs scale nice and linearly with our performance requirements.\n",
    "\n",
    "Now, it's important to understand that with a sharded cluster, all of our reads and writes are going to go into a mongos.\n",
    "\n",
    "This is important to realize because this mongos needs to be able to determine where to send the reads and writes.\n",
    "\n",
    "This is achieved with a shard key.\n",
    "\n",
    "The shard key defines how our data is partitioned across different machines.\n",
    "\n",
    "The shard key is either an index field or an index compound of fields that exist in every document in the collection.\n",
    "\n",
    "Now it's very important that we evenly distribute our data across these shards so that we can evenly distribute their load.\n",
    "\n",
    "This is why picking a good shard key is the most important part of sharding.\n",
    "\n",
    "With a shard key, our data is divided up into bite size pieces called chunks.\n",
    "\n",
    "Each chunk has an inclusive lower bound and exclusive upper bound.\n",
    "\n",
    "In this hypothetical example, we defined a shard key on last name and we created three chunks.\n",
    "\n",
    "The first chunk has a lower bound of Abbott and has an upper bound Fisher.\n",
    "\n",
    "Now in reality, with sharding, we'd have far more chunks than this.\n",
    "\n",
    "By default, a chunk's maximum size is 64 megabytes.\n",
    "\n",
    "Chunks will grow close to this value, and then they will be split.\n",
    "\n",
    "So there are many chunks existing on each of the shards in a cluster.\n",
    "\n",
    "Now in order for our write throughput to truly scale linearly as we add shards, we need to ensure that these chunks are evenly distributed across each shard.\n",
    "\n",
    "To achieve this, there are three key things to keep in mind when designing a shard key.\n",
    "\n",
    "There is carnality, frequency, and rate of change.\n",
    "\n",
    "Let's take a look at each of these.\n",
    "\n",
    "With cardinality, we're referring to the number of distinct values for a given shard key.\n",
    "\n",
    "We want high cardinality.\n",
    "\n",
    "The cardinality of our shard key determines the maximum number of chunks that can exist in our cluster.\n",
    "\n",
    "If, for instance, we were to build an application that was used only by people who live in New York City, and we were sharding on state, then we could have a maximum of one chunk, because both the upper and lower bound of this chunk would be New York.\n",
    "\n",
    "And since we only have one chunk, this means we can only have one shard.\n",
    "\n",
    "So we want to ensure that our shard key has high cardinality.\n",
    "\n",
    "If you can't use a field that has higher cardinality, you can increase the cardinality of your shard key by creating a compound shard key.\n",
    "\n",
    "Now instead of having the range of values just on state, we have a range of values for every state and last name combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bc671",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbc7d867",
   "metadata": {},
   "source": [
    "Next, let's talk about frequency.\n",
    "\n",
    "Not only is it important that we have a large number of different values for our shard key, but we also want to make sure that there's an even distribution for each value.\n",
    "\n",
    "If certain values come into our system more often than others, then we won't have an even amount of load across our cluster.\n",
    "\n",
    "This limits the effectiveness of our ability to scale the handling of incoming reads and writes.\n",
    "\n",
    "If for example, we built an application where the majority of the people using it had the last name Brown, then the throughput of our application would be constrained by the shard containing those values.\n",
    "\n",
    "We define this as a hot shard.\n",
    "\n",
    "Furthermore, the chunks containing our frequently appearing values would grow larger and larger.\n",
    "\n",
    "Typically, when a chunk gets close to its maximum size, MongoDB will then split it into two chunks.\n",
    "\n",
    "However, if a chunk is created where the lower and upper bounds are the same, then that chunk is no longer eligible for splitting.\n",
    "\n",
    "We call these jumbo chunks.\n",
    "\n",
    "These reduce the effectiveness of horizontal scaling, because we won't be able to move these chunks between shards.\n",
    "\n",
    "The issue of uneven frequency can be mitigated if we create a good compound shard key.\n",
    "\n",
    "You want to make sure that the fields at the beginning of your shard key still have high cardinality.\n",
    "\n",
    "But by compounding the key, we're able to effectively distribute the frequency of popular values.\n",
    "\n",
    "And finally, we have rate of change.\n",
    "\n",
    "Here, we're going to talk about how our values change over time.\n",
    "\n",
    "The key here is that we want to avoid monotonically increasing or decreasing values in our shard key.\n",
    "\n",
    "Monotonically means in a way that either is always increasing or always decreasing.\n",
    "\n",
    "The classic example of this is obectID.\n",
    "\n",
    "Because of the way that objectID is designed, new object IDs will always increase in value.\n",
    "\n",
    "Keep this in mind if you're using underscore IDs default data type, objectID, as your shard key.\n",
    "\n",
    "As you can see, when we have a monotonically increasing shard key, all of our writes are going to the same shard, the shard that contains the chunk where the upper bound is max key.\n",
    "\n",
    "As you can see, when we have a monotonically increasing shard key, all of our writes are going to the same shard.\n",
    "\n",
    "This is the shard that contains the upper bound of max key, which is often referred to as the last shard.\n",
    "\n",
    "If we were to have a monotonically decreasing value, then all of our writes would be coming in to this shard, the shard where the lower bound is set to min key, our first shard.\n",
    "\n",
    "Now, its OK to have a monotonically increasing value in your shard key, as long as it's not the first field.\n",
    "\n",
    "Adding a monotonically increasing value to the end of our shard key actually is a great idea, because it increases the total cardinality of our shard key since it's guaranteed to always be unique.\n",
    "\n",
    "Now let's spend some time talking about bulk writes in a shard cluster.\n",
    "\n",
    "When we make bulk writes into MongoDB, we have to specify whether we want those writes to be ordered or unordered.\n",
    "\n",
    "With an ordered bulk write, the server is going to execute these operations one after another, waiting for the last response to succeed before executing the next.\n",
    "\n",
    "If an operation fails, we immediately stop the bulk insertion and report back to the client.\n",
    "\n",
    "With an unordered bulk write, the server can execute all these operations in parallel.\n",
    "\n",
    "Now, with a sharded cluster, ordered bulk writes can be an issue because we have to wait for the last operation to complete before we can execute the next.\n",
    "\n",
    "While both replica sets and sharded clusters would both work in this way, the difference between the two is that in a replica set, these operations will be processed entirely in one machine, the primary.\n",
    "\n",
    "While in a sharded cluster, we are bound to the response time of each shard.\n",
    "\n",
    "So with a sharded cluster, the latency in between executing an operation and it's response is increased, since the write is being performed on a different machine.\n",
    "\n",
    "On the other hand, with an unordered bulk write, we can execute all of our operations in parallel, maintaining the distributed benefits that we get with a sharded cluster.\n",
    "\n",
    "It's important to note that with a bulk write in a sharded cluster, the Mongos is going to need to deserialize these write operations into the corresponding nodes.\n",
    "\n",
    "This means that the mongos will have to send each write operation to each individual shard.\n",
    "\n",
    "And that should give you a good overview of increasing your performance with sharding.\n",
    "\n",
    "Let's recap what we've learned.\n",
    "\n",
    "We talked about the differences between horizontal and vertical scaling.\n",
    "\n",
    "We also discussed some important rules to keep in mind when you're designing a shard key, as it's the most important part of sharding.\n",
    "\n",
    "And then finally, we discussed bulk inserts and some of the differences that you'll see when doing bulk inserts on a sharded cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df057f",
   "metadata": {},
   "source": [
    "# Reading from Secondaries"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c19c9ca",
   "metadata": {},
   "source": [
    "# db.people.find().readPref(\"Primary\")\n",
    "# db.people.find().readPref(\"PrimaryPreferred\")\n",
    "# db.people.find().readPref(\"secondary\")\n",
    "# db.people.find().readPref(\"secondaryPreferred\")\n",
    "# db.people.find().readPref(\"nearest\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de2dd73a",
   "metadata": {},
   "source": [
    "# When reading from a secondary is a good idea\n",
    "\n",
    "- Analytics queries\n",
    "- Local reads"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65f53603",
   "metadata": {},
   "source": [
    "# When reading from a secondary is a bad idea\n",
    "\n",
    "- Providing extra capacity for reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522337c2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d96d9a4",
   "metadata": {},
   "source": [
    "All right, welcome back.\n",
    "\n",
    "In this lesson we're going to discuss reading from secondaries as it pertains to performance in MongoDB.\n",
    "\n",
    "We'll discuss when it's a good idea and when it can be a bad idea.\n",
    "\n",
    "Before we talk about performance, let's first talk about read preference.\n",
    "\n",
    "When we read data from MongoDB, there is an associated read preference.\n",
    "\n",
    "By default, this is set to the primary node, meaning that, by default, all reads will go to the primary member of a replica set.\n",
    "\n",
    "There are several other read preferences available to us, but discussing what each of these does and when you'd use them is out of scope for this lesson.\n",
    "\n",
    "For now, we're just going to discuss the read preferences that are relevant to performance.\n",
    "\n",
    "By default, the read preference is primary, meaning that all reads and writes will go to the primary node by default.\n",
    "\n",
    "If you change the read preference to secondary, then your reads will be routed to one of the secondaries.\n",
    "\n",
    "Writes, however, can only be routed to the primary node.\n",
    "\n",
    "When you set the read preference to secondary preferred, than your reads will always be routed to a secondary unless there aren't any available, in which case your reads will be routed to the primary.\n",
    "\n",
    "And finally, we have nearest, which will read from the member which has the lowest network latency.\n",
    "\n",
    "The driver determines this member by measuring network lag from the heartbeat message.\n",
    "\n",
    "Now it's super important to understand that whenever we read data from a secondary node there is a possibility that we're reading stale data.\n",
    "\n",
    "Since all write operations come into the primary, when we also read from the primary we can be guaranteed to read the latest copy of the data.\n",
    "\n",
    "This is called strong consistency.\n",
    "\n",
    "On the other hand, when we read from a secondary node we're not guaranteed to be reading from the most up-to-date version of the data.\n",
    "\n",
    "This is because data is asynchronously replicated to the secondaries as writes are still occurring on the primary.\n",
    "\n",
    "This is called eventual consistency.\n",
    "\n",
    "So anytime that the read preference isn't set to primary, which is the default, we need to make sure that our application or client is OK with reading stale data.\n",
    "\n",
    "All right, so now that we have an understanding of how we can change the way that we read our data, let's discuss when it's a good idea to do so.\n",
    "\n",
    "The two most common performance scenarios for reading from secondaries is when performing an analytics query and when doing local reads.\n",
    "\n",
    "So a great example of offloading work on a secondaries is an analytics or reporting job that needs to be run against our data.\n",
    "\n",
    "This is a great example because the queries required to do analytics are generally resource-intensive and long-running.\n",
    "\n",
    "They have a much different memory footprint than the queries associated with our operational workload.\n",
    "\n",
    "We don't want to execute these queries on the primary because the reads and writes that our application is making would be affected.\n",
    "\n",
    "So when we use this setup we get the best of both worlds.\n",
    "\n",
    "Our application continues to read the most up-to-date information just like it always has.\n",
    "\n",
    "And we're able to run our long-running and resource-intensive queries made by our analytics job without interfering with the primary's ability to handle reads and frequent writes.\n",
    "\n",
    "Now I want to point out that this is possible because our analytics job is OK with reading stale data.\n",
    "\n",
    "This is typically true for batch operations since they don't expect to be run on the latest copy.\n",
    "\n",
    "Another good use case for reading from secondaries is for local reads and geographically-distributed replica sets.\n",
    "\n",
    "In this case, we have two application servers where one is dedicated to the West coast of the United States and the other is dedicated to the East coast.\n",
    "\n",
    "In this hypothetical scenario, one of the members is located on one coast while the remaining two members reside on the other.\n",
    "\n",
    "This setup is favorable when application clients need to have low latency but are OK with reading stale data.\n",
    "\n",
    "So we've discussed the two most common best practice use cases for reading for secondaries.\n",
    "\n",
    "Now let's discuss a bad reason to read from secondaries, which is providing extra capacity for our application to read.\n",
    "\n",
    "Some people have the false notion that if the primary is overworked by writes that they can offload their reads to a secondary node.\n",
    "\n",
    "This is not the case, because, as writes come into the primary, they are replicated to the secondaries.\n",
    "\n",
    "This means that all members of a replica set have roughly the same amount of write traffic.\n",
    "\n",
    "On the other hand, if your primary is overworked with reads, and you're OK with reading stale data, you're fine to read from secondaries.\n",
    "\n",
    "All right, so just to recap, we've discussed some of the read preferences that are associated with performance, when it's a good idea to read from secondaries, such as analytics queries and local reads, and when it's a bad idea, such as trying to provide extra write throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb28993",
   "metadata": {},
   "source": [
    "# Replica Sets with Differing Indexes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cd3d73f",
   "metadata": {},
   "source": [
    "In this lesson, we're going to be talking about replicas set nodes with different indexes.\n",
    "\n",
    "Now I need to know right from the start that an architecture that relies on secondary nodes with specific indexes is not very usual, and is only useful for a handful of use cases, things like specific analytics on secondary nodes, or reporting on delayed consistency data, or even text search.\n",
    "\n",
    "Those are a few of the examples of use cases that will benefit from having specific indexes on secondary nodes alone.\n",
    "\n",
    "But again, this should not be a common practice.\n",
    "\n",
    "Once you have identified a favorable scenario, you also need to consider the requirements for this setup.\n",
    "\n",
    "These nodes should not be allowed to become primary nodes.\n",
    "\n",
    "So we should configure them either with priority 0, becoming hidden nodes, or pure simply delayed secondary nodes.\n",
    "\n",
    "This is because if a primary were to step down, then your main application could then begin communicating with replica set members whose indexes are not designed to serve its queries.\n",
    "\n",
    "This will be a very bad performance scenario for your application.\n",
    "\n",
    "Let's see this in practice using an example.\n",
    "\n",
    "Let's start by creating a replica set.\n",
    "\n",
    "I'm going to start by creating the folders or DB paths for each one of my replicas set members.\n",
    "\n",
    "I'm going to have our data r 0, 1, and 2.\n",
    "\n",
    "With the handouts for this lesson, you'll find a set of configuration files that I'll be using to launch my replica set.\n",
    "\n",
    "As you can see here, there are three different files, r0, r1, and r2, one for each of the instances of my replica set.\n",
    "\n",
    "The next step is to launch all of these instances.\n",
    "\n",
    "But before that, let's see in on which ports are we running this particular set of instances.\n",
    "\n",
    "So my r0 will be listening on port 27000, r1 on 27001, and r2 on 27002.\n",
    "\n",
    "So now that we've seen on which ports my instances are going to be listening on, I can go ahead and launch them all.\n",
    "\n",
    "So I'm going to launch my r0, my r1, and obviously my r2.\n",
    "\n",
    "If I look for the grep of all [?\n",
    "\n",
    "MongoD's ?] running, I can see that all my instances are up and running and very well, thank you so much.\n",
    "\n",
    "The configured replica set is called M201 very originally.\n",
    "\n",
    "Once all instances up and running, we can go ahead and configure this particular replica set.\n",
    "\n",
    "We are going to have one primary and two secondaries.\n",
    "\n",
    "One of the secondaries will be configured with priority 0, preventing it from becoming a primary node.\n",
    "\n",
    "So it can then select them to create a specific index that is going to be only accessible if we run queries through this particular node.\n",
    "\n",
    "So let's go ahead and connect to one of the members.\n",
    "\n",
    "In this case, I'm going to use 27000.\n",
    "\n",
    "And I'm going to set this particular configuration.\n",
    "\n",
    "The ID [INAUDIBLE] the replica set name, M201.\n",
    "\n",
    "And here on hots 2, or ID 2, and running on port 27002, I will set this member as priority 0.\n",
    "\n",
    "This will be the selected node to hold those specific indexes that will be different from the remaining nodes of my replica set.\n",
    "\n",
    "Once I have the configuration in place, I can now go ahead and initiate it.\n",
    "\n",
    "Once the configuration is up and running, I'll see that I will have my hosts and one passive node, here my priority 0 node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c026222",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16e50122",
   "metadata": {},
   "source": [
    "So now that we have our configuration set up and running, it's time for us to load some data.\n",
    "\n",
    "I'm going to connect to my replica set, passing along the seed list.\n",
    "\n",
    "And on database M201, very original again, and in collection restaurants, I'm going to load my restaurants.json, our famous file that we've been working with throughout this course.\n",
    "\n",
    "After we inserted all documents into are brand new replica set, it's then time to run some queries.\n",
    "\n",
    "Once my 1 million documents of restaurants is all loaded up, I'll go ahead and connect to my replica set.\n",
    "\n",
    "I'm going to pass on the replica set I'd name, all the seed lists.\n",
    "\n",
    "Once I'm connected to the primary, I'm going to just go ahead and use my M201 database.\n",
    "\n",
    "And I can see here that I have my collections, or my recently created restaurants collection.\n",
    "\n",
    "Great.\n",
    "\n",
    "And as you are already familiar with it, I'll have my restaurants document, where I have a name, a cuisine, stars, address, and so on.\n",
    "\n",
    "Let's say that our application wants to be able to query on the restaurant name.\n",
    "\n",
    "That's the main purpose of our application.\n",
    "\n",
    "A very lame application, I have to say, but the only thing that he needs to do is actually find elements in this restaurants collection based on the name.\n",
    "\n",
    "This will be our operational workload going forward.\n",
    "\n",
    "To do that, we will probably, as you've probably figured out already, need to create an index to support such a query so it's optimized.\n",
    "\n",
    "In this case, we only need name.\n",
    "\n",
    "So let's go ahead and create an index to do just that.\n",
    "\n",
    "Once the index is created, we will see that this index is not only available in the primary node, but also on secondary nodes.\n",
    "\n",
    "So by running this particular query, where we're looking for one of the restaurants available and explaining the output, we can see that this query is actually supported by our recently created index.\n",
    "\n",
    "That's all good, but let's connect to one of the secondaries-- in this case, the secondary, which is a passive secondary right now, priority 0-- and see if the same behavior is present.\n",
    "\n",
    "So once I'm connected to now the secondary node, as you can see here I'm connected to 27002, I will need to enable reads from secondaries.\n",
    "\n",
    "To do that, I need to express the sets label k command.\n",
    "\n",
    "Otherwise, as you all know, MongoDB does not allow you to do secondary reads by default.\n",
    "\n",
    "You need to explicitly enable that.\n",
    "\n",
    "Once I do this and run exactly the same explain command on the exact same query, I can see that the same winning plan and execution stats apply.\n",
    "\n",
    "So the same index has been used, and pretty much the same winning plan.\n",
    "\n",
    "So once I create something on the primary, it will be reflected on the secondary nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36101daa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "361b0158",
   "metadata": {},
   "source": [
    "What would actually be interesting to do is allow our system to run special analytics queries on this node alone.\n",
    "\n",
    "Queries that do not serve any operation workload therefore never going to be run on the primary node.\n",
    "\n",
    "We can do this by creating such an index on a particular secondary.\n",
    "\n",
    "For that, what we will do is just shut down our server.\n",
    "\n",
    "Once the server is down, we'll bring it up as a standalone.\n",
    "\n",
    "To do that, I need to reflect the exact same DB path.\n",
    "\n",
    "The port could potentially be different, but let's keep some consistency here.\n",
    "\n",
    "But the important thing is that we are loading a MongoD using the same previously set up r2 DB path to load this machine without a replica set configuration in place.\n",
    "\n",
    "So bringing it up as a standalone node.\n",
    "\n",
    "Once I do that, and I connect to the nodes on port 27002, I can confirm that this instance is no longer running on replica set enabled mode.\n",
    "\n",
    "Not running with --replSet.\n",
    "\n",
    "Also telling me no replication enabled, which is great.\n",
    "\n",
    "This is exactly what we wanted.\n",
    "\n",
    "So let's create a specific index to support our analytical query.\n",
    "\n",
    "In this case, we want to be able to index the full address information and the restaurant's type of cuisine.\n",
    "\n",
    "So for that, we're going to we creating an index on cuisine and all members of our address sub documents, street, city, state, and zip code.\n",
    "\n",
    "Once we do that, and as you can imagine, this is going to be a large beefy index, that is only going to serve a set of specific queries from the analytical workload.\n",
    "\n",
    "If we then run our query, that looks for example for cuisine that starts with medi for Mediterranean, and in a given address zip code range, which all zip codes start with the digit 6.\n",
    "\n",
    "If we explain this query, we will see that our recently created index is, in fact, supporting our query, and therefore being used to optimize search types of queries like this one, where we are using a regex for the zip code and another regex for cuisine.\n",
    "\n",
    "So apparently we've done our job here.\n",
    "\n",
    "So let's go ahead and shut down the server once again.\n",
    "\n",
    "Once we shut down the server, we can then relaunch our MongoD by just basically relaunching with the configuration file that it previously sets.\n",
    "\n",
    "Once we have that up and running, we can then connect again to our replica set by passing along the set list and the replica set name.\n",
    "\n",
    "Once connected to the primary, let's use our designated database, which is M201.\n",
    "\n",
    "And if we run the previous analytical query that looks for cuisine and zip code in a range using regex as we've seen before on the primary node, we will see that we are no longer using the index.\n",
    "\n",
    "So what happened?\n",
    "\n",
    "Did our index just run away scared?\n",
    "\n",
    "No, not at all.\n",
    "\n",
    "Our brave index will only be utilized if we run this query on the designated secondary node.\n",
    "\n",
    "So let's do just that.\n",
    "\n",
    "Let's go ahead and connect again to our 27002 priority 0 passive node.\n",
    "\n",
    "Once we connect it, we need again to enable reading from secondaries with sets labelled k.\n",
    "\n",
    "And if we run the query again now under a replica set, no longer in a standalone mode, we can see that our index is being used to support this particular query.\n",
    "\n",
    "Let's recap what we learned today.\n",
    "\n",
    "Again, let's reinforce that it is not a usual set up for our indexes.\n",
    "\n",
    "The main purpose of our replica set is to enable high availability.\n",
    "\n",
    "Therefore, all nodes should be configured homogeneously.\n",
    "\n",
    "It is a very useful set up for attending analytical, reporting, and text-based search kind of workloads on secondary nodes alone.\n",
    "\n",
    "You should prevent your secondaries that hold those indexes to ever become primaries.\n",
    "\n",
    "If they do, given the nature of the indexes, the expected performance of your system, especially in what right workload is concerned, will be considerably impacted.\n",
    "\n",
    "So be careful about that.\n",
    "\n",
    "But then again, great for analyticals.\n",
    "\n",
    "Not very usual, but awesome.\n",
    "\n",
    "And that's what we learned today on replica set nodes with different indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4da986",
   "metadata": {},
   "source": [
    "### 範例01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d85260ca",
   "metadata": {},
   "source": [
    "Which of the following conditions apply when creating indexes on secondaries?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "847f94d2",
   "metadata": {},
   "source": [
    "# A secondary should never be allowed to become primary\n",
    "\n",
    "True! If we were to allow it to become primary our application will experience the different set of indexes, once it becomes primary. That will potentially affect your application's expected performance.\n",
    "\n",
    "# These indexes can only be set on secondary nodes\n",
    "\n",
    "False! The indexes can be set on the primary node, however we avoid doing so to prevent any impact on the operational workload, since these only service an analytical workload.\n",
    "\n",
    "# We can create specific indexes on secondaries, even if they are not running in standalone mode\n",
    "\n",
    "False! No we first need to safely shutdown the secondary, and then restart it in standalone mode before we can create an index on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4428c0f",
   "metadata": {},
   "source": [
    "# Aggregation Pipeline on a Sharded Cluster"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e53fb4a",
   "metadata": {},
   "source": [
    "In this lesson, we're going to talk about the aggregation pipeline on a sharded cluster.\n",
    "\n",
    "Specifically we're going to discuss how it works, where operations are completed, and we'll also look into how pipelines are optimized to perform well on sharded clusters.\n",
    "\n",
    "Let's go ahead and talk about how aggregation works in a sharded cluster.\n",
    "\n",
    "When we run aggregation queries on a replica set or standalone MongoDB, it's much easier for the server to reason about because all the data is located in one place.\n",
    "\n",
    "In a sharded cluster, since our data is partitioned across different shards, this become slightly more difficult.\n",
    "\n",
    "Fortunately, MongoDB has some good tricks up its sleeve to address these issues.\n",
    "\n",
    "For example, here we have the simple aggregation query where I'm using match to find all the restaurants in New York state.\n",
    "\n",
    "I'm then using group to group by each state and then average the amount of stars for that given state.\n",
    "\n",
    "Since my shard key is on state, all of the restaurants in New York are going to be on the same shard.\n",
    "\n",
    "This means that the server is able to simply route the aggregate query to that shard, where it can run the aggregation and return the results back to the Mongo S and then back to the client.\n",
    "\n",
    "Very straightforward.\n",
    "\n",
    "Now look at this example.\n",
    "\n",
    "I've changed the query slightly so we're no longer using the match stage.\n",
    "\n",
    "So now we're talking about all documents in our sharded collection.\n",
    "\n",
    "Now since these documents are spread across multiple shards, we're going to need to do some computing on each shard, but then we'll also need to somehow get all of those results to one place, where we can merge the results together.\n",
    "\n",
    "In this case, our pipeline needs to be split.\n",
    "\n",
    "The server will determine which stages need to be executed on each shard, and then what stages need to be executed on a single shard where the results from the other shards will be merged together.\n",
    "\n",
    "Generally, merging will happen on a random shard, but there are certain circumstances where this is not the case."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f900da4",
   "metadata": {},
   "source": [
    "This isn't the case when we use $out or $facet or $lookup or $graphLookup.\n",
    "\n",
    "For these queries, the primary shard will do the work of merging our results."
   ]
  },
  {
   "cell_type": "raw",
   "id": "66d6489e",
   "metadata": {},
   "source": [
    "And this is important to understand because if we're running these operations very frequently, then one of our shards, the primary shard, will be under a lot more load than the rest of our cluster, degrading the benefits of our horizontal scaling.\n",
    "\n",
    "Under these specific circumstances, you can mitigate this issue by using a machine with more resources for your primary shard.\n",
    "\n",
    "There are also some cool optimizations that the server will try to perform that you should be aware of.\n",
    "\n",
    "Most of these will also apply when you're not sharding, but are still helpful to know.\n",
    "\n",
    "Take this example.\n",
    "\n",
    "Here we have a sort followed by a match.\n",
    "\n",
    "Now the query optimizer will move the match in front of the sort to reduce the number of documents that need to be sorted.\n",
    "\n",
    "This is particularly useful in sharded clusters when we have a split in our pipeline and when you want to reduce the amount of data being transferred over the wire to our merging shard.\n",
    "\n",
    "Similarly, we can reduce the number of documents that we need to examine by moving the limit after a skip in front of it.\n",
    "\n",
    "Notice that the query planner updates the values accordingly to support this optimization.\n",
    "\n",
    "Other than moving stages around, the server is also able to combine certain stages together.\n",
    "\n",
    "Here we're going to see where we're combining two limits into one.\n",
    "\n",
    "Same thing with skip.\n",
    "\n",
    "And finally, we're seeing the same thing with match.\n",
    "\n",
    "Now all these optimizations will automatically be attempted by the query optimizer.\n",
    "\n",
    "That being said, I think it's important to point out these optimizations so that you can more carefully consider your own aggregation pipelines and the performance implications.\n",
    "\n",
    "And that should give you a good overview of the aggregation pipeline on a sharded cluster.\n",
    "\n",
    "Let's recap what we learned.\n",
    "\n",
    "We discussed how the aggregation pipeline works on a sharded environment.\n",
    "\n",
    "And specifically we looked at where the different operations happen when we're using sharding.\n",
    "\n",
    "And finally, we looked at some optimizations that the server will try to do when running aggregation queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f537c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8419f4",
   "metadata": {},
   "source": [
    "### 範例01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "148aca63",
   "metadata": {},
   "source": [
    "Which of these statements is/are true?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dec49005",
   "metadata": {},
   "source": [
    "The only true statement was:\n",
    "\n",
    "# Creating an ascending index on a monotonically increasing value creates index keys on the right-hand side of the index\n",
    "  tree.\n",
    "  \n",
    "Let's take a look at why each of the other statements are false:\n",
    "\n",
    "# You can index multiple array fields in a single document with a single compound index.\n",
    "\n",
    "Multikey indexes allow us to index on array fields, but they do not support indexes on multiple array fields on single documents.\n",
    "\n",
    "# Covered queries can sometimes still require some of your documents to be examined.\n",
    "\n",
    "A query is covered if and only if it can be satisfied using the keys of the index.\n",
    "\n",
    "# Write concern has no impact on write latency.\n",
    "\n",
    "Different write concerns can certainly impact your write latency. Write concerns that only need acknowledgment from a primary are generally faster than ones that need acknowledgment from a majority of replica set members.\n",
    "\n",
    "# A collection scan has a logarithmic search time.\n",
    "\n",
    "No, collection scans have a linear search time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7120d6",
   "metadata": {},
   "source": [
    "### 範例02"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8954fa1d",
   "metadata": {},
   "source": [
    "Which of the following statements is/are true?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8d1d565",
   "metadata": {},
   "source": [
    "All of the following statements are true!\n",
    "\n",
    "# Indexes can decrease insert throughput.\n",
    "# Partial indexes can be used to reduce the size requirements of the indexes.\n",
    "# It's important to ensure that secondaries with indexes that differ from the primary not be eligible to become primary.\n",
    "# Indexes can be walked backwards by inverting their keys in a sort predicate.\n",
    "# It's important to ensure that your shard key has high cardinality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af5a91f",
   "metadata": {},
   "source": [
    "### 範例03"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12a732bc",
   "metadata": {},
   "source": [
    "Which of the following statements is/are true?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3f204b8",
   "metadata": {},
   "source": [
    "Let's take a closer look at each of these possibilities:\n",
    "\n",
    "# MongoDB indexes are markov trees.\n",
    "\n",
    "No, MongoDB indexes are designed using B-trees.\n",
    "\n",
    "# By default, all MongoDB user-created collections have an _id index.\n",
    "\n",
    "Yes, this is true!\n",
    "\n",
    "# Background index builds block all reads and writes to the database that holds the collection being indexed.\n",
    "\n",
    "No, foreground index builds block all reads and writes to the database that holds the collection being indexed. Background index builds don't have this limitation, but are generally slower than foreground index builds.\n",
    "\n",
    "# It's common practice to co-locate your mongos on the same machine as your application to reduce latency.\n",
    "\n",
    "Yes, this is true!\n",
    "\n",
    "# Collations can be used to create case insensitive indexes.\n",
    "\n",
    "Yes, this is true!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017e72b7",
   "metadata": {},
   "source": [
    "### 範例04"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25e76a42",
   "metadata": {},
   "source": [
    "Which of the following statements is/are true?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4447a66",
   "metadata": {},
   "source": [
    "# Indexes can solve the problem of slow queries.\n",
    "\n",
    "This is correct.\n",
    "\n",
    "# Indexes are fast to search because they're ordered such that you can find target values with few comparisons.\n",
    "\n",
    "This is correct.\n",
    "\n",
    "# Under heavy write load you should scale your read throughput by reading from secondaries.\n",
    "\n",
    "No, since writes are replicated to secondaries all members of the replica set have about the same write workload, therefore sending reads to a secondary will not scale you read throughput. However, after MongoDB 4.0 all secondary reads can read from snapshot without being blocked by replication writes.\n",
    "\n",
    "# When you index on a field that is an array it creates a partial index.\n",
    "\n",
    "No, when you index a field that is an array it creates a multikey index.\n",
    "\n",
    "# On a sharded cluster, aggregation queries using $lookup will require a merge stage on a random shard.\n",
    "\n",
    "No, $lookup, $graphLookup, $facet, and $out all require a merge stage on the primary shard, not a random shard like most other merged queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf8cc5",
   "metadata": {},
   "source": [
    "### 範例05"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d61de6ed",
   "metadata": {},
   "source": [
    "Which of the following statements is/are true?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b44c85bb",
   "metadata": {},
   "source": [
    "Let's take a moment to examine each of the choices:\n",
    "\n",
    "# Compound indexes can service queries that filter on any subset of the index keys.\n",
    "\n",
    "No, not all subsets of a index's keys can service a query. The prefix of an index's keys can service a query.\n",
    "\n",
    "# Compound indexes can service queries that filter on a prefix of the index keys.\n",
    "\n",
    "Yes, this is true!\n",
    "\n",
    "# If no indexes can be used then a collection scan will be necessary.\n",
    "\n",
    "Yes, this is true and should be avoided!\n",
    "\n",
    "# Query plans are removed from the plan cache on index creation, destruction, or server restart.\n",
    "\n",
    "Yes, this is true!\n",
    "\n",
    "# By default, the explain() command will execute your query.\n",
    "\n",
    "No, by default explain() will not execute your query. This is useful to test queries that need to run on a server under heavy load. Passing \"executionStats\" or \"allPlansExecution\" will execute the query and collect execution statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe72fbc",
   "metadata": {},
   "source": [
    "### 範例06"
   ]
  },
  {
   "cell_type": "raw",
   "id": "409eef19",
   "metadata": {},
   "source": [
    "Which of the following statements is/are true?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cdc5a22",
   "metadata": {},
   "source": [
    "# An index doesn't become multikey until a document is inserted that has an array value.\n",
    "\n",
    "This is correct!\n",
    "\n",
    "# Running performance tests from the mongo shell is an acceptable way to benchmark your database.\n",
    "\n",
    "No, you're performance tests should be as close to your production environment as possible. The mongo shell is designed for administrative tasks and ah-hoc queries, not performance benchmarks. You'd also be running in a single thread, which is unlikely how you'd be operating in production.\n",
    "\n",
    "# You can use the --wiredTigerDirectoryForIndexes option to place your indexes on a different disk than your data.\n",
    "\n",
    "This is correct!\n",
    "\n",
    "# Indexes can only be traversed forward.\n",
    "\n",
    "No, indexes can be traversed both forward and backward.\n",
    "\n",
    "# The ideal ratio between nReturned and totalKeysExamined is 1.\n",
    "\n",
    "This is correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19733fc",
   "metadata": {},
   "source": [
    "### 範例07"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c81b0680",
   "metadata": {},
   "source": [
    "Given the following indexes:\n",
    "\n",
    "{ categories: 1, price: 1 }\n",
    "{ in_stock: 1, price: 1, name: 1 }\n",
    "\n",
    "The following documents:\n",
    "\n",
    "{ price: 2.99, name: \"Soap\", in_stock: true, categories: ['Beauty', 'Personal Care'] }\n",
    "{ price: 7.99, name: \"Knife\", in_stock: false, categories: ['Outdoors'] }\n",
    "\n",
    "And the following queries:\n",
    "\n",
    "db.products.find({ in_stock: true, price: { $gt: 1, $lt: 5 } }).sort({ name: 1 })\n",
    "db.products.find({ in_stock: true })\n",
    "db.products.find({ categories: 'Beauty' }).sort({ price: 1 })\n",
    "\n",
    "Which of the following is/are true?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13847d32",
   "metadata": {},
   "source": [
    "Let's examine each of these choices:\n",
    "\n",
    "# Index #1 would provide a sort to query #3.\n",
    "\n",
    "Yes, that is correct.\n",
    "\n",
    "# Index #2 properly uses the equality, sort, range rule for query #1.\n",
    "\n",
    "No, if we were to build an index for query #1 using the equality, sort, range rule, then the index would be: { in_stock: 1, name: 1, price: 1 }.\n",
    "\n",
    "# There would be a total of 4 index keys created across all of these documents and indexes.\n",
    "\n",
    "No, there would be 5 total index keys:\n",
    "\n",
    "{ categories: 'Beauty', price: 2.99 }\n",
    "{ categories: 'Personal Care', price: 2.99 }\n",
    "{ categories: 'Outdoors', price: 7.99 }\n",
    "{ in_stock: true, price: 2.99, name: 'Soap' }\n",
    "{ in_stock: false, price: 7.99, name: 'Knife'}\n",
    "The additional index keys are due to the multikey index on categories.\n",
    "\n",
    "# Index #2 can be used by both query #1 and #2.\n",
    "\n",
    "Yes, that is correct."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
