{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837b5835",
   "metadata": {},
   "source": [
    "# What Slow Queries Look Like in an Application"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8d5eada",
   "metadata": {},
   "source": [
    "So your application is taking its first baby steps.\n",
    "\n",
    "You start getting some decent load, and with that you start to understand if the choices that you've made, in terms of hardware provisioning, schema design, and overall system configuration, meet the expected load.\n",
    "\n",
    "One of the first obvious aspects will be the response time of your system.\n",
    "\n",
    "If we have a web application, a role of thumb is that any end-to-end Application Request should be under 200 milliseconds.\n",
    "\n",
    "After that, operations become noticeably slow by the end user and impact the perceived performance of your application.\n",
    "\n",
    "This does not apply to all operations.\n",
    "\n",
    "There are several operations that are expected to take longer response times.\n",
    "\n",
    "Especially if you rely on external services to accomplish a task.\n",
    "\n",
    "Like a payment service, or a booking service, and other similar services.\n",
    "\n",
    "However, if we are building an application that relies on intermediary API, like a REST API.\n",
    "\n",
    "Or just simple, ordinary HTP request, the 200 milliseconds mark is something to consider.\n",
    "\n",
    "Keeping this in mind, any operation that takes over 100 milliseconds, in regards to MongoDB, is considered slow by default.\n",
    "\n",
    "This means that if requests to database, which tends to be where the significant amount of the work ends up happening.\n",
    "\n",
    "Having 100 milliseconds threshold allows you to understand, very quickly, that some operation might be taking longer than originally expected.\n",
    "\n",
    "Regardless of your SLA's.\n",
    "\n",
    "Your service level agreement.\n",
    "\n",
    "For these reasons, you can in fact set the threshold value to something different.\n",
    "\n",
    "This small command here that I am showing does the trick for us in MongoDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef120e3",
   "metadata": {},
   "source": [
    "<img src=\"img/78.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a541c39d",
   "metadata": {},
   "source": [
    "If you are in the financial trading business, or your use case requires high speed processing, your SLA's will probably be a few orders magnitude lower.\n",
    "\n",
    "Therefore, you can set up that threshold to what you need.\n",
    "\n",
    "The notion of slow queries, or operations for that matter, in an application will be affected by your SLA's.\n",
    "\n",
    "Any external dependency to services that you do not make part of your stack, and therefore you cannot control.\n",
    "\n",
    "The workload your application is subjected to, and the infrastructure that you set in place.\n",
    "\n",
    "All of these need to be considered.\n",
    "\n",
    "When using mongodb, we will look into this topic from three different perspectives.\n",
    "\n",
    "How much time does it take to read from the database?\n",
    "\n",
    "Where should we be looking to resolve any issues with the read response time?\n",
    "\n",
    "How much time does it take to write the database?\n",
    "\n",
    "Which components will affect the write performance?\n",
    "\n",
    "And what indicators will we follow to deal with them?\n",
    "\n",
    "Lastly, the end-to-end response analysis.\n",
    "\n",
    "This is the cumulative time taken to provide the response back to the client, when multiple different operations in the database need to be packaged together.\n",
    "\n",
    "Not the response time of a single query or write operation.\n",
    "\n",
    "In this chapter, we will use sample application, and analyze scenarios where we have to detect slow queries.\n",
    "\n",
    "Situations where the response time degrades over time.\n",
    "\n",
    "Or when a single operation impacts expected load, and some other similar situations.\n",
    "\n",
    "We will use the previously introduced tools so we can diagnose these scenarios.\n",
    "\n",
    "But in essence, this chapter is all about slowness.\n",
    "\n",
    "How to identify, measure, and correct its occurrence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eed560",
   "metadata": {},
   "source": [
    "# Response Time Degredation - Working set exceeding RAM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9bc1629",
   "metadata": {},
   "source": [
    "In this lesson, we will look into a common issue regarding applications.\n",
    "\n",
    "Response time degradation.\n",
    "\n",
    "What we mean is that the application response time, measured generally in milliseconds, will become higher as time goes by.\n",
    "\n",
    "And there's a couple of factors that will drive you to get into a situation like this.\n",
    "\n",
    "So in this lesson, we will look into how to determine the culprits, how to fix them, and more importantly, how to avoid them.\n",
    "\n",
    "There are a few scenarios that may lead to response time degradation.\n",
    "\n",
    "There are a few culprits that we might have to look into."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def47bd3",
   "metadata": {},
   "source": [
    "<img src=\"img/79.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "532dd4c8",
   "metadata": {},
   "source": [
    "Those scenarios can be, the working set exceeding RAM, queries taking longer as the data set grows, growing pool of clients, unbounded array growth, or even excessive number of indexes.\n",
    "\n",
    "We're going to be looking to a couple of those-- working set exceeding RAM and queries taking longer as the data set grows.\n",
    "\n",
    "Those are the two more common ones that we see coming in to our support queue.\n",
    "\n",
    "When are working sets, which compromises the data set that is most often accessed by our client application, requires more RAM than the server has available, or configured, one of the possible symptoms is that the application becomes slower over time and the response time of incoming requests takes longer and longer.\n",
    "\n",
    "Let's see an example.\n",
    "\n",
    "Let's start by creating our folder our dbpath, which is going to be our rtd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8feeb3",
   "metadata": {},
   "source": [
    "<img src=\"img/80.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92232120",
   "metadata": {},
   "source": [
    "I'm using our vacant box to do this, so I recommend you guys if you want to follow along to do the same.\n",
    "\n",
    "So in this dbpath we are going to be launching a new MongoD.\n",
    "\n",
    "Now, within the handouts of this lesson you will find this file, which should be placed under the shared folder, and it's called rtd.cfg.\n",
    "\n",
    "And you can see there are some instructions on how to run our MongoD.\n",
    "\n",
    "Now, as you all know by now, what we need to do is, basically, call our MongoD, pass along the file, which should be on shared, and it should be named rtd-config file.\n",
    "\n",
    "There we go.\n",
    "\n",
    "Once this is up and running we will be able to see that we have a clear MongoD up and running in our system.\n",
    "\n",
    "And there it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423eb1d4",
   "metadata": {},
   "source": [
    "<img src=\"img/81.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aeeb24e7",
   "metadata": {},
   "source": [
    "Now, if you look closely into this rtd config file, you will see that we are setting are wiredTiger size to a very small value, only 0.25% of a gigabyte.\n",
    "\n",
    "Roughly, or exactly, 256 megabytes of cache size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c92afa",
   "metadata": {},
   "source": [
    "<img src=\"img/82.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10bc2887",
   "metadata": {},
   "source": [
    "Now what we are trying to simulate here is when you do not have enough resources for your MongoD.\n",
    "\n",
    "And we will be loading some large data set that will be requiring a little bit more than this to operate correctly.\n",
    "\n",
    "Now that we have our MongoD up and running, let's go ahead and import a data set.\n",
    "\n",
    "The londonbikes data set.\n",
    "\n",
    "You should also have access to that data set through the handouts of this lesson.\n",
    "\n",
    "Once I put it up and running, you'll see that I'll start restoring that data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f259f2",
   "metadata": {},
   "source": [
    "<img src=\"img/83.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "668dc03b",
   "metadata": {},
   "source": [
    "Since we configured this instance to run only on 256 megabytes of cache size, this may take longer than expected.\n",
    "\n",
    "In normal conditions, with a bit more memory to allow us to operate correctly, this process should take a very, very small amount of time.\n",
    "\n",
    "Or not such a big amount of time.\n",
    "\n",
    "But given the fact that we are using a very tiny amount of memory, the minimum that MongoD requires, this will take a little bit longer.\n",
    "\n",
    "How can we detect that into a production environment?\n",
    "\n",
    "Let's go into a different tab and let's connect to this box.\n",
    "\n",
    "Now, if we connect to this machine using our mongostat we will see some interesting data coming along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a023a0d",
   "metadata": {},
   "source": [
    "<img src=\"img/84.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "647375ba",
   "metadata": {},
   "source": [
    "There's a bunch of information here that I might not be so much interested in, but I'm starting to see that my used memory is pretty high, in my dirty memory, the amount which is currently used, pretty low.\n",
    "\n",
    "And this might be an indicator that we don't have enough space for accommodating all the data set that we need.\n",
    "\n",
    "But let's make this a little bit more streamlined.\n",
    "\n",
    "With this instruction over here we are trimming out only the fields in the output that we are really interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8374c2",
   "metadata": {},
   "source": [
    "<img src=\"img/85.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79bba450",
   "metadata": {},
   "source": [
    "We are going to be looking to the time, the amount of memory which is dirty-- or the amount of memory which is currently being used-- the number of inserts, the queues for reads and writes, and then the active readers and writers.\n",
    "\n",
    "Once we do this we can see that we have more sane information in front of our eyes.\n",
    "\n",
    "And we can see here that our dirty amount of information and our used amount of information is quite off balance.\n",
    "\n",
    "Generally, what we see is that this value of used memory is quite smaller than it is showing right here.\n",
    "\n",
    "And it's much more balanced with the amount of dirty information.\n",
    "\n",
    "Dirty means, all the pages, or memory allocation, that is constantly being used.\n",
    "\n",
    "So if we are doing a bunch of inserts, around 8,000 or between 8,000 and 7,000, and we are only dirtying up, let's say, this small amount, but we're still using a quite significant amount allocated-- meaning that we are using this amount of information in RAM-- there's probably, or more likely, the indicator is that our total data set is exceeding the amount of memory available.\n",
    "\n",
    "We know this because we are simulating that situation.\n",
    "\n",
    "But in a production environment if you would not know exactly what was going on and if we just see a spike in the response time per application that will probably be the cause.\n",
    "\n",
    "If we don't have enough memory to allocate all of our data sets this will imply that we are paging out a lot of information.\n",
    "\n",
    "So the actual amount of dirty pages coming in is not being able to be allocated on our total amount of memory, and therefore, we will need to page a bunch of information out to be able to accommodate new incoming data.\n",
    "\n",
    "We can also see that from our queues and active readers and writers if we don't have a lot of pending jobs to do it means that our system is actually quite idle.\n",
    "\n",
    "It just processes everything that it needs to process, no big problem.\n",
    "\n",
    "The problem here is that the response time taken back to the client and say, OK, I got that and I read it, or I wrote it.\n",
    "\n",
    "It's taking a lot more time because we need to make space in our memory to actually allocate the memory, or the data, which is incoming to the server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71436f95",
   "metadata": {},
   "source": [
    "<img src=\"img/86.png\">\n",
    "<img src=\"img/87.png\">\n",
    "<img src=\"img/88.png\">\n",
    "<img src=\"img/89.png\">\n",
    "<img src=\"img/90.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d24fbc4",
   "metadata": {},
   "source": [
    "Now, if we go back and shut down the server in a controlled way by emitting the shut down server command and we edit our shared config file, and raise the level of this cache size to two gigabytes, and we run again, or relaunch back our MongoD, and try to reload the information that we got before-- the same exact data sets, we are actually going to say, we are going to drop it so we don't have any errors of, for example, unique key violations-- And if we look back into our mongostat again, we start seeing a completely different scenario where the amount of used data and the amount of dirty data are pretty much aligned.\n",
    "\n",
    "And also as you can see from this table here indicating amount of inserts per second that we might be getting, which we already finished for example, it's a clear indicator that things went way, way faster than before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da89fc4",
   "metadata": {},
   "source": [
    "# Response Time Degredation - queries taking longer as the data set grows"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16f44308",
   "metadata": {},
   "source": [
    "Our queries taking longer as data set grows.\n",
    "\n",
    "And obviously, this is the read response time that gets affected.\n",
    "\n",
    "And we need to understand why if our data set grows-- why does our queries take longer?\n",
    "\n",
    "Now, just to be clear, all queries are like that.\n",
    "\n",
    "But we should not have a response time that is linear.\n",
    "\n",
    "When this occurs, we're going to have a situation where we have big O notation of N, which basically means that as your data size grows, so does grow the response time in terms of milliseconds of any query that you do to the database.\n",
    "\n",
    "And now that's pretty bad because it will mean that as more successful you are in terms of the data you are including into your database, the longer it will take for you to query on that data.\n",
    "\n",
    "And that just means that there's no benefit in actually growing the data size.\n",
    "\n",
    "And as we all know, that's not particularly right.\n",
    "\n",
    "What we are mostly looking for is something like big O notation of logarithm of N, log of N.\n",
    "\n",
    "And this is a much more saner situation, where as your data size grows, your response time doesn't grow that much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f6241b",
   "metadata": {},
   "source": [
    "<img src=\"img/91.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22860cff",
   "metadata": {},
   "source": [
    "It keeps it in a very consistent, stable way in terms of what you can expect.\n",
    "\n",
    "No matter how much data you get, you're always going to get a good response time.\n",
    "\n",
    "This only happens if you have in place the proper indexes to respond to your queries.\n",
    "\n",
    "And this situation over here, where you have big O notation of N, you will get this when you do not have indexes that support your queries.\n",
    "\n",
    "Let's see this in action.\n",
    "\n",
    "I'm going to simulate the constant growth of data by importing a slightly larger set and running the same query after each import.\n",
    "\n",
    "Now, the first data set that I'm going to import is into our MondoDB database m312, and the one that we've been using for this course, a collection called norberto_friends.\n",
    "\n",
    "I have a lot of friends.\n",
    "\n",
    "But let's start with my 10 first friends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b72414",
   "metadata": {},
   "source": [
    "<img src=\"img/92.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b191628",
   "metadata": {},
   "source": [
    "Once my 10 friends are imported, I can go and have a look to those friends.\n",
    "\n",
    "In this friends data set, if I use my m312 database and if I show my collections here, I'll see my norberto_friends there.\n",
    "\n",
    "I can query that to see what kind of friends do I have-- all good friends, I can assure you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da47f3",
   "metadata": {},
   "source": [
    "<img src=\"img/93.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "577a2e13",
   "metadata": {},
   "source": [
    "But this is the information I can get-- an ID, a name, a created at, a city-- my lovely city of Porto-- an ID which is incremental, an email, age, phone number, and so on.\n",
    "\n",
    "For me to show you that sometimes we [INAUDIBLE] some parts of our development phase, let's say that I want to find all my friends that I made-- let's say a city like Barcelona.\n",
    "\n",
    "If you never visit Barcelona, you are missing out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468100e7",
   "metadata": {},
   "source": [
    "<img src=\"img/94.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a232a3e",
   "metadata": {},
   "source": [
    "So if I run this query, easily I can get immediately all the results corresponding to all my friends which live in Barcelona.\n",
    "\n",
    "If we want to understand while in development phase how well does this query perform, we can enable the profiler and test execution of this query.\n",
    "\n",
    "Here I'm going to set the profiler to 2, which means it captures every single operation in the system, and setting the threshold of my slow operations milliseconds value to 0.\n",
    "\n",
    "Anything that is higher than 0 will be captured in the profiler collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f3f77",
   "metadata": {},
   "source": [
    "<img src=\"img/95.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2a56b49",
   "metadata": {},
   "source": [
    "So let's do just that.\n",
    "\n",
    "Once we have that done, let's run again our query, exactly the same query.\n",
    "\n",
    "And let's look into our profiler and look for that query.\n",
    "\n",
    "Now, some of the queries, since we are capturing everything, will be collected here.\n",
    "\n",
    "But the important thing that we are collecting is this one here, where we are querying on this namespace, m312.norberto_friends.\n",
    "\n",
    "This is the filter-- and tells me how many keys examine, how many docsExamined, and some other information, like the amount of time it took, which in this case is 0 milliseconds.\n",
    "\n",
    "Now, doing a naive interpretation of this data, we might be bound to say that this data is looking pretty good.\n",
    "\n",
    "It's not going through a lot of data.\n",
    "\n",
    "It actually returns in less than 0 milliseconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3fb47",
   "metadata": {},
   "source": [
    "<img src=\"img/96.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1c6b573",
   "metadata": {},
   "source": [
    "So we can't go faster than that, right?\n",
    "\n",
    "Well, let's see how this story develops when we add more data to the data set.\n",
    "\n",
    "Let's get out of the shell.\n",
    "\n",
    "And let's import now instead of 10 friends-- since I'm very popular, I have lots and lots of friends-- let's import my 1,000 friends data set.\n",
    "\n",
    "So import that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3635d53",
   "metadata": {},
   "source": [
    "<img src=\"img/97.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36fa0c54",
   "metadata": {},
   "source": [
    "This is pretty quick.\n",
    "\n",
    "MondoDB is pretty awesome on this.\n",
    "\n",
    "So let's go and connect again.\n",
    "\n",
    "Now let's go and jump directly to our m312 database.\n",
    "\n",
    "Once we are in, we can run the same query again.\n",
    "\n",
    "If we run the same query, will we-- having grown our data set-- so the number of results that we get.\n",
    "\n",
    "But also, that will be reflected on the total time taken by the application to actual return the result set.\n",
    "\n",
    "So let's do that.\n",
    "\n",
    "As we can see, we get more results.\n",
    "\n",
    "That's fine.\n",
    "\n",
    "But if we go to our system profile again, we can see that some things have changed.\n",
    "\n",
    "Now, this query, the same query as before with a different cursor ID, obviously, has examined 629 documents.\n",
    "\n",
    "This is because we didn't fully iterate it for the full amount of documents.\n",
    "\n",
    "But it did reply in a very small amount of time, 0 milliseconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235b471",
   "metadata": {},
   "source": [
    "<img src=\"img/98.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c77d1bf",
   "metadata": {},
   "source": [
    "So again, if we are looking into this data crudely without analyzing the planSummary or execution stats, we might be led into error to think that this is pretty good.\n",
    "\n",
    "This is pretty, pretty awesome.\n",
    "\n",
    "We taking 0 seconds to reply.\n",
    "\n",
    "This is fantastic.\n",
    "\n",
    "Well, not so fast, young grasshopper, because there's more to this story.\n",
    "\n",
    "To show you exactly that, let's import a little bit more of data-- instead of 1,000, a million of my friends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f783ed87",
   "metadata": {},
   "source": [
    "<img src=\"img/99.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66266371",
   "metadata": {},
   "source": [
    "I can guarantee you I am a very popular person.\n",
    "\n",
    "So once all this data is back into our mongod, and obviously, a million is quite larger amount of information than 1,000-- once this is done, we will be looking into running the exact same query again and see how does this translate in terms of the response time-- can go back.\n",
    "\n",
    "If we run a exact same query again, looking for all of my Barcelona friends and iterating a few times over the result set, as I can see, I getting a lot of this information.\n",
    "\n",
    "So if we look into the data again and we only look for the queries that we are running with, we might be again [?\n",
    "\n",
    "led ?] to believe that our total amount of time that the application needed to wait for a response was actually 0 milliseconds again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba0fff",
   "metadata": {},
   "source": [
    "<img src=\"img/100.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d704adfd",
   "metadata": {},
   "source": [
    "Now, a way to avoid any confusion-- and let's stop our profiling for a second.\n",
    "\n",
    "Let's put it back to 0.\n",
    "\n",
    "And let's say it's back into the 100 milliseconds default level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03199990",
   "metadata": {},
   "source": [
    "<img src=\"img/101.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c93945e",
   "metadata": {},
   "source": [
    "Once we are in this situation and if we want to fully understand how much time is our queries actually taking, we need to call our explain command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4876b",
   "metadata": {},
   "source": [
    "<img src=\"img/102.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ecb5572",
   "metadata": {},
   "source": [
    "Once we run this, saying that we want to execute our query, we will see exactly the statistics needed to determine if our query is actually taking the appropriate amount of time.\n",
    "\n",
    "Now, in this case here, what we can see is that we're returning roughly 167,000 documents.\n",
    "\n",
    "And the total amount of documents is 1,001,010.\n",
    "\n",
    "And the actual execution time in milliseconds is quite high-- is around 356 milliseconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f42770d",
   "metadata": {},
   "source": [
    "<img src=\"img/103.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5cf9ac5b",
   "metadata": {},
   "source": [
    "If you all know, MongoDB will log this as a slow query.\n",
    "\n",
    "So we can see that there's been a progression in terms of the response time taken by this operation as time goes by and as we add more data to our system because frankly, this is not optimized at all.\n",
    "\n",
    "It's a collection scan.\n",
    "\n",
    "So we could do way better than this.\n",
    "\n",
    "We can also get this information from our mongo logs.\n",
    "\n",
    "If we run our Mongo logvis against our MongoDB log, say no-browser, and specifying this output as the file that we want to analyze, if we open our rtd.html from our local box, we will be able to see that that exact operation are captured in our mlogvis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43494894",
   "metadata": {},
   "source": [
    "<img src=\"img/104.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a75e8493",
   "metadata": {},
   "source": [
    "As you can see here, this operation here alone, the one that is a command that does a find and the filter equals our city of Barcelona-- it's actually taking a huge amount of time.\n",
    "\n",
    "To complete, it took around 235 milliseconds-- so a quite significant amount of time to complete a single operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d8f50",
   "metadata": {},
   "source": [
    "<img src=\"img/105.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bff5be9a",
   "metadata": {},
   "source": [
    "Now, to solve this operation, we will need to connect back to our mongod.\n",
    "\n",
    "And once in our mongod in this particular collection, where we have my friends, I will need to create an index over that field, which is my city.\n",
    "\n",
    "And once I have this index created, if I run my query again with the explain, I would see a dramatic change in terms of the execution stats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f9c70d",
   "metadata": {},
   "source": [
    "<img src=\"img/106.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31cb079",
   "metadata": {},
   "source": [
    "<img src=\"img/107.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "632fc05f",
   "metadata": {},
   "source": [
    "The total amount of time taken for the execution time is now a third of the previous one.\n",
    "\n",
    "And I have a much more optimized query.\n",
    "\n",
    "Now, obviously, we should not sit tight only on this.\n",
    "\n",
    "We probably could do way better.\n",
    "\n",
    "Let's say, for example, that what I'm showing is not at all relevant to my system.\n",
    "\n",
    "What I only need is the name of my friends.\n",
    "\n",
    "And I don't even need their underscore ID field because I'm not going to treat it at all.\n",
    "\n",
    "I can filter that out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7411c",
   "metadata": {},
   "source": [
    "<img src=\"img/108.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29c4d87f",
   "metadata": {},
   "source": [
    "So if I execute again the query with my execution stats, I'll see that there's even more benefit there.\n",
    "\n",
    "I'll be sending back a smaller amount of information.\n",
    "\n",
    "The same number of documents has been returned.\n",
    "\n",
    "But the total payload of those documents will be much, much smaller.\n",
    "\n",
    "We could even go further and say that we only want an index on city and name.\n",
    "\n",
    "And if we run the query again specifying that we want to filter on the city and only show the name, I'll even go a few steps further in terms of the actual optimization [?\n",
    "\n",
    "my ?] query and reduce even further the amount of time taken to execute this query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b931e57",
   "metadata": {},
   "source": [
    "<img src=\"img/109.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3823d9b9",
   "metadata": {},
   "source": [
    "So to recap what we learn in this lesson, make sure your working data set fits RAM.\n",
    "\n",
    "Make sure to optimize your queries by using indexes and filter responses and [INAUDIBLE] pagination of those responses.\n",
    "\n",
    "Smaller documents are better documents in general.\n",
    "\n",
    "So take that into consideration.\n",
    "\n",
    "Mongostat, Mongo logvis, and profiler are here to help.\n",
    "\n",
    "Make sure you use profiler only on development.\n",
    "\n",
    "And don't get tricked by the partial results that profiler might give you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83fd96",
   "metadata": {},
   "source": [
    "### 範例01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99ae77a7",
   "metadata": {},
   "source": [
    "Which of the following can improve an application's response time?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee55bfc3",
   "metadata": {},
   "source": [
    "All of these can improve an application's response time.\n",
    "\n",
    "# Having the correct set of indexes ensures that your queries are being answered efficiently.\n",
    "# Having enough RAM for your working set ensures that you're not touching the disk for most queries.\n",
    "# Optimizing the query results ensures that you're not fetching documents you don't require."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a6aab",
   "metadata": {},
   "source": [
    "# Throughput Drops- Long-running queries"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8001f0b",
   "metadata": {},
   "source": [
    "OK, sometimes you'll be going along, your database is looking great, and then all of a sudden things get slow.\n",
    "\n",
    "Queries are taking forever and you're not sure why.\n",
    "\n",
    "In this lesson we'll look into some of the common reasons why this might have happened."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a74c0b2",
   "metadata": {},
   "source": [
    "<img src=\"img/110.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14f5a8ee",
   "metadata": {},
   "source": [
    "We're going to look into long running queries and some possible explanations, index builds, and write contention.\n",
    "\n",
    "So the first thing you're going to want to look at is, to check to see if you're doing a lot of collection scans.\n",
    "\n",
    "Maybe your application has just deployed a new query that doesn't use an index.\n",
    "\n",
    "Or maybe that new DBA just dropped an index.\n",
    "\n",
    "How do you check this hypothesis?\n",
    "\n",
    "You have a few places to look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8a4b77",
   "metadata": {},
   "source": [
    "<img src=\"img/111.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d8b7fc8",
   "metadata": {},
   "source": [
    "So the server logs should show any long running queries.\n",
    "\n",
    "Db.currentOp will show whatever is going on right now, including long running queries.\n",
    "\n",
    "And, of course, you can always turn on the profiler.\n",
    "\n",
    "But if the issue is performance, that may not be a great idea because it's going to slow down your system even further.\n",
    "\n",
    "Now once you know it's a collection scan, you can simply build a new index.\n",
    "\n",
    "But it's also possible that you've got a new query that uses an index, but it's not using it well.\n",
    "\n",
    "For example, maybe your database is doing regex queries that are not anchored at the beginning of a string field, so it has to do a full index scan with every query.\n",
    "\n",
    "This can actually be fixed, if you anchor it to the beginning of the string, so that it only has to search a subset of the index.\n",
    "\n",
    "It's also possible that you're looking at inefficient index usage.\n",
    "\n",
    "This is where you're using an index, but maybe not using it very well.\n",
    "\n",
    "This can be harder to find because if logs capture these queries, they still show index usage.\n",
    "\n",
    "In this case, you may need to go through and explain the queries, to see how efficiently you're returning them.\n",
    "\n",
    "So that summarizes how to find and respond to long running queries.\n",
    "\n",
    "Again, if you see a sudden performance drop, it's probably because your application is fielding a new query or because someone dropped an index.\n",
    "\n",
    "If you want more details, you can find them in M-201, the MongoDB performance course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8101e4",
   "metadata": {},
   "source": [
    "# Throughput Drops- Index builds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7b72065",
   "metadata": {},
   "source": [
    "Now at the other extreme, the opposite event can also cause sudden problems, an unexpected index build.\n",
    "\n",
    "If you're building an index, your storage engine needs to create a lot of index entries.\n",
    "\n",
    "This will be a blocking operation.\n",
    "\n",
    "And depending on the size of the index, it could take time.\n",
    "\n",
    "Your server won't take rights while the index is getting built.\n",
    "\n",
    "We'll create an index.\n",
    "\n",
    "Then we'll go to the log.\n",
    "\n",
    "Here you can see the index build.\n",
    "\n",
    "And if you look at the start and stop times, you can figure out how long it took.\n",
    "\n",
    "Obviously, it didn't take long here, since I just spun up my replica set and everything was empty.\n",
    "\n",
    "If you can catch an index build in action, you can also find it with db.currentOp.\n",
    "\n",
    "But once an index build is in progress, you've already got a problem.\n",
    "\n",
    "And by the time you connect, it's probably going to be done with.\n",
    "\n",
    "But maybe you really need to build an index.\n",
    "\n",
    "And maybe you can't afford to take the performance hit while an index is getting built.\n",
    "\n",
    "What are your alternatives?\n",
    "\n",
    "They basically all come down to(歸根於) planning.\n",
    "\n",
    "We'll cover this in detail in our lesson on building indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2111dfe0",
   "metadata": {},
   "source": [
    "# Throughput Drops- Write contention"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21794fcb",
   "metadata": {},
   "source": [
    "Another issue that can come up is write contention.\n",
    "\n",
    "This is a complicated issue.\n",
    "\n",
    "So let's draw it out.\n",
    "\n",
    "When a document is updated in the WiredTiger storage engine, it uses a copy-on-write approach.\n",
    "\n",
    "First, a new version of the document is prepared.\n",
    "\n",
    "During this process, only the original document is visible to any applications.\n",
    "\n",
    "Then the update is committed by switching a pointer in a single CPU operation.\n",
    "\n",
    "And suddenly, the old version of the document is no longer available, but the new version is.\n",
    "\n",
    "This is how things work when everything's going smoothly.\n",
    "\n",
    "And it's how you can simultaneously both read from and write to the same document at the same time.\n",
    "\n",
    "You simply read from the old version while the new version is being prepared.\n",
    "\n",
    "And once the new version is in place, queries will read from that.\n",
    "\n",
    "This method, known as multiversion concurrency control, is also how the storage engine is able to achieve so much throughput.\n",
    "\n",
    "However, an issue occurs when you have multiple writers all trying to update the same document at the same time.\n",
    "\n",
    "In this case, the writers don't realize that other writes are updating the document.\n",
    "\n",
    "There aren't any locks.\n",
    "\n",
    "It just uses optimistic concurrency protocols.\n",
    "\n",
    "So what happens?\n",
    "\n",
    "Here, I'm drawing what would happen if three writers were trying to simultaneously update the same document.\n",
    "\n",
    "Each of them would begin preparing a new document on its own.\n",
    "\n",
    "They all devote system resources to the update, including CPU cycles and allocation of RAM.\n",
    "\n",
    "But only one update can happen.\n",
    "\n",
    "Maybe in this example, it's v2-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b9f28",
   "metadata": {},
   "source": [
    "<img src=\"img/112.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4704acc",
   "metadata": {},
   "source": [
    "The pointer is flipped and these versions fail.\n",
    "\n",
    "But those writes still need to occur.\n",
    "\n",
    "So if they're valid, they'll write to this version of the document.\n",
    "\n",
    "Now, in this example, two writes had to be repeated.\n",
    "\n",
    "But you can imagine a scenario where you have 20 writes and 19 of them have to be repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92fc51",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32957171",
   "metadata": {},
   "source": [
    "I've written an example script so that you can try this.\n",
    "\n",
    "What this script does is it spawns a bunch of parallel processes, 20 by default, and they all try to write the same document.\n",
    "\n",
    "Let's create a replica set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d4087",
   "metadata": {},
   "source": [
    "<img src=\"img/113.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75a66748",
   "metadata": {},
   "source": [
    "And I'm going to show a few things to.\n",
    "\n",
    "So I'm going to open up a few tabs to do things in parallel.\n",
    "\n",
    "First, I'm going to start here with the mongo shell.\n",
    "\n",
    "I want to capture some information about what I'm going to do.\n",
    "\n",
    "So let's take a snapshot of the current server status.\n",
    "\n",
    "Next, let's set up mongostat in another tab.\n",
    "\n",
    "I'll connect to just the server on port 30,000.\n",
    "\n",
    "And I just want a few fields to make it look pretty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b05dcf",
   "metadata": {},
   "source": [
    "<img src=\"img/114.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1f36a05",
   "metadata": {},
   "source": [
    "Right now, I've got a few connections just from the replica set, the mongo shell, and now mongostat.\n",
    "\n",
    "And now we're in a third tab, where we're going to run our script.\n",
    "\n",
    "Let's go to mongostat.\n",
    "\n",
    "First, you'll notice that it says there are 20 inserts.\n",
    "\n",
    "It did get 20 insert commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7697a9f",
   "metadata": {},
   "source": [
    "<img src=\"img/115.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c22c901",
   "metadata": {},
   "source": [
    "But most of them failed with the duplicate key error.\n",
    "\n",
    "Next, you can see that we've got a bunch of updates going on.\n",
    "\n",
    "And you can see that I'm dirtying a lot of my cache quickly all just to update that one single document.\n",
    "\n",
    "You can also see that I've added more than one connection per process.\n",
    "\n",
    "There are 20 processes.\n",
    "\n",
    "And we created 40 connections, even though each is just one mongo client.\n",
    "\n",
    "Each mongo client actually maintains a connection pool to the server, though that's outside of the scope of this course to discuss that in detail.\n",
    "\n",
    "I've added a link to the [INAUDIBLE] mongo FAQ in case you're interested in reading a bit more.\n",
    "\n",
    "You can also see that we're doing a ton of updates, basically as fast as our system can handle them.\n",
    "\n",
    "And once it's finished, no more writes.\n",
    "\n",
    "And our connections are back down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b93f23",
   "metadata": {},
   "source": [
    "<img src=\"img/116.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b84419",
   "metadata": {},
   "source": [
    "<img src=\"img/117.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfe94527",
   "metadata": {},
   "source": [
    "Going to the mongo shell, there's our document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102fcd5",
   "metadata": {},
   "source": [
    "<img src=\"img/118.png\">\n",
    "<img src=\"img/119.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b40bd319",
   "metadata": {},
   "source": [
    "And if I scroll up, we had 200,000 updates, 10,000 per process.\n",
    "\n",
    "Also, while we saw that we were getting a relatively high throughput if we looked at mongostat, we still have some seriously long-running operations, which we'll see in the logs.\n",
    "\n",
    "I can also check the current server status to see how many operations I've done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db0e193",
   "metadata": {},
   "source": [
    "<img src=\"img/120.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8abc6bd9",
   "metadata": {},
   "source": [
    "There are my 200,000 updates.\n",
    "\n",
    "There are my 20 attempted inserts.\n",
    "\n",
    "And there is my one insert that succeeded.\n",
    "\n",
    "Let's check out those logs.\n",
    "\n",
    "Here is my log path-- copy that.\n",
    "\n",
    "Let's jump to the bottom.\n",
    "\n",
    "So most recently, I can see my 20 processes closing their connections.\n",
    "\n",
    "But if I scroll up, here I can see a bunch of pairs of write and command entries.\n",
    "\n",
    "Note that each pair is for the same connection-- in this case, connection 71.\n",
    "\n",
    "They're both saying the same thing.\n",
    "\n",
    "I've got queries that took too long.\n",
    "\n",
    "You can see we've had 41 write conflicts, and it yielded 41 times.\n",
    "\n",
    "That's the source of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e43b0",
   "metadata": {},
   "source": [
    "<img src=\"img/121.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ea6a13c",
   "metadata": {},
   "source": [
    "Typically in circumstances where you see a lot of write conflicts, you probably would want to revise your schema.\n",
    "\n",
    "If all those processes were working on different documents, things would improve dramatically.\n",
    "\n",
    "With that then, let's go back to our shell and run our script.\n",
    "\n",
    "I've set this docPerProcess flag to avoid contention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f910c21",
   "metadata": {},
   "source": [
    "<img src=\"img/122.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc946c01",
   "metadata": {},
   "source": [
    "And when we go to mongostat, here we have our inserts-- looks like it miscounted a little.\n",
    "\n",
    "We've got our connections.\n",
    "\n",
    "We've got our updates happening.\n",
    "\n",
    "Let's wait for this to finish.\n",
    "\n",
    "Once again, we'll look at our logs.\n",
    "\n",
    "Here, if we start at the top, we've got our initial log entries.\n",
    "\n",
    "Following that, we can see a bunch of our connections spinning up.\n",
    "\n",
    "Then we see a bunch of our connections closing, and that's it.\n",
    "\n",
    "We don't see any of those long-running queries we saw before.\n",
    "\n",
    "We've eliminated the write conflicts by simulating a change in our schema from one with a lot of write conflicts to one without.\n",
    "\n",
    "What have we seen?\n",
    "\n",
    "We've looked into how you can have sudden drops in throughput.\n",
    "\n",
    "We've looked at long-running queries, index builds, and server write contention, all of which does happen in production.\n",
    "\n",
    "We've seen how to investigate the causes-- typically, using the server logs, but also with currentOp, the profiler.\n",
    "\n",
    "And we've talked a bit about how to fix these issues when they're identified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8738075",
   "metadata": {},
   "source": [
    "### 範例01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22c89df1",
   "metadata": {},
   "source": [
    "Where is the first place to look when you notice a sudden drop in throughput?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2060f74",
   "metadata": {},
   "source": [
    "# The logs are the correct place to look. There, you can find information on slow queries, as well as connections.\n",
    "# Mongotop is useful for telling you where you're spending your time, but isn't the first place to look.\n",
    "# Mongooplog is used to replay an oplog from another machine, locally, and isn't useful for this task in any way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1d38a",
   "metadata": {},
   "source": [
    "# Impact of Application Changes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ff6f759",
   "metadata": {},
   "source": [
    "In this lesson, we'll be looking into ways that you, wearing the system administrator or DB hat, has to identify potential impact of client application changes.\n",
    "\n",
    "We'll be looking into keeping track of historical monitoring data, why is that important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34869289",
   "metadata": {},
   "source": [
    "<img src=\"img/123.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "513c5d5c",
   "metadata": {},
   "source": [
    "We'll be looking to a couple of different spikes in terms of graphical information that we should look into, like watching out for spikes and connections and spikes in ops per seconds and some other few indicators for a couple of different examples that we have prepared for you, and obviously, spotting long-lasting non-indexed question.\n",
    "\n",
    "This is specifically interesting from a slow query or slowness analysis of our system.\n",
    "\n",
    "But you, if you're wearing the DB hats or system administrator hats, you might say, why do I need to care about what developers are doing?\n",
    "\n",
    "Well, let's face it.\n",
    "\n",
    "Any of this information will allow us as DBAs to sleep better at nights.\n",
    "\n",
    "That new super-hot feature that will generate thousands of instructions per second and make everyone happy needs to be well-tested with the expected load, well-configured in terms of schema design and indexes to support it.\n",
    "\n",
    "So you as a DBA need to make the necessary steps to keep your system in shipshape and Bristol fashion(井井有條).\n",
    "\n",
    "Let's start with the basics.\n",
    "\n",
    "If we want to be able to pinpoint changes in your code from our system infrastructure, we will need context and historical data.\n",
    "\n",
    "Let's see this in action using MongoDB Atlas.\n",
    "\n",
    "It will look similar from Cloud and Ops Manager.\n",
    "\n",
    "In this account of Atlas, I have the best of two worlds.\n",
    "\n",
    "We can deploy machines with the click of a button, which is great-- can select our infrastructure engines and Confirm and Deploy.\n",
    "\n",
    "But once we deploy it, we would immediately get our system monitored.\n",
    "\n",
    "In this particular example here, I already have preloaded a instance, or in this case, a replica set called Cluster0.\n",
    "\n",
    "And from there, I can go immediately into the dashboard of historical data, of monitored historical data, and I can start analyzing what happened with my system.\n",
    "\n",
    "Once we have a nice set of historical information on the behavior of our application, we can start to track down any changes that might affect our back end.\n",
    "\n",
    "And this includes watching out for spikes, spikes in connections, spikes in [INAUDIBLE] per second, and a few other types of spikes in our dashboard.\n",
    "\n",
    "Now, in this example, I have a few client applications mimicking the constant flow of requests.\n",
    "\n",
    "You can see it from the number of connections and a bunch of different metrics that I'm collecting here.\n",
    "\n",
    "Just analyzing the number of connections, I can see here that a few things happen.\n",
    "\n",
    "I had a jump here in terms of my connections, and then another jump on this one.\n",
    "\n",
    "And then they fall back again.\n",
    "\n",
    "But if we cross-checked with the number of documents and the number of app counters, well, looks like the spikes did not affect that much our system, or did they?\n",
    "\n",
    "Well, the question here is that we need to analyze all types of spikes.\n",
    "\n",
    "In this case here, I'm going to zoom in a region where I can have information on all different spikes that happened here.\n",
    "\n",
    "In this one here, my op counters and document metrics, as well, is skewing up a little bit my data.\n",
    "\n",
    "I know exactly what happened here.\n",
    "\n",
    "But if you don't, you as a DBA should immediately be asking your developers, what went wrong on this particular point in time?\n",
    "\n",
    "What that is saying, not what was wrong, but what did you guys do at this point?\n",
    "\n",
    "Now, if I want to correlate that with the number of connections established, I need to select just those-- still getting a little bit of skewed data.\n",
    "\n",
    "Let's just remove that from our view.\n",
    "\n",
    "And once we do that, we can see a total different figure.\n",
    "\n",
    "Raising the number of connections in my system-- this correlates with a bunch more work in my application that was being skewed out by other spikes in my graph.\n",
    "\n",
    "So make sure you understand that not always what we see is what actually is going on.\n",
    "\n",
    "So you need to be careful about that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b77edd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "619c7ab7",
   "metadata": {},
   "source": [
    "So in my system here, I can see that there's been a normal flow of connections, then a spike in this place here, and then another spike here.\n",
    "\n",
    "Now, connection spikes are generally correlated with something that the application is doing.\n",
    "\n",
    "New connections being established means that you might have new clients or new threads of those clients establishing connections to do some work.\n",
    "\n",
    "There are a couple of things that also can provoke this which are not that good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e44b7",
   "metadata": {},
   "source": [
    "<img src=\"img/124.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "654b6c40",
   "metadata": {},
   "source": [
    "Well, exhausting connection pools is probably an indicator and a direct correlation between how your driver's configured and how connections have you been enabling your system to work with.\n",
    "\n",
    "The drivers will try to reuse as many connections as possible by maintaining a connection pool.\n",
    "\n",
    "If those connections pools are exhausted, they will have specific configuration to allow you to establish new connections.\n",
    "\n",
    "But once the connection pool is exhausted, it will try to connect more and more and more.\n",
    "\n",
    "So seeing exactly why there's some exhaustion of your connection pools might be a good indicator from debugging perspective to see if your application is actually doing what it should be doing.\n",
    "\n",
    "There can also be occasional incorrect connections to your production environment.\n",
    "\n",
    "Let's say, for example, that we are running a long-lasting tests that inadvertently connects to your production environment.\n",
    "\n",
    "Those can also be identified in terms of connection spikes in your system.\n",
    "\n",
    "And obviously, there's the analytical workload load and reporting tools.\n",
    "\n",
    "If they are supposed to connect your system, you eventually see the spikes in the numbers of connections and some specific operations that those tools will do.\n",
    "\n",
    "Now, if your connections keep increasing but not a lot of work or workload is associated with that increase, that might be provoked by two different situations, either stale operations or incorrect credentials used by the application.\n",
    "\n",
    "In this case in particular, for us to analyze exactly what happened in terms of number of workload, we need to see if the number of connections, especially in these two setups here, [?\n",
    "\n",
    "did ?] actually correlated with more operations per second.\n",
    "\n",
    "We can see that there's a small spike in number of operations per second here, especially commands.\n",
    "\n",
    "There are some queries going on, not a lot of get mores.\n",
    "\n",
    "So there's something going on here.\n",
    "\n",
    "And there's some document metrics as well-- some operations that are related with return documents per queries.\n",
    "\n",
    "But the connections keeping increasing at a completely different pace than the number of returned documents and the number of operations per second.\n",
    "\n",
    "That might not be a very good sign.\n",
    "\n",
    "Actually, it's not at all a extremely good sign.\n",
    "\n",
    "For us to understand exactly what's going on, we also need to see the number of cursors open.\n",
    "\n",
    "Now, if I need more cursors-- and here, I can totally see that there's been an increase once we jumped the first level of number of connections in the number of cursors open.\n",
    "\n",
    "But once I increase it again a second time, no more curses were needed to be opened.\n",
    "\n",
    "So that means that the database is actually being able to fulfill the number of requests that these new connections are establishing with the same number of cursors.\n",
    "\n",
    "Now, this can be correlated with a particular situation where we have very, very, very bad queries.\n",
    "\n",
    "And for that, we need to analyze this particular metric here, which is query targeting.\n",
    "\n",
    "Query targeting will allow us to identify long-lasting non-indexed queries, which as you all know from this chapter, that's a very bad thing.\n",
    "\n",
    "So identifying them-- it's our mission.\n",
    "\n",
    "Here, I can tell you right now that this is not an ideal scenario for a couple of reasons.\n",
    "\n",
    "Let's look in more detail.\n",
    "\n",
    "The query targeting metric allows us to see two different ratios, the number of scans per returned documents-- so number of scan entries in an index-- and the number of returned documents consecutive to that number of scans.\n",
    "\n",
    "As you can see here, it's pretty much flat to almost 0-- so very little index scanning going on here.\n",
    "\n",
    "The other ratio is the scanned objects per returned documents.\n",
    "\n",
    "This gives us the information on how many documents we are scanning divided by the number of documents returned.\n",
    "\n",
    "Now, as you can see here, this is looking pretty bad.\n",
    "\n",
    "Why?\n",
    "\n",
    "Well, we are scanning a lot of different documents and returning a very small amount of those documents in return.\n",
    "\n",
    "This is basically clear indication that the queries that our clients are doing in this particular stage here are all non-indexed queries.\n",
    "\n",
    "Once you target such a thing and correlate it back with the number of connections being increasing constantly and not a lot of document metrics being returned, for example, and not a lot of different operations per second, you might want to go back to your developers and ask, why do we need so many clients, or why are we launching so many requests to our system if the total amount of work in our system is actually pretty much not significant?\n",
    "\n",
    "Now, once you have clearly identified the situations, apart from going back to your developer team and start doing some questions about why did we launch at this point and this point and again at this point so many different connections, you should also analyze the logs of these machines to pinpoint what kind of queries are being done by these clients.\n",
    "\n",
    "So you'll have much more clear information of what kind of queries are our system doing.\n",
    "\n",
    "And for that, we will need tools like mlogvis or just analyzing the logs of your mongod instance.\n",
    "\n",
    "So just to recap what we've learned, keeping an historical monitoring data-- it's quite important to analyze how the system is doing and how we can predict the system application will be doing in the future.\n",
    "\n",
    "Watching out for spikes in connections or spikes in the number of operations per second, cursors, and so on will allow us to correlate values between them.\n",
    "\n",
    "And if they out of sync, you need to come back to your developers and ask educated questions.\n",
    "\n",
    "Make sure you use mlogvis and other tools to understand exactly what those connections are doing, what those clients are doing.\n",
    "\n",
    "Do not forget that some spikes might skew out your data.\n",
    "\n",
    "So make sure you know what you're looking for.\n",
    "\n",
    "And obviously, don't forget to spot long-lasting queries or non-indexed queries to understand how those can affect your overall performance of the system and get to the bottom of why they exist and why they are present.\n",
    "\n",
    "Now, changes, if notified and controlled, will still be observed by the monitoring tools.\n",
    "\n",
    "Make sure you keep an eye on a change log of your application.\n",
    "\n",
    "Ask your team to keep you up-to-date on incoming changes.\n",
    "\n",
    "If they don't, given that you have all this information and the detailed information of mlogvis, the profiler, the explain commands, you'll be able to go back with a great deal of detail and help them solve some potential issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009fbda2",
   "metadata": {},
   "source": [
    "### 範例01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc47f5b3",
   "metadata": {},
   "source": [
    "Keeping historical monitoring data allows you to ..."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3dad7651",
   "metadata": {},
   "source": [
    "The following are correct. Keeping historical monitoring data allows you to ...\n",
    "\n",
    "# predict the normal behavior of your application.\n",
    "With historical data, you should be able to predict what your application's behavior will look like, to the database, for normal behavior.\n",
    "\n",
    "# compare your current application performance with benchmarked data.\n",
    "With historical data, you can compare current performance with historical benchmarks, a useful way of determining if your behavior is normal or not.\n",
    "\n",
    "This is incorrect:\n",
    "\n",
    "# Keeping historical monitoring data allows you to correct future problems, like a crystal ball.\n",
    "As it has been said, \"It's difficult to make predictions, especially about the future.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae1406",
   "metadata": {},
   "source": [
    "# Using Mtools to Find Slow Queries-mloginfo"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10f6b224",
   "metadata": {},
   "source": [
    "In this lesson, we'll see how Mtools can help us to identify slow queries.\n",
    "\n",
    "We'll dive deep into three tools to help you identify those slow queries, mloginfo, mplotqueries, and mlogvis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4bfb3a",
   "metadata": {},
   "source": [
    "<img src=\"img/125.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bd4db56",
   "metadata": {},
   "source": [
    "Mloginfo can be used to create a quick summary of the query shapes.\n",
    "\n",
    "Mplotqueries gives you a plot to show all the queries over time.\n",
    "\n",
    "And mlogvis is similar to mplotqueries, but will make use of your internet browser instead of using the graphical libraries needed by mplotqueries.\n",
    "\n",
    "Let's take a look.\n",
    "\n",
    "First I'll ssh into my Vagrant box.\n",
    "\n",
    "Great.\n",
    "\n",
    "Next I'll go into my shared folder.\n",
    "\n",
    "OK, all of these tools need log files and I've got one here.\n",
    "\n",
    "This is actual data from one of our customers, but the databases, collections, and field names have been replaced by animal names, while the text values are replaced by random strings.\n",
    "\n",
    "Let's start with the simplest tool.\n",
    "\n",
    "Mloginfo can be used for a lot of things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd05470",
   "metadata": {},
   "source": [
    "<img src=\"img/126.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d331b8fa",
   "metadata": {},
   "source": [
    "The most common is to get the envelope of log, basically figuring out the period of time it covers and from which host it comes.\n",
    "\n",
    "We've redacted some of the information, which is why it's unknown.\n",
    "\n",
    "However, there is also a mode with --queries where it reports all the queries by shape ordered by the total amount of time that it took."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd727ece",
   "metadata": {},
   "source": [
    "<img src=\"img/127.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69a52741",
   "metadata": {},
   "source": [
    "That means if a query took two seconds, on average, and appears one million times in the log, then the total amount of time will be 2 million seconds.\n",
    "\n",
    "By ordering the queries that way, we can easily see the most expensive query shape at the top and decide if it should be optimized.\n",
    "\n",
    "I'm afraid the text is wrapping.\n",
    "\n",
    "I had to do that in order to keep it big enough to read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a6da7",
   "metadata": {},
   "source": [
    "<img src=\"img/128.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23bb71d4",
   "metadata": {},
   "source": [
    "We can see at the top of the queries that there is an update that has a count of 1203.\n",
    "\n",
    "The update may have been run more often than this, but this is the number of times it appears in the log, because all those log entries were for updates that exceeded the threshold of a slow query, which by default is 100 milliseconds.\n",
    "\n",
    "This update takes an average of 599 milliseconds, as you can see from this mean value column.\n",
    "\n",
    "And obviously, for all these queries, we see those are not great numbers.\n",
    "\n",
    "And we'd like to look at them.\n",
    "\n",
    "It could be that there is no index on hamster.wallaby.\n",
    "\n",
    "And adding the index could improve the performance a lot.\n",
    "\n",
    "Not just for this update, but also improving the performance of the overall system.\n",
    "\n",
    "The following two lines show another query and an update that should also be optimized.\n",
    "\n",
    "The following queries and updates are only a fraction of the time of those, so they have less of an impact.\n",
    "\n",
    "That's why we care about this total time taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d4b7f1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecf6cab3",
   "metadata": {},
   "source": [
    "Now let's use mplotqueries.\n",
    "\n",
    "To do this, I'm going to have to get out of the virtual machine.\n",
    "\n",
    "I've set it up on my laptop.\n",
    "\n",
    "And it'll show us what we want to see.\n",
    "\n",
    "First, I'm going to go to a tab of my terminal that's not in the Vagrant box.\n",
    "\n",
    "I'll go into the Shared folder.\n",
    "\n",
    "And we'll look at the help documentation.\n",
    "\n",
    "This is a very rich tool and there are a lot of options.\n",
    "\n",
    "It may look overwhelming.\n",
    "\n",
    "But you can run the tool with all the defaults, and it's likely to do what you want.\n",
    "\n",
    "Once you become more accustomed to it, you can do things like change the y-axis to a logarithmic scale so outliers aren't as distorting to your view.\n",
    "\n",
    "You can create different types of graphs, for example, looking at connections instead of slow queries.\n",
    "\n",
    "And you can overlay a few of those graphs together to correlate events.\n",
    "\n",
    "Let's go ahead and run it by passing the log file to it.\n",
    "\n",
    "This tool goes deeper.\n",
    "\n",
    "And it doesn't just give you aggregates per query shape.\n",
    "\n",
    "It plots every single slow query as a dot in the picture.\n",
    "\n",
    "You may want to keep that in mind if you try to plot millions of slow queries.\n",
    "\n",
    "Reducing the scope of your log ahead of time may save you some processing time for the mplotqueries tool.\n",
    "\n",
    "Our x-axis is the timeline, while the y-axis is the value in milliseconds each query takes.\n",
    "\n",
    "And every dot in this picture is one of those slow queries.\n",
    "\n",
    "The first thing you probably want to do here is to narrow down the graph to a time frame that interests you.\n",
    "\n",
    "Again, if you know that period in advance, use mlogfilter to do it beforehand.\n",
    "\n",
    "Let's say you want to pay attention to the beginning of when we get a lot of those slow queries.\n",
    "\n",
    "Just click on the Zoom icon and draw a rectangle with your mouse.\n",
    "\n",
    "The graph is a little less crowded now.\n",
    "\n",
    "You can also get out of Zoom Mode when you're done.\n",
    "\n",
    "There seems to be a lot of green dots, which correspond to the hamster.wallaby namespace, as indicated by our legend on the left, though it may be a bit small for you to read.\n",
    "\n",
    "My apologies to those of you who are colorblind.\n",
    "\n",
    "I know there is a lot to parse.\n",
    "\n",
    "If I wanted to omit this namespace, I could simply click on the dot in the legend.\n",
    "\n",
    "However, I think I want to keep those right now.\n",
    "\n",
    "Let's look at one of those early green dots and click on it.\n",
    "\n",
    "The corresponding query from the mongod log is printed into the console where I started the tool.\n",
    "\n",
    "At this point, I can take this query and figure out if there is something wrong with the indexes or conclude that it's slow because of another issue, like an overloaded system, an underprovisioned system, et cetera.\n",
    "\n",
    "We'll go through some of those in a more complete way in other exercises.\n",
    "\n",
    "For right now, we just want to easily identify the slow queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773123a2",
   "metadata": {},
   "source": [
    "# Using Mtools to Find Slow Queries-mplotqueries"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6424f658",
   "metadata": {},
   "source": [
    "Now let's use mplotqueries.\n",
    "\n",
    "To do this, I'm going to have to get out of the virtual machine.\n",
    "\n",
    "I've set it up on my laptop.\n",
    "\n",
    "And it'll show us what we want to see.\n",
    "\n",
    "First, I'm going to go to a tab of my terminal that's not in the Vagrant box.\n",
    "\n",
    "I'll go into the Shared folder.\n",
    "\n",
    "And we'll look at the help documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d34db7",
   "metadata": {},
   "source": [
    "<img src=\"img/129.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64f4761e",
   "metadata": {},
   "source": [
    "This is a very rich tool and there are a lot of options.\n",
    "\n",
    "It may look overwhelming.\n",
    "\n",
    "But you can run the tool with all the defaults, and it's likely to do what you want.\n",
    "\n",
    "Once you become more accustomed to it, you can do things like change the y-axis to a logarithmic scale so outliers aren't as distorting to your view.\n",
    "\n",
    "You can create different types of graphs, for example, looking at connections instead of slow queries.\n",
    "\n",
    "And you can overlay a few of those graphs together to correlate events.\n",
    "\n",
    "Let's go ahead and run it by passing the log file to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827f722",
   "metadata": {},
   "source": [
    "<img src=\"img/130.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b8f3866",
   "metadata": {},
   "source": [
    "This tool goes deeper.\n",
    "\n",
    "And it doesn't just give you aggregates per query shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21235b04",
   "metadata": {},
   "source": [
    "<img src=\"img/131.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b060531",
   "metadata": {},
   "source": [
    "It plots every single slow query as a dot in the picture.\n",
    "\n",
    "You may want to keep that in mind if you try to plot millions of slow queries.\n",
    "\n",
    "Reducing the scope of your log ahead of time may save you some processing time for the mplotqueries tool.\n",
    "\n",
    "Our x-axis is the timeline, while the y-axis is the value in milliseconds each query takes.\n",
    "\n",
    "And every dot in this picture is one of those slow queries.\n",
    "\n",
    "The first thing you probably want to do here is to narrow down the graph to a time frame that interests you.\n",
    "\n",
    "Again, if you know that period in advance, use mlogfilter to do it beforehand.\n",
    "\n",
    "Let's say you want to pay attention to the beginning of when we get a lot of those slow queries.\n",
    "\n",
    "Just click on the Zoom icon and draw a rectangle with your mouse.\n",
    "\n",
    "The graph is a little less crowded now.\n",
    "\n",
    "You can also get out of Zoom Mode when you're done.\n",
    "\n",
    "There seems to be a lot of green dots, which correspond to the hamster.wallaby namespace, as indicated by our legend on the left, though it may be a bit small for you to read.\n",
    "\n",
    "My apologies to those of you who are colorblind.\n",
    "\n",
    "I know there is a lot to parse.\n",
    "\n",
    "If I wanted to omit this namespace, I could simply click on the dot in the legend.\n",
    "\n",
    "However, I think I want to keep those right now.\n",
    "\n",
    "Let's look at one of those early green dots and click on it.\n",
    "\n",
    "The corresponding query from the mongod log is printed into the console where I started the tool.\n",
    "\n",
    "At this point, I can take this query and figure out if there is something wrong with the indexes or conclude that it's slow because of another issue, like an overloaded system, an underprovisioned system, et cetera.\n",
    "\n",
    "We'll go through some of those in a more complete way in other exercises.\n",
    "\n",
    "For right now, we just want to easily identify the slow queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d1f9df",
   "metadata": {},
   "source": [
    "# Using Mtools to Find Slow Queries-mlogvis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34620854",
   "metadata": {},
   "source": [
    "Let's go back into our VM.\n",
    "\n",
    "And let's look at our last tool, mlogvis.\n",
    "\n",
    "This tool is very similar to mplotqueries.\n",
    "\n",
    "But the tool was created later and doesn't require the graphical libraries used by mplotqueries.\n",
    "\n",
    "Instead, it produces an HTML file in your local directory and points your browser to it.\n",
    "\n",
    "If the tool is unable to open the default browser in your system, you can open the file yourself from the browser.\n",
    "\n",
    "I'm in the VM in the shared folder.\n",
    "\n",
    "So I can switch out of the VM and open it on my desktop machine if I like.\n",
    "\n",
    "The nice thing about this behavior is that you can create the output file from one system with the minus minus no-browser option and move it to another one for analysis or send it to someone who doesn't have mtools installed at all because this HTML file doesn't require anything, just a browser.\n",
    "\n",
    "Similar to the other tools, we'll simply call mlogvis by passing it our mongod.log file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8a914",
   "metadata": {},
   "source": [
    "<img src=\"img/132.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b7267e",
   "metadata": {},
   "source": [
    "And now I've got this HTML file.\n",
    "\n",
    "I'll go to this on my host machine and open it up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82800af8",
   "metadata": {},
   "source": [
    "<img src=\"img/133.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59813abc",
   "metadata": {},
   "source": [
    "Just like before, we can zoom in on the graph.\n",
    "\n",
    "First, we select Zoom and then draw a rectangle on the area of interest.\n",
    "\n",
    "And like our previous tool, I can toggle the collections I'm looking at and look at individual slow queries by clicking on the event.\n",
    "\n",
    "When you do so, you can see the corresponding query in the status box at the bottom.\n",
    "\n",
    "The UI is simple and intuitive.\n",
    "\n",
    "So feel free to play with it.\n",
    "\n",
    "In summary, these tools are particularly helpful for identifying and visualizing slow queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3baf0d",
   "metadata": {},
   "source": [
    "### 範例01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7b9e846",
   "metadata": {},
   "source": [
    "Incorrect answers:\n",
    "\n",
    "# mtools has a command line tool to list the slow queries from the profiler.\n",
    "The set of tools in mtools is using the mongod log, it can't interpret results from the collections saved by \"mongod\" profiler.\n",
    "\n",
    "# Both mloginfo and mplotqueries have the ability to filter the slow queries per-collection, as well as other criteria.\n",
    "mplotqueries let you do it from its UI, however for mloginfo, you will have to rely on mlogfilter to do it before processing the file.\n",
    "\n",
    "Correct answers:\n",
    "\n",
    "# Mtools has a command line tool to list the slow queries from a mongod log.\n",
    "Mloginfo will do this, and it can be done with mplotqueries, as well.\n",
    "\n",
    "# Mtools lets you see slow queries in a two dimensional plot. \n",
    "Yes, mplotqueries and mlogvis will both allow you to do this.\n",
    "\n",
    "# Mtools is not officially supported by MongoDB. \n",
    "Mtools is an open source project that is very useful, but it is not officially supported by MongoDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f52c08",
   "metadata": {},
   "source": [
    "# Fixing Missing Indexes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a292772",
   "metadata": {},
   "source": [
    "In this lesson, we're going to be looking at different ways to add an index to a collection.\n",
    "\n",
    "When you get to building indexes, you're already pretty deep into the process.\n",
    "\n",
    "You've done a good job of figuring out that an index is missing.\n",
    "\n",
    "And now it's time to fix the problem.\n",
    "\n",
    "However, before we start, there is something we have to remind ourselves.\n",
    "\n",
    "Building an index means doing a collection scan on the collection you're adding the index to.\n",
    "\n",
    "As we all know, collection scans are evil and can have a severe impact on your performance in production.\n",
    "\n",
    "We're going to try to minimize that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee23b82",
   "metadata": {},
   "source": [
    "<img src=\"img/134.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a3bd649",
   "metadata": {},
   "source": [
    "First, we could build an index on the Primary from the shell.\n",
    "\n",
    "Building on the Primary in the foreground is easy.\n",
    "\n",
    "You simply build the index and the creation will automatically propagate to all other members of the cluster through the oplog.\n",
    "\n",
    "The index will build in the foreground, which will have the drawback of locking your collection for writes.\n",
    "\n",
    "The alternative method is to build in the background, which is a non-blocking operation for the writes, but it takes a little longer.\n",
    "\n",
    "It's usually preferred to building in the foreground for a production system, all else being equal(如果一切順利).\n",
    "\n",
    "Do note that the default is to build in the foreground.\n",
    "\n",
    "So you have to explicitly say, build in the background.\n",
    "\n",
    "If you don't want to use the shell, you can use Compass to do either of the first two methods.\n",
    "\n",
    "The fourth option is to build the index on each member separately using a rolling upgrade method that we'll see.\n",
    "\n",
    "And the fifth and final option, and by far my favorite, is to do the previous rolling upgrade procedure without getting our hands dirty using Cloud or Ops Manager.\n",
    "\n",
    "If you have a managed cluster or replica set, meaning a set of machines controlled by automation under a Cloud Manager or Ops Manager, you can let those systems add the index for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0eb8ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee2d180a",
   "metadata": {},
   "source": [
    "Talking about getting our hands dirty, let's do that right now by looking at those different methods of creating an index.\n",
    "\n",
    "First, I'm going to prepare my system.\n",
    "\n",
    "Let's prepare this setup.\n",
    "\n",
    "We're going to want a three-member replica set that starts on port 30,000 of localhost.\n",
    "\n",
    "And we'll prepare a collection with some data that we can build indexes on.\n",
    "\n",
    "We'll also build one index just to make it feel like a regular production system.\n",
    "\n",
    "Great.\n",
    "\n",
    "And let's see what our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.people.findOne()  # see what the documents look like"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60ea1241",
   "metadata": {},
   "source": [
    "In this example, we'll want to add an index on the Social Security number to our collection.\n",
    "\n",
    "First, let's look at the existing indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56070c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.people.getIndexes() # see the index we've built already"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a4e93ff",
   "metadata": {},
   "source": [
    "Great.\n",
    "\n",
    "We can see that there's no index on Social Security numbers.\n",
    "\n",
    "So let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.people.createIndex({\"ssn\":1}) # build another index"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4125efab",
   "metadata": {},
   "source": [
    "The index has been created.\n",
    "\n",
    "And the command reports the number of indexes before and after the index creation process.\n",
    "\n",
    "This looks good.\n",
    "\n",
    "The index, by the way, is also building on the secondaries.\n",
    "\n",
    "I can connect to one of those and confirm.\n",
    "\n",
    "I'm going I want to give myself permission to read from a secondary.\n",
    "\n",
    "I can connect to one of those and confirm.\n",
    "\n",
    "I'll give myself permission to read from a secondary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.slaveOk()  # permission to read from a secondary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b39a9d14",
   "metadata": {},
   "source": [
    "And here's my index on Social Security number.\n",
    "\n",
    "Next, let's go back to the primary, drop the index, and create it in the background.\n",
    "\n",
    "It looks pretty much the same as the previous operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7601c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the index, then rebuild in the background.\n",
    "db.people.dropIndex({\"ssn\":1})\n",
    "db.people.createIndex({\"ssn\":1},{\"background\":true})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e88e6102",
   "metadata": {},
   "source": [
    "So how can we tell that the index was built in the background?\n",
    "\n",
    "One way to find out is to look into the log.\n",
    "\n",
    "I'm going to let bash do the work for me.\n",
    "\n",
    "And there's our log file.\n",
    "\n",
    "Let's look at the index options.\n",
    "\n",
    "And here, the index got built in the background with background true.\n",
    "\n",
    "I can also see this if I look at the command components.\n",
    "\n",
    "And here, once again, is our createIndex command with background true.\n",
    "\n",
    "Interestingly, in the commands, I can also see my dropIndex command.\n",
    "\n",
    "A difference between the background and foreground builds is that this command will yield the collection locks more often, letting other [?\n",
    "\n",
    "rights ?] happen.\n",
    "\n",
    "Again, for that reason, you would prefer building an index in the background instead of building it in the foreground on a production system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc3509",
   "metadata": {},
   "source": [
    "# Fixing Missing Indexes- Using Compass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f5c9f",
   "metadata": {},
   "source": [
    "# Fixing Missing Indexes- Using a rolling upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af383b36",
   "metadata": {},
   "source": [
    "# Fixing Missing Indexes- Using cloud manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939aac36",
   "metadata": {},
   "source": [
    "### 範例01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6dc22ca",
   "metadata": {},
   "source": [
    "Which of the following are true?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "087519a9",
   "metadata": {},
   "source": [
    "Here are the incorrect answers:\n",
    "\n",
    "# If you have a heavy write load, it is recommended to build indexes in the foreground on the Primary.\n",
    "First, you should avoid building indexes on a Primary with a lot of traffic, and certainly not in the foreground, which blocks the writes to the collection.\n",
    "\n",
    "# Compass does not help with indexes.\n",
    "You can visualize your indexes, and even create new ones, with Compass.\n",
    "\n",
    "# mtools is another tool that can help you build indexes.\n",
    "mtools is great, but it does not help for managing indexes.\n",
    "\n",
    "Here are the correct answers:\n",
    "\n",
    "# If your system is under load, using a \"rolling upgrade\" is the recommended way to build an index.\n",
    "The rolling upgrade will prevent undue load on the primary during the index building process. You can do this either manually, or with Cloud/Ops Manager.\n",
    "\n",
    "# We can use Ops Manager to rebuild our indexes\n",
    "This is correct, Ops Manager has the functionality to rebuild and create new indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4189967a",
   "metadata": {},
   "source": [
    "### 範例02-Building an Index in the Foreground in Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f43ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這個mongo shell命令將首先切換到admin資料庫，可以看到目前mongoDB 資料庫的一些配置\n",
    "db.serverCmdLineOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39694b",
   "metadata": {},
   "source": [
    "<img src=\"img/135.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc20388",
   "metadata": {},
   "source": [
    "### 範例03-Analyse Profiler Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d48149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一步\n",
    "db.profiler_data.find({planSummary: {$ne: \"COLLSCAN\"}}).sort({ts:1}).limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二步\n",
    "db.profiler_data.find(\n",
    "    {\"ts\": {$lt: ISODate(\"2017-03-06T22:56:30.407Z\")}, \"query.filter.birthdate\":{\"$exists\":false}}\n",
    "    ).sort({ts:-1}).limit(1).pretty()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
