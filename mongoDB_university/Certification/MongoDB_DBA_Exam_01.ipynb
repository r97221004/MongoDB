{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6aa238",
   "metadata": {},
   "source": [
    "# Philosophy & Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4919c4df",
   "metadata": {},
   "source": [
    "### 問題01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5580d8e",
   "metadata": {},
   "source": [
    "You have documents stored in the invoices collection of your customers database. Which namespace are these documents stored in?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51636d32",
   "metadata": {},
   "source": [
    "(O)3. customers.invoices"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea20586f",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "A database name and a collection name combine to create a namespace. So, the database customers and the collection invoices would form the namespace customers.invoices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c568c837",
   "metadata": {},
   "source": [
    "### 問題02"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c995c4e",
   "metadata": {},
   "source": [
    "What information can be obtained from running db.serverStatus()['repl'] on a secondary replica set node?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "317702e2",
   "metadata": {},
   "source": [
    "(O)1. The name, port, and IP address of the parimary node\n",
    "(O)2. Whether the node is a primary or a secondary\n",
    "(O)3. The replica set name"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2eb925a",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "db.serverStatus()['repl'] provides information aboout the categories listed and more, such as the status of the replica set and its members. This particular command's output is almost identical to the rs.isMaster command except that it includes the \"rbid\" field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b966f87",
   "metadata": {},
   "source": [
    "# CRUD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df6663",
   "metadata": {},
   "source": [
    "### 問題01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fc8f0fd",
   "metadata": {},
   "source": [
    "Given this document:\n",
    "    \n",
    "{\n",
    "  \"title\": \"Harry Potter\",\n",
    "  \"reviews\": [1,3,5]\n",
    "}\n",
    "\n",
    "How will the following command update the reviews array field?\n",
    "\n",
    "db.books.updateOne(\n",
    "   { \"title\": \"Harry Potter\" },\n",
    "   { \"$push\": { \"reviews\": { \"$each\": [1, 2] } } }\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00c626b2",
   "metadata": {},
   "source": [
    "(O)5. add the two elements to the array \"reviews\": [1, 3, 5, 1, 2]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "716d4154",
   "metadata": {},
   "source": [
    "Correct Answer:\n",
    "\n",
    "This command applies the $push operation to the reviews array for each element of the array [1, 2].\n",
    "\"reviews\": [1, 3, 5, 1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de4be8",
   "metadata": {},
   "source": [
    "### 問題02"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4272de15",
   "metadata": {},
   "source": [
    "Which of the following statements are true of creating documents?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15cd9604",
   "metadata": {},
   "source": [
    "(O)1. We can supply an _id for the document\n",
    "(O)2. MongoDB or the client will create an _id for us if we do not supply one\n",
    "(O)3. All _id values within a single collection must be unique"
   ]
  },
  {
   "cell_type": "raw",
   "id": "842324d5",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "_id values created for us by MongoDB are of type ObjectId. We can supply an _id for the document and all _id values within a single collection must be unique given that they represent the document primary key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2ff7c2",
   "metadata": {},
   "source": [
    "### 問題03"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afef6bd6",
   "metadata": {},
   "source": [
    "Select all statements that accurately describe how the updateOne command works in conjunction with the $unset operator."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a86a997",
   "metadata": {},
   "source": [
    "(O)1. if the field does not exist, $unset does nothing\n",
    "(O)2. the specified value in the $unset expression does not impact the operation\n",
    "(O)3. the $unset operator deletes a particular field"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edb635a3",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "$unset operator deletes the field specified in the expression if it is present in the document regardless of the value that is used in the $unset expression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f5348",
   "metadata": {},
   "source": [
    "### 問題04"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43b0396c",
   "metadata": {},
   "source": [
    "You have a large collection of astronomical data. Each document in the collection has an array of planet information that looks like the following:\n",
    "\n",
    "{\n",
    "  \"planets\": [\n",
    "    { \"type\": \"Rocky\", \"earthMasses\": 1.9 },\n",
    "    { \"type\": \"Rocky\", \"earthMasses\": 0.87 },\n",
    "    { \"type\": \"Gaseous\", \"earthMasses\": 512.33 },\n",
    "  ]\n",
    "}\n",
    "\n",
    "Which array query operator should be used to find all documents with subdocuments that have planets of type \"Rocky\" and earthMasses between 0.8 and 2.7?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45474500",
   "metadata": {},
   "source": [
    "(O)1. $elemMatch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42571ccc",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "The correct answer is $elemMatch. The $elemMatch operator allows for rich query expression that will be used to test elements in an array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a4e37",
   "metadata": {},
   "source": [
    "### 問題05"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7ca1fed",
   "metadata": {},
   "source": [
    "Consider the following query:\n",
    "\n",
    "db.toys.find({ \"price\": { \"$gt\": 20, \"$lt\": 100 }})\n",
    "\n",
    "Which of the following documents could be returned by this query?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad0534d1",
   "metadata": {},
   "source": [
    "3. { \"name\": \"toy truck\", \"price\": 50 }"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c50e9275",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "{ \"name\": \"toy truck\", \"price\": 50 }\n",
    "This document will be returned, because 50 is less than 100 and greater than 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e3892",
   "metadata": {},
   "source": [
    "# Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7babd56f",
   "metadata": {},
   "source": [
    "### 問題01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c8434fb",
   "metadata": {},
   "source": [
    "Given the following query:\n",
    "    \n",
    "db.songs.find(\n",
    "  { \"seconds\": { \"$lt\": 400 }, \"genre\": \"rock\" }\n",
    ").sort(\n",
    "  { \"rating\": 1 }\n",
    ")\n",
    "\n",
    "Which index on the songs collection will be the most performant for the above query?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96d06818",
   "metadata": {},
   "source": [
    "(O)2. { \"genre\": 1, \"rating\": 1, \"seconds\": 1 }"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b25a45a",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "The correct answer is\n",
    "\n",
    "{\"genre\": 1, \"rating\": 1, \"seconds\": 1}\n",
    "\n",
    "The most efficient index for the given query should follow the equality, sort, range rule, where the compound index is built in this order for a query that employs equality, range and sort conditions in it. This rule helps to avoid inefficient operations such as a full collection scan or in memory sort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d70377",
   "metadata": {},
   "source": [
    "### 問題02"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1605d2e",
   "metadata": {},
   "source": [
    "Consider the following index in the plants collection:\n",
    "\n",
    "{ climate: 1 }\n",
    "\n",
    "Which of the following queries could use this index?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd038a42",
   "metadata": {},
   "source": [
    "(O)1. db.plants.find({ type: \"conifer\", climate: \"forest\" })\n",
    "(O)2. db.plants.find({ climate: { $in: [ \"marsh\", \"swamp\" ]}})\n",
    "(X)3. db.plants.find({ type: { $in: [ \"succlent\", \"moss\" ]}})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69d4e27c",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "db.plants.find({ climate: { $in: [ \"marsh\", \"swamp\" ] } })\n",
    "db.plants.find({ type: \"conifer\", climate: \"forest\" })\n",
    "\n",
    "These queries can use the index, because the query selector filters on the \"climate\" field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b92c1",
   "metadata": {},
   "source": [
    "### 問題03"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25f78e09",
   "metadata": {},
   "source": [
    "Given the following index:\n",
    "    \n",
    "db.books.createIndex({ \"genre\": 1, \"chapters\": 1 })\n",
    "\n",
    "what will the query plan look like for the following query?\n",
    "\n",
    "db.books.find(\n",
    "  { \"genre\": \"fiction\", \"chapters\": {\"$gt\": \"20\" } }\n",
    ").sort(\n",
    "  { \"rating\": -1 }\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6be85670",
   "metadata": {},
   "source": [
    "(O)1. IXSCAN -> FETCH -> SORT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2d84458",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Given that the index supports this query, the first stage would be IXSCAN. Therefore, any option that does not start with that needs to be discarded.\n",
    "\n",
    "Since the existing index supports the fetching of documents, it will be used before the documents are fetched. The query is also looking to get a sorted response on a field that is not indexed, so the last step will be to do the sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86d8be",
   "metadata": {},
   "source": [
    "### 問題04"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0481a682",
   "metadata": {},
   "source": [
    "Given the following query:\n",
    "    \n",
    "db.animals.find(\n",
    "  {},\n",
    "  { \"_id\": 0, \"species\": 1, \"name\": 1, \"number_of_chromosomes\": 1 }\n",
    ").sort(\n",
    "  { \"number_of_chromosomes\": -1 }\n",
    ")\n",
    "\n",
    "and the following index:\n",
    "\n",
    "{ \"number_of_chromosomes\": 1 }\n",
    "\n",
    "How will the data get retrieved, and why?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d1c6f19",
   "metadata": {},
   "source": [
    "(O)1. index scan in descending order without the need to sort"
   ]
  },
  {
   "cell_type": "raw",
   "id": "efec5e76",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "This is because when we are sorting with a single field index, we can always sort our documents either in ascending or descending order regardless of the physical ordering of the index keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a4f8a",
   "metadata": {},
   "source": [
    "### 問題05"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e056dcf9",
   "metadata": {},
   "source": [
    "We have the following index on the songs collection:\n",
    "    \n",
    "{ \"track\": 1, \"artist\": 1, \"length\": 1 }\n",
    "\n",
    "What would you expect to see in the output of this explain() query?\n",
    "\n",
    "db.songs.find(\n",
    "  { \"track\": \"Africa\", \"artist\": \"Toto\" }\n",
    ").explain(\"executionStats\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "627127c7",
   "metadata": {},
   "source": [
    "(O)3. a 1:1 ration between totalKeysExamined and nReturned"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cff810ea",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "We should see a ratio of 1:1 as we are querying on the first two fields in the index. This means that all documents can be retrieved by walking the index and returning documents in order. Avoiding the need for a collection scan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f810e",
   "metadata": {},
   "source": [
    "### 問題06"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5a6c6e8",
   "metadata": {},
   "source": [
    "When creating an index on a field with values of varying data types, how will the values be sorted in this index?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65559ad5",
   "metadata": {},
   "source": [
    "(O)2. first ordered by data type, then by value"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0691484f",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "The indexed values are grouped based on the data type representation first, that way if we are traversing the tree, we can go directly to that branch of the tree and get results in a more streamlined fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d80b66",
   "metadata": {},
   "source": [
    "### 問題07"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51ab7a95",
   "metadata": {},
   "source": [
    "What is the default mode when using explain to analyze a query?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76534c54",
   "metadata": {},
   "source": [
    "(X)1. queryPlanner\n",
    "(O)2. allPlansExecution\n",
    "(O)3. executionStats"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c294d6ed",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "The correct answer is queryPlanner. This is to allow immediate use on a server that may already be under heavy load to help the administrator determine if a query would have used an index without impacting other operations more heavily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb5651a",
   "metadata": {},
   "source": [
    "### 問題08"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9995fa6",
   "metadata": {},
   "source": [
    "Your company operates a very popular movie review and recommendation site. Queries for movie recommendations are becoming unacceptably slow. 90% of queries are for movies with a viewer rating above 7 on a 1-10 scale. What type of index is most appropriate to help speed up these queries?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "300e611b",
   "metadata": {},
   "source": [
    "(O)1. partial\n",
    "(X)2. multi-key\n",
    "(X)3. sparse\n",
    "(X)4. hashed\n",
    "(X)5. text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87bfcdf1",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "The correct answer is partial. Partial indexes are especially useful when we want to index a subset of our data, typically the most accessed portion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835dd056",
   "metadata": {},
   "source": [
    "### 問題09"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c73cd34",
   "metadata": {},
   "source": [
    "Consider the following index in the computers collection:\n",
    "    \n",
    "{ processor: 1, price: 1, memoryGB: -1 }\n",
    "\n",
    "Which of the following queries could use this index for filtering and sorting?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62a08b0d",
   "metadata": {},
   "source": [
    "(O)2. db.computers.find({ processor: \"i7\", }).sort({ price: 1 })"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b277f2cc",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "db.computers.find( { processor: \"i7\" } )\n",
    "            .sort( { price: 1 } )\n",
    "    \n",
    "This answer is correct because the processor and price form an index prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b72bf",
   "metadata": {},
   "source": [
    "### 問題10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ab5bdb1",
   "metadata": {},
   "source": [
    "Consider the following operation:\n",
    "\n",
    "db.employees.createIndex( { firstname: 1, lastname: 1 } )\n",
    "\n",
    "Which of the following are true about this operation?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f66a3f96",
   "metadata": {},
   "source": [
    "(X)1. It builds two indexes\n",
    "(O)2. It builds one index\n",
    "(X)3. mongod will throw an error"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19d3cd31",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "This operation will build a single index, on the firstname and lastname fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b0d4b",
   "metadata": {},
   "source": [
    "### 問題11"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edb96f88",
   "metadata": {},
   "source": [
    "Given a replica set and the following set of commands run from the secondary node (port 27003, node name: r3) of the replica set:\n",
    "\n",
    "use admin\n",
    "db.shutdownServer()\n",
    "\n",
    "What will be the result of the following shell command?\n",
    "\n",
    "mongod --port 27003 --dbpath /data/r3 --logpath /data/r3/r3.log --fork"
   ]
  },
  {
   "cell_type": "raw",
   "id": "569c73bf",
   "metadata": {},
   "source": [
    "(O)1. r3 will be run as a standalone node\n",
    "(X)2. r3 will get started and become part of the replica set again"
   ]
  },
  {
   "cell_type": "raw",
   "id": "444d43e8",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "This is because the command did not include the --replSet option, even though all other configurations stayed the same. All other answers are incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece25735",
   "metadata": {},
   "source": [
    "# Server Administration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147e964",
   "metadata": {},
   "source": [
    "### 問題01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33c005ef",
   "metadata": {},
   "source": [
    "Which of the following would not be found in the combined results of explain() commands run on every shard?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e14441a",
   "metadata": {},
   "source": [
    "(X)1. list of stages ran on the mongos\n",
    "(X)2. execution time of each stage on each shard\n",
    "(X)3. number of documnents read on every shard\n",
    "(X)4. name of the index, or lack of it, chosen on each shard\n",
    "(O)5. the complete list og available indexes on each shard"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f7347cf",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "You may see 2 or 3 alternate plans for a given query, however the output is not listing the whole list of available indexes, only those few that it thinks may be the best match. Run getIndexes() on your collection to see the complete list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460914b",
   "metadata": {},
   "source": [
    "### 問題02"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cdd243d",
   "metadata": {},
   "source": [
    "Consider a write operation that takes 150 milliseconds, and a database profiler that uses the default value of slowms.\n",
    "\n",
    "Which of the following profiler levels would cause the profiler to capture this operation?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2348d9f9",
   "metadata": {},
   "source": [
    "(X)1. 0\n",
    "(O)2. 1\n",
    "(O)3. 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c9ac0f7",
   "metadata": {},
   "source": [
    "注意: 0 是沒有打開， 1 的預設是 100 ms以上會被寫入，2 是全部被寫入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adddef1",
   "metadata": {},
   "source": [
    "### 問題03"
   ]
  },
  {
   "cell_type": "raw",
   "id": "451e3ff8",
   "metadata": {},
   "source": [
    "Which of the following is true for the given command line instruction:\n",
    "    \n",
    "mongod --dbpath /data/db --port 40001 --replSet RS-0 --bind_ip 10.0.0.1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c9c01d6",
   "metadata": {},
   "source": [
    "(X)1. The mongod will be accepting requests on localhost\n",
    "(O)2. The mongod will be listening for incoming requests on port 40001\n",
    "(X)3. All incoming requests need to come from a client with ip 10.0.0.10\n",
    "(X)4. The mongod will be part of a replica set with name RS-01\n",
    "(X)5. Log files will be stored in folder /data/db"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ba6f1da",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Incorrect Options:\n",
    "\n",
    "Log files will be stored in folder /data/db\n",
    "\n",
    "The log information will not be stored in a file, it will rather be sent to the standard output of the server where the mongod instance is running\n",
    "\n",
    "The mongod will be accepting requests on localhost\n",
    "\n",
    "The mongod will be accepting requests on only on ip 10.0.0.1\n",
    "\n",
    "The mongod will be part of a replica set with name RS-01\n",
    "\n",
    "The replica set name configured for this mongod is RS-0 instead of RS-01\n",
    "\n",
    "All incoming requests need to come from a client with ip 10.0.0.10\n",
    "\n",
    "Any client can connect to this instance as long as the established connection is set to 10.0.0.1. i.e.:\n",
    "\n",
    "mongod --host 10.0.0.1:40001\n",
    "\n",
    "Correct Answer:\n",
    "\n",
    "The mongod will be listening for incoming requests on port 40001\n",
    "\n",
    "The configured requests listening port (option --port) is set to 40001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53597cf1",
   "metadata": {},
   "source": [
    "### 問題04"
   ]
  },
  {
   "cell_type": "raw",
   "id": "651a3204",
   "metadata": {},
   "source": [
    "Which of the following data management processes are heavily reliant on available CPU and benefit from the abundance of such computational resource?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fa2f4c1",
   "metadata": {},
   "source": [
    "(O)1. Write operations\n",
    "(O)2. Aggregation pipeline\n",
    "(O)3. Read operations"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d5bbaa4",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Almost all MongoDB data management processes will benefit from the abundance of CPU resources. In particular due to the fact that MongoDB uses concurrency model that benefits from available CPU.\n",
    "\n",
    "- Write operations\n",
    "- Aggregation pipeline\n",
    "- Read operations\n",
    "Are operations perform better the more CPU resources are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48295daf",
   "metadata": {},
   "source": [
    "### 問題05"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38f536d0",
   "metadata": {},
   "source": [
    "Which of the following is a reason to use --wiredTigerDirectoryForIndexes or --directoryperdb?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a66a1a87",
   "metadata": {},
   "source": [
    "(X)1. To scale writes across your cluster\n",
    "(X)2. To allow for easy backup and restore of the db path\n",
    "(O)3. To parallelize IO throughput using symlinks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76af2bf5",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct answer:\n",
    "\n",
    "# To parallelize IO throughput using symlinks\n",
    "\n",
    "You can use --directoryperdb and --wiredTigerDirectoryForIndexes and symlink those directories to separate volumes to horizontally scale IO.\n",
    "\n",
    "Incorrect answers:\n",
    "\n",
    "# To allow for easy backup and restore of the db path.\n",
    "\n",
    "This is not a correct answer. Having individual directories in the db path will not help backup and restores. When restoring a set of files from a backup, you need all the files together to have a consistant state.\n",
    "\n",
    "# To scale writes across your cluster\n",
    "\n",
    "Using these options will not scale writes across a cluster. Sharding is used for scaling writes as opposed to any storage level options such as --directoryperdb or --wiredTigerDirectoryForIndexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1166dca7",
   "metadata": {},
   "source": [
    "### 問題06"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42c9994b",
   "metadata": {},
   "source": [
    "You are setting up MongoDB and have enabled authorization with the following setting in your configuration file\n",
    "\n",
    "security:\n",
    "  authorization: enabled\n",
    "  \n",
    "Which of the following statements apply?`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca23c5da",
   "metadata": {},
   "source": [
    "(X)1. Users will be forced to connect to MongoDB over SSL/TLS\n",
    "(O)2. Database users will have access to only those resources granted to them through the role-based access control system\n",
    "(O)3. Authentication will now be enforced as turning on authorization implicitly enables authentication"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c08de0ad",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "The correct answers are:\n",
    "\n",
    "# Authentication will now be enforced as turning on authorization implicitly enables authentication\n",
    "# Database users will have access to only those resources granted to them through the role-based access control system\n",
    "\n",
    "The answer Users will be forced to connect to MongoDB over SSL/TLS is incorrect. These settings are contained in the net.ssl section of the configuration document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cc8c6a",
   "metadata": {},
   "source": [
    "### 問題07"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd034fdb",
   "metadata": {},
   "source": [
    "What is the correct way to report a vulnerability to MongoDB?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52c3c4fb",
   "metadata": {},
   "source": [
    "(O)1. file a ticket in our security Jira project\n",
    "(X)2. post on the forums in MongoDB University\n",
    "(X)3. calling our support hotline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6771e0c",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "When you believe you have discovered a vulnerability you should file a ticket in our security Jira project including as much information as possible, such as contact details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1411ca3",
   "metadata": {},
   "source": [
    "### 問題08"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9c614da",
   "metadata": {},
   "source": [
    "Which of the following statements is true with regard to the localhost exemption?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c788436c",
   "metadata": {},
   "source": [
    "(O)2.You can create the first user when connecting to a newly configured mongod from localhost."
   ]
  },
  {
   "cell_type": "raw",
   "id": "de9c30dc",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "When you first connect to a newly configured mongod, you can create the first user even if authentication is on. This user can then be used to create subsequent users as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d54286",
   "metadata": {},
   "source": [
    "### 問題09"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3260751",
   "metadata": {},
   "source": [
    "Which is/are primarily authorization operation(s)?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07346a40",
   "metadata": {},
   "source": [
    "(O)1. Reading a document from the Mongo Shell\n",
    "(O)2. Creating a user in any database other than admin\n",
    "(X)3. Using an X.509 certificate"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6081d92e",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct Options:\n",
    "\n",
    "# Reading a document from the Mongo Shell\n",
    "\n",
    "Before you can issue the query to read a document, you would have been authenticated. Now the server would verify that you are authorized to access this document.\n",
    "\n",
    "# Creating a user in any database other than admin\n",
    "\n",
    "The operation of creating the user is also related to authorization. You will be authorized to add this user, if you are granted the appropriate privileges in this database.\n",
    "\n",
    "Incorrect Option:\n",
    "\n",
    "Using an X.509 certificate\n",
    "\n",
    "You can use an X.509 certificate to authenticate a machine, or a user. In both cases, the certificate helps identifying who you are, so it is an authentication operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846a14aa",
   "metadata": {},
   "source": [
    "### 問題10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce4eea21",
   "metadata": {},
   "source": [
    "In the context of a role-based access control (RBAC), which of following apply to the principle of least privilege (POLP)?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d66483d5",
   "metadata": {},
   "source": [
    "(O)3. Grant roles to users with minimal access required for their tasks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f32acf3",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Users should be granted privileges limited to the scope of the operations that they need. Most built-in roles have been designed with this principle in mind, however, you may have to create your own database custom roles to adequately provide users with the absolute necessary set of privileges they need to perform their expected tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37132d",
   "metadata": {},
   "source": [
    "### 問題11"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b95b17ab",
   "metadata": {},
   "source": [
    "What authentication mechanisms are available in the community version of MongoDB?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0c1f48a",
   "metadata": {},
   "source": [
    "(X)1. LDAP\n",
    "(O)2. X.509\n",
    "(O)3. SCRAM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe3cab77",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "The correct answers are SCRAM and X.509. LDAP, and Kerberos, are only available in the Enterprise version of MongoDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cd3fe",
   "metadata": {},
   "source": [
    "# Application Administration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0020aa",
   "metadata": {},
   "source": [
    "### 問題01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc8b0cf1",
   "metadata": {},
   "source": [
    "Consider the following audit filter:\n",
    "    \n",
    "--auditFilter '{ \"atype\": { \"$in\": [ \"createCollection\", \"dropCollection\" ] },\n",
    "                 \"param.ns\": \"test.*\"}'\n",
    "\n",
    "Which of the following operations must appear in the audit log?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b520fa6",
   "metadata": {},
   "source": [
    "(X)1. use test ->  db.dropCollection(\"games\")\n",
    "(O)2. use test ->  db.createCollection(\"games\")\n",
    "(X)3. use production -> db.createCollection(\"test\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db33452f",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "(X)use test -> db.dropCollection(\"games\")\n",
    "\n",
    "1. 根本就沒這個指令，要用 db.collection.drop()\n",
    "2. In this case both the action dropCollection and the namespace test.games are part of the audit filter. However, given the information that we have, we cannot guarantee that the collection games exists in the test database, therefore we cannot be sure that this command will be successful. The audit log will only log successful operations, operations that complete. Given that we are looking for operations that must be logged, we cannot tell for sure that this would be a successful operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537726df",
   "metadata": {},
   "source": [
    "### 問題02"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a63e28e",
   "metadata": {},
   "source": [
    "Which of the following is the correct command line option to set up an audit filter on a mongod process at startup?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3fe0272",
   "metadata": {},
   "source": [
    "(O)1. --auditFilter\n",
    "(X)2. --auditFormat\n",
    "(X)3. --logpath"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c9878c4",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "--auditFilter will allow you to specify an audit filter at startup for a mongod. You can specify your custom filter directly in the command line. The following filter audits only the createCollection and dropCollection actions:\n",
    "\n",
    "mongod --dbpath data/db --auditDestination file --auditFilter '{ atype: { $in: [ \"createCollection\", \"dropCollection\" ] } }' --auditFormat BSON --auditPath data/db/auditLog.bson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f5ebe",
   "metadata": {},
   "source": [
    "### 問題03"
   ]
  },
  {
   "cell_type": "raw",
   "id": "920cf748",
   "metadata": {},
   "source": [
    "You need to create a user \"harry\" which will use LDAP authentication. This user exists on your LDAP server. Which command would you use in the mongo shell to create this user?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa71ef26",
   "metadata": {},
   "source": [
    "(O)4. db.getSiblingDB(\"$external\").createUser({\n",
    "     user: 'harry',\n",
    "     roles: [{role: 'root', db: 'admin'}]\n",
    "})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edc825a9",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "db.getSiblingDB(\"$external\").createUser({\n",
    "     user: 'harry',\n",
    "     roles: [{role: 'root', db: 'admin'}]\n",
    "})\n",
    "\n",
    "This command will create a user in the $external database which is used for external authentication mechanisms such as LDAP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89b9a2",
   "metadata": {},
   "source": [
    "### 問題04"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2451e29",
   "metadata": {},
   "source": [
    "Given this partial config for a mongod that should be using X.509 for internal authentication:\n",
    "\n",
    "...\n",
    "security:\n",
    "  clusterAuthMode: x509\n",
    "net:\n",
    "  mode: preferSSL\n",
    "  allowInvalidCertificates: true\n",
    "  CAFile: ca.pem\n",
    "  clusterFile: member1.pem\n",
    "...\n",
    "\n",
    "Which line is wrong and should be removed or modified?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf33857c",
   "metadata": {},
   "source": [
    "(O)5. allowInvalidCertificates: true"
   ]
  },
  {
   "cell_type": "raw",
   "id": "746a477b",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct Option:\n",
    "\n",
    "allowInvalidCertificates: true\n",
    "\n",
    "First, you should avoid this option, especially on the servers. If you want to lower the SSL/TLS requirements of your servers, you are already doing it by having mode: preferSSL.\n",
    "\n",
    "Incorrect Options:\n",
    "\n",
    "All other lines are needed to enable X.509 authentication for client-server communication with the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cceaed",
   "metadata": {},
   "source": [
    "### 問題05"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83edc062",
   "metadata": {},
   "source": [
    "Let's assume an administrator created a user account with the following commands on a replica set with authorization turned on:\n",
    "\n",
    "$ mongo\n",
    "use foundation\n",
    "db.createUser({user: \"daneel.olivaw\", pwd: \"etodemerzel\", roles: [\"readWrite\"]})\n",
    "\n",
    "Which of the following methods is not valid to authenticate this user?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92dac684",
   "metadata": {},
   "source": [
    "(X)1. $ mongo test --authenticationDatabase foundation\n",
    "      > db.auth(\"daneel.olivaw\", \"etodemerzel\")\n",
    "(O)2. mongo foundation -u daneel.olivaw -p etodemerzel\n",
    "(O)3. $ mongo\n",
    "      > use foundation\n",
    "      > db.auth(\"daneel.olivaw\", \"etodemerzel\")\n",
    "(O)4. $ mongo test\n",
    "      > use foundation\n",
    "      > db.auth(\"daneel.olivaw\", \"etodemerzel\")\n",
    "(O)5. $ mongo test -u daneel.olivaw -p etodemerzel --authenticationDatabase foundation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "506b5c34",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "This is the only commands that will not authenticate correctly. After the mongo shell starts, it will land in the 'test' directory. The subsequent db.auth() command will try to authenticate in this 'test' database, while it should do it in 'foundation' to succeed. The key thing to understand here is that --authenticationDatabase only make sense if you are also providing the credentials at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e59a0",
   "metadata": {},
   "source": [
    "### 問題06"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2d8332b",
   "metadata": {},
   "source": [
    "Consider the following custom role:\n",
    "\n",
    "use admin\n",
    "db.createRole(\n",
    "  {\n",
    "   \"role\": \"intern\",\n",
    "   \"privileges\": [\n",
    "     { \"resource\": { \"db\": \"\", \"collections\": \"\" }, \"actions\": [ \"find\", \"createIndex\" ] }\n",
    "   ],\n",
    "   \"roles\": []\n",
    "  }\n",
    ")\n",
    "\n",
    "Which of the following are commands that this user-defined role is authorized to execute?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a7a6f68",
   "metadata": {},
   "source": [
    "(X)1. db.products.insert({\"name\": \"Brillo Soap\" })\n",
    "(O)2. db.customers.createIndex({\"username\": 1 })\n",
    "(O)3. db.products.find({\"name\": {\"$exists\": 1} })"
   ]
  },
  {
   "cell_type": "raw",
   "id": "430c840d",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct Options:\n",
    "\n",
    "# db.products.find({\"name\": {\"$exists\": 1} })\n",
    "# db.customers.createIndex({\"username\": 1 })\n",
    "\n",
    "Both these operations will be allowed by the intern role given that this role allows for find and createIndex actions in all collections and in all collections.\n",
    "\n",
    "# db.products.insert({\"name\": \"Brillo Soap\" })\n",
    "\n",
    "The insert action was not granted to the role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4a95b",
   "metadata": {},
   "source": [
    "### 問題07"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65e67c4f",
   "metadata": {},
   "source": [
    "Which of the following roles should you assign to a user to enable them to grant themselves any other role?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7e7f9ed",
   "metadata": {},
   "source": [
    "(O)1. dbOwner\n",
    "(O)2. userAdmin\n",
    "(X)3. __system"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d41a0f51",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "The correct answers are dbOwner and userAdmin. These are super user roles. dbOwner inherits the userAdmin role, and the userAdmin role is commonly assigned to administrative users.\n",
    "\n",
    "The __system role is used by MongoDB in normal operations. It is not and should not be commonly assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2345bd",
   "metadata": {},
   "source": [
    "### 問題08"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af660583",
   "metadata": {},
   "source": [
    "Select the resource definition that best describes all collections named products in any database."
   ]
  },
  {
   "cell_type": "raw",
   "id": "740de1e9",
   "metadata": {},
   "source": [
    "(O)5. { \"db\": \"\", \"collection\": \"products\" }"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6729a89",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "This resource definition document determines that any action over this resource will be applied on all products collections created on any database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7046e64",
   "metadata": {},
   "source": [
    "### 問題09"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18bb7de3",
   "metadata": {},
   "source": [
    "Consider the following user:\n",
    "\n",
    "{\n",
    "  \"_id\" : \"admin.matt\",\n",
    "  \"user\" : \"matt\",\n",
    "  \"db\" : \"admin\",\n",
    "  \"roles\" : [\n",
    "    {\n",
    "      \"role\" : \"userAdminAnyDatabase\",\n",
    "      \"db\" : \"admin\"\n",
    "    }\n",
    "  ],\n",
    "  \"mechanisms\" : [\n",
    "    \"SCRAM-SHA-1\",\n",
    "    \"SCRAM-SHA-256\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Which commands would let you see the privileges and actions for this user?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9942fb29",
   "metadata": {},
   "source": [
    "(X)1. db.getRole( \"userAdminAnyDatabase\" )\n",
    "(O)2. db.getRoles( { \"showPrivileges\": true, showBuiltinRoles: true } )\n",
    "(O)3. db.getUser( \"matt\", { \"showPrivileges\": true } )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a166b10",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct Options:\n",
    "\n",
    "# db.getUser( \"daniel\", { \"showPrivileges\": true } )\n",
    "This is the most straightforward way to see the privileges and actions this user can execute.\n",
    "\n",
    "# db.getRoles( { \"showPrivileges\": true, showBuiltinRoles: true } )\n",
    "This command would give you more than you need, listing all the privileges for all roles, however since our user has only one role, it is possible to locate that section in the output to see the list of privileges and actions that are allowed.\n",
    "\n",
    "Incorrect Options:\n",
    "\n",
    "db.getRole( \"userAdminAnyDatabase\" )\n",
    "This command would provide the desired information if you add the option {\"showPrivileges\": true} to it. Otherwise, the information returned is much less detailed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ecaf4e",
   "metadata": {},
   "source": [
    "### 問題10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cfcba6f",
   "metadata": {},
   "source": [
    "What security mechanisms will be enabled with the following command?\n",
    "\n",
    "$ mongod --sslMode requireSSL --sslPEMKeyFile server.pem --sslCAFile ca.pem"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcb2005f",
   "metadata": {},
   "source": [
    "(O)1. enable TLS/SSL connection\n",
    "(O)2. encrypt connection between client and server using the server.pem file\n",
    "(O)3. verify the client identity when connecting to the server using the ca.pem file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95fa9468",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "All answers are correct.\n",
    "\n",
    "--ssl Enables TLS/SSL connection.\n",
    "\n",
    "sslPEMKeyFile Specifies the .pem file that contains the mongo shell's certificate and key to present to the mongod or mongos instance.\n",
    "\n",
    "--sslCAFile Specifies the Certificate Authority (CA) .pem file for verification of the certificate presented by the mongod or the mongos instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd9546",
   "metadata": {},
   "source": [
    "### 問題11"
   ]
  },
  {
   "cell_type": "raw",
   "id": "938af4e2",
   "metadata": {},
   "source": [
    "Where does MongoDB use TLS 1.1+ encryption algorithms?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "716f69c4",
   "metadata": {},
   "source": [
    "(O)1. Transport llayer\n",
    "(X)2. Password salting\n",
    "(X)3. Encrypted storage engine"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd88f317",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "MongoDB uses TLS 1.1+ to encrypt client-server and intra-cluster network transport layer communication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7caad84",
   "metadata": {},
   "source": [
    "# Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf137c",
   "metadata": {},
   "source": [
    "### 問題01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3bf6cf9",
   "metadata": {},
   "source": [
    "You have the following information for the members field in your replicaset configuration document\n",
    "\n",
    "\"members\" : [\n",
    "  {\n",
    "    \"_id\" : 0,\n",
    "    \"host\" : \"acmecorp:27017\",\n",
    "    \"arbiterOnly\" : false,\n",
    "    \"buildIndexes\" : true,\n",
    "    \"hidden\" : false,\n",
    "    \"priority\" : 1,\n",
    "    \"tags\" : {\n",
    "\n",
    "    },\n",
    "    \"slaveDelay\" : NumberLong(0),\n",
    "    \"votes\" : 1\n",
    "  },\n",
    "  {\n",
    "    \"_id\" : 1,\n",
    "    \"host\" : \"acmecorp:27018\",\n",
    "    \"arbiterOnly\" : false,\n",
    "    \"buildIndexes\" : true,\n",
    "    \"hidden\" : true,\n",
    "    \"priority\" : 0,\n",
    "    \"tags\" : {\n",
    "\n",
    "    },\n",
    "    \"slaveDelay\" : NumberLong(3600),\n",
    "    \"votes\" : 0\n",
    "  },\n",
    "  {\n",
    "    \"_id\" : 2,\n",
    "    \"host\" : \"acmecorp:27019\",\n",
    "    \"arbiterOnly\" : false,\n",
    "    \"buildIndexes\" : true,\n",
    "    \"hidden\" : false,\n",
    "    \"priority\" : 1,\n",
    "    \"tags\" : {\n",
    "\n",
    "    },\n",
    "    \"slaveDelay\" : NumberLong(0),\n",
    "    \"votes\" : 1\n",
    "  }\n",
    "],\n",
    "\n",
    "Select the following true statements."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b70e0fa1",
   "metadata": {},
   "source": [
    "(O)1. If member 0 or member 2 goes down, no new primary will be elected\n",
    "(X)2. Member 2 is more likely than member 0 to become primary\n",
    "(O)3. Member 1 can never become the primary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b96a2809",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "The correct answers are:\n",
    "\n",
    "# If member 0 or member 2 goes down, no new primary will be elected\n",
    "This is because of the hidden node, member 1! Since it cannot vote, there would be no majority to elect a new primary if member 0 or member 2 goes down. An important consideration to keep in mind.\n",
    "\n",
    "# Member 1 can never become the primary\n",
    "Because member 1 has a slaveDelay, it can never become the primary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ec6bf",
   "metadata": {},
   "source": [
    "### 問題02"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be6ddd74",
   "metadata": {},
   "source": [
    "You have an application that does not need to have the most up to date data, however you want to ensure that network latency between your client application and the member it is reading from is minimized. Which read preference should you set to achieve this goal?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72ee0ec8",
   "metadata": {},
   "source": [
    "(X)1. primaryPreferred\n",
    "(O)2. nearest\n",
    "(X)3. Secondary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f620eaf5",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Incorrect Options:\n",
    "\n",
    "# primaryPreferred\n",
    "primaryPreferred Will read from a primary unless the primary is unavailable for any reason.\n",
    "In which case, the client will read from a secondary.\n",
    "\n",
    "# Secondary\n",
    "Secondary Will always read from a secondary node.\n",
    "\n",
    "Correct Option\n",
    "\n",
    "# nearest\n",
    "nearest is the correct answer as it will read from the node with the lowest network latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3edbb9",
   "metadata": {},
   "source": [
    "### 問題03"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b5fe40c",
   "metadata": {},
   "source": [
    "In a 3-node replica set, which of the following write concerns are more durable than the default?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07630056",
   "metadata": {},
   "source": [
    "(X)1. w: 0\n",
    "(X)2. w: 1\n",
    "(O)3. w: 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7cad083",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct answers:\n",
    "\n",
    "# w: 2\n",
    "The default write concern is w: 1, and waiting for 2 nodes to apply a write is more durable than only waiting for 1 node to apply it.\n",
    "\n",
    "Incorrect answers:\n",
    "\n",
    "# w: 1\n",
    "This is already the default write concern in MongoDB, so it does not represent a higher durability than the default.\n",
    "\n",
    "# w: 0\n",
    "This will not wait for any nodes to apply a write before sending an acknowledgement, so it is a less durable write than the default value of w: 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ce6c6",
   "metadata": {},
   "source": [
    "### 問題04"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3bbe9244",
   "metadata": {},
   "source": [
    "When connected to a replica set secondary node using the mongo shell, which of the following set of commands will return successfully?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "524c99bf",
   "metadata": {},
   "source": [
    "(O)1. rs.slaveOk(); db.adminCommand({listDatabases: 1})\n",
    "(X)2. rs.slaveOk(); db.newcollection.insert({\"name\": \"Nathan\"})\n",
    "(O)3. db.isMaster()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb890574",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Incorrect Option:\n",
    "\n",
    "# rs.slaveOk(); db.newcollection.insert({\"name\": \"Nathan\"})\n",
    "This command will fail since write operations cannot be performed in secondary nodes of a replica set.\n",
    "\n",
    "Correct Options:\n",
    "\n",
    "# rs.slaveOk(); db.adminCommand({listDatabases: 1})\n",
    "Reads on secondary nodes need to be explicit. In the mongo shell we enable reads on secondary nodes by preceding a read command with rs.slaveOk(), therefore this db.adminCommand({listDatabases: 1}) would return successfully.\n",
    "\n",
    "# db.isMaster()\n",
    "The db.isMaster() returns a document that describes the role of the mongod instance to which we are connected. This command can be run on all nodes, regardless of the node current replica set role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649455e0",
   "metadata": {},
   "source": [
    "### 問題05"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ec6652e",
   "metadata": {},
   "source": [
    "Consider a write operation performed against a replica set with write concern w: 1.\n",
    "After changing the write concern to w: \"majority\", this operation is:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30b464a4",
   "metadata": {},
   "source": [
    "(O)1. more likely to block other operations in the application\n",
    "(O)2. less likely to be rolled back\n",
    "(O)3. more likely to take longer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9971188a",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "All three of these options are true.\n",
    "\n",
    "The write operation is more likely to take longer because the server has to wait for acknowledgement from a majority of nodes in the replica set. This typically takes longer than waiting for only one acknowledgement.\n",
    "\n",
    "It is also less likely to be rolled back, because even if the primary node shuts down, there is at least one other node that's applied the write operation.\n",
    "\n",
    "And finally, it is more likely to block other operations in the application, because the write operation will take longer than the same operation issued with write concern w: 1. However, this can be remedied by issuing a wtimeout that satisfies the application's need for timely acknowledgement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e234d06",
   "metadata": {},
   "source": [
    "### 問題06"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fec4138",
   "metadata": {},
   "source": [
    "Which command would you use to add an arbiter to an existing replica set on host mongo2, running on port 27017?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "862abb98",
   "metadata": {},
   "source": [
    "(X)1. rs.reconfig({\"host\": \"mongo2\", \"port\": 27017, \"arbiter\": \"true\"})\n",
    "(X)2. rs.add(\"mongo2:27017, arb: true\")\n",
    "(O)3. rs.addArb(\"mongo2:27107\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da00bf25",
   "metadata": {},
   "source": [
    "3 是對的沒問題\n",
    "2 應該改成 rs.add( { host: \"mongo2:27017\", arbiterOnly: true } )\n",
    "1 Is not a valid command, you need to pass a full configuration document to rs.reconfig()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec11205",
   "metadata": {},
   "source": [
    "### 問題07"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef28a37b",
   "metadata": {},
   "source": [
    "Which collections in the local database are replicated by secondary nodes in a MongoDB replica set?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed216ccd",
   "metadata": {},
   "source": [
    "(X)1. system.replSet\n",
    "(O)2. oplog.rs\n",
    "(X)3. startup_log"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d51a256e",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct Answer\n",
    "\n",
    "# oplog.rs\n",
    "The oplog collection is replicated by secondary nodes to perform any new operations. This is the only collection in the local database that is replicated by secondary nodes.\n",
    "Incorrect Answers\n",
    "\n",
    "# system.replSet\n",
    "This collection stores information on the replica set, but it is not replicated by secondaries.\n",
    "\n",
    "# startup_log\n",
    "This collection contains the options used to start the mongod process. It is not replicated by secondaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11edf830",
   "metadata": {},
   "source": [
    "### 問題08"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ceeb638",
   "metadata": {},
   "source": [
    "Which are valid read concerns in MongoDB?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed3f4d63",
   "metadata": {},
   "source": [
    "(O)1. majority\n",
    "(O)2. linearizable\n",
    "(O)3. local"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37e1bdce",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct Options:\n",
    "\n",
    "All choices are correct.\n",
    "\n",
    "majority read concern reads data that was written to a majority of nodes.\n",
    "\n",
    "local read concern reads data at least written to the primary. It is the default read concern\n",
    "\n",
    "linearizable read concern reads data written to a majority of nodes prior to the read request, and unlike majority will wait for pending write operations to complete that would modify the document(s) requested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf2784f",
   "metadata": {},
   "source": [
    "### 問題09"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15fcf4ca",
   "metadata": {},
   "source": [
    "You need to set up a replica set. Which command(s) do you need to run to set up the replica set and add 2 other nodes?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5279b951",
   "metadata": {},
   "source": [
    "(O)1. rs.add(node2); rs.add(node3); rs.initiate()\n",
    "(X)2. rs.initiate(); rs.add(node2); rs.reconfig()\n",
    "(O)3. rs.initiate(); rs.add(node2); rs.add(node3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3257758",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "rs.initiate() must be run first in order to initialize the replica set, and rs.reconfig() should only be run if you are modifying the replica configuration file directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5775346f",
   "metadata": {},
   "source": [
    "### 問題10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ecfd0ff",
   "metadata": {},
   "source": [
    "Which of the following commands can be used to retrieve the size of the oplog in a MongoDB replica set?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49147e9f",
   "metadata": {},
   "source": [
    "(O)1. rs.printReplicationInfo()\n",
    "(X)2. db.startup_log.stats()\n",
    "(O)3. db.oplog.rs.stats()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26043af3",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct Answers\n",
    "\n",
    "# rs.printReplicationInfo()\n",
    "This will return the size of the oplog in both gigabytes and minutes.\n",
    "\n",
    "# db.oplog.rs.stats()\n",
    "This will return all available stats on the oplog.rs collection.\n",
    "\n",
    "Incorrect Answer\n",
    "\n",
    "# db.startup_log.stats()\n",
    "This will return all available stats on the startup_log collection, which does not tell us about the oplog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da780f86",
   "metadata": {},
   "source": [
    "# Sharding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6834319",
   "metadata": {},
   "source": [
    "### 問題01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50b3aabd",
   "metadata": {},
   "source": [
    "In order to store data in a sharded cluster in MongoDB, you must have:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e772275c",
   "metadata": {},
   "source": [
    "(O)1. config servers\n",
    "(O)2. at least one shard\n",
    "(O)3. a mongos process"
   ]
  },
  {
   "cell_type": "raw",
   "id": "522c4193",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "All three of these options are true.\n",
    "\n",
    "In order to start a sharded cluster in MongoDB, you must have config servers, which will store chunk metadata and user information, a mongos process to route requests to the correct shards, and at least one shard to store data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1842e",
   "metadata": {},
   "source": [
    "### 問題02"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcb43f93",
   "metadata": {},
   "source": [
    "You have sharded the collection users with the following command:\n",
    "\n",
    "sh.shardCollection(\n",
    "  \"app.users\",\n",
    "  { \"userId\": 1, \"last_login\": 1, \"isActive\": 1 }\n",
    ")\n",
    "\n",
    "Now you are tasked to help a colleague define which query predicate they should use to address a given critical, low latency feature of the application. Which of the following query predicates should they use to implement the feature? (All of the following options are valid to implement the feature)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49e3cc52",
   "metadata": {},
   "source": [
    "(X)1. { \"isActive\": true }\n",
    "(O)2. {\"userId\": <String>, \"last_login\": {\"$gte\": <ISODate> } }\n",
    "(X)3. { \"name\": { \"$exists\": 1 }}\n",
    "(X)4. { \"name\": <String>, \"last_login\": { \"$lt\": <ISODate> }}\n",
    "(X)5. { \"last_login\": { \"$lt\": <IsODate> }, \"isActive\": false }"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5125eaa5",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct Option:\n",
    "\n",
    "{\"userId\": <String>, \"last_login\": {\"$gte\": <ISODate> } }\n",
    "\n",
    "In case of equally fulfilling query predicates for the feature at hand, developers should use the most optimized query possible. Given that we are dealing with a sharded query, the choice should always fall on routed queries, queries that can be serviced by the shard key, which in this case can only be satisfied by this option\n",
    "\n",
    "All other options would be scattered gathered queries, which are less performant.\n",
    "\n",
    "要使用 targeted queries，要使用 prefix of the shard key。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767521b4",
   "metadata": {},
   "source": [
    "### 問題03"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3c88cf5",
   "metadata": {},
   "source": [
    "You have the following operational requirements and benchmarks within your organization:\n",
    "\n",
    "# Full backup or restore times can never exceed 20 minutes\n",
    "# Client read and writes can never exceed 95 ms latency\n",
    "# The current machines are provisioned with 16GB of RAM and 4TB disk space\n",
    "# Backup and recovery times with 1.5TB took 15 minutes each, respectively\n",
    "# The next available server size is 32GB RAM and 8TB disk space with a monthly cost increase of 10% for double the\n",
    "  performance.\n",
    "\n",
    "The application is expected to grow in users and resource consumption at a rate of 7% monthly. Consider the following scenarios that represent different applications:\n",
    "\n",
    "Scenario A: Your replica set nodes are consuming 10% of available RAM and your database is 200GB, and a new law was passed\n",
    "            in the EU requiring your organization to store certain data about EU customers within the EU. 66% of your users\n",
    "            are location within the Americas with an average read and write response time of 90ms.\n",
    "Scenario B: Your replica set nodes are consuming 90% of available RAM and your database is 400GB\n",
    "Scenario C: Your replica set nodes are consuming 60% of a available RAM and your database is 2.8TB\n",
    "\n",
    "Select the scenario(s) above where sharding should be considered."
   ]
  },
  {
   "cell_type": "raw",
   "id": "42b6b8e7",
   "metadata": {},
   "source": [
    "(O)1. A\n",
    "(x)2. B\n",
    "(O)3. C"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25a5995f",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "The correct answers are scenarios A and C.\n",
    "\n",
    "Scenario C: While the cost of vertically scaling is acceptable, we're already using 2.8TB of disk space. Considering we benchmarked a backup operation and restore operation at 15 minutes each with 1.5TB of data, we're already beyond our SLAs. Sharding should have already been considered much sooner.\n",
    "\n",
    "Scenario A: This is a real world scenario that zone sharding was designed to address, and depending on the type of information your organization stores you may be subject to regulations requiring you to store data in a specific geographical area. Considering the majority of users are located in the Americas approaching SLA limits, sharding is more appropriate here than relocating all data to the EU.\n",
    "\n",
    "Let's discuss the incorrect answer.\n",
    "\n",
    "In scenario B, we're consuming 10% of available disk (400GB) and 90% of available RAM. This indicates quite an abundance of indexes for more performant reads. Based on benchmarks, backup and restore times are within acceptable SLAs and the cost to scale vertically is cheaper than the cost to scale horizontally. Based on the information provided, sharding is not appropriate in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e446e",
   "metadata": {},
   "source": [
    "### 問題04"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4e8ec8b",
   "metadata": {},
   "source": [
    "Which of the following is the most important factor in choosing a shard key?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4558d42",
   "metadata": {},
   "source": [
    "(O)1. knowledge of the read and write workloads of the application\n",
    "(X)2. knowledge of the approximate size of the collection to shard\n",
    "(X)3. shard key for which the different values and their frequency are known\n",
    "(X)4. using more than one field for the shard key\n",
    "(X)5. shard key that is not increasing/decreasing monotically"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a8e7fad",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct Answer:\n",
    "\n",
    "# knowledge of the read and write workloads of the application\n",
    "\n",
    "This is the most important criteria. There is often no perfect shard key, so compromises may be needed.\n",
    "\n",
    "If the workload is mostly writes, not using a monotonically increasing/decreasing shard key and distributing the writes is crucial.\n",
    "\n",
    "If the workload is mostly reads, you want to identify the most frequent queries, and ensure those get distributed and localized. The queries not using the shard key will be sent to all shards. Those non-targeted queries do not scale well, meaning adding a new shard is not helping, so we want to minimize those.\n",
    "\n",
    "Incorrect Answers:\n",
    "\n",
    "# knowledge of the approximate size of the collection to shard\n",
    "This will help you estimate the number of shards you may need, however not help you identify the shard key.\n",
    "\n",
    "# shard key that is not increasing/decreasing monotically\n",
    "This is true for a write intense workload, but may not be your priority in a read intense workload.\n",
    "\n",
    "# shard key for which the different values and their frequency are known\n",
    "You may not need to know the different values, however you need to have a ballpark number on the cardinality of the values for your shard key.\n",
    "\n",
    "# using more than one field for the shard key\n",
    "That helps increase the cardinality and reduce the frequency, however is is not mandatory. You may have a single field that already has good cardinality and frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987329d1",
   "metadata": {},
   "source": [
    "### 問題05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980383d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Having a good compound shard key on a collection:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7826e74f",
   "metadata": {},
   "source": [
    "(O)1. helps avoid potential un-splittable jumbo chunks\n",
    "(X)2. there will be fewer shards required for the collection\n",
    "(O)3. allows for even distribution of the collection"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e10a11b1",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Correct Answer\n",
    "\n",
    "# helps avoid potential un-splittable jumbo chunks\n",
    "\n",
    "In the case where a chunk's upper bound is equal to its lower bound, it can not be split, which hinders the benefits of horizontal scaling. Creating a compound key mitigates that, by adding an additional criteria for chunk upper an lower bounds. This allows chunks with identical value on one field to be split by the values of another field in the shard key.\n",
    "\n",
    "#　allows for even distribution of the collection\n",
    "\n",
    "Having a good compound shard key can only improve the collection distribution because it adds a parameter for the distribution criteria.\n",
    "\n",
    "Incorrect Answer\n",
    "\n",
    "# there will be fewer shards required for the collection\n",
    "\n",
    "This is incorrect, since your shard key does not determine the number of shards in your cluster, and that decision is made at an earlier step of the collection sharding process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f375795",
   "metadata": {},
   "source": [
    "### 問題06"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6baa4a1",
   "metadata": {},
   "source": [
    "Before sharding a collection, by running the sh.shardCollection command in the mongo shell, which operation is required?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acae2df1",
   "metadata": {},
   "source": [
    "(O)3. create an index on the shard key"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09246582",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "Before sharding a collection using sh.shardCollection command, the selected shard key needs to be supported by an index, therefore the correct answer is:\n",
    "\n",
    "# create an index on the shard key\n",
    "All other operations are not necessary, or desired, to enable sharding in a collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ecc551",
   "metadata": {},
   "source": [
    "### 問題07"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69300be6",
   "metadata": {},
   "source": [
    "At which point does the balancer decide to start moving chunks from one shard to another?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7fe4fcc",
   "metadata": {},
   "source": [
    "(O)1. zone sharding is used and some chunks are identified to be on the wrong shard\n",
    "(O)2. when some shards have too many chunks compared to others\n",
    "(O)3. there has been a request to drain a shard due to a removeShard command"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f30eed67",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "All of these scenarios trigger a chunk migration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f78777",
   "metadata": {},
   "source": [
    "### 問題08"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f367ef5f",
   "metadata": {},
   "source": [
    "What is sharding?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5b21904",
   "metadata": {},
   "source": [
    "(X)1. a method to ensure data availability\n",
    "(O)2. a method of distributing data across multiple machines\n",
    "(X)3. a way to vertically scale"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88ac636d",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "# a method to ensure data availability \n",
    "Is an incorrect answer. Replication is used to ensure data availability.\n",
    "\n",
    "# a way to vertically scale\n",
    "Is an incorrect answer. Sharding is a way to horizontally scale when vertical scaling becomes either too costly or you reach a data size where backups and restores will become unmanagable for a single replica set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702c751",
   "metadata": {},
   "source": [
    "### 問題09"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7aabd5f2",
   "metadata": {},
   "source": [
    "Given the following query:\n",
    "    \n",
    "db.movies.find({\"cast\": \"Meryl Streep\"}).sort({\"year\":1}).skip(100).limit(20)    \n",
    "\n",
    "And the following steps for executing such query in a sharded cluster:\n",
    "\n",
    "route - mongos send/route the query to the shards limit_by_shards - each shard limits to 100+20 docs on their partial result set limit_by_mongos - mongos limits to 20 docs skip_by_shards - each shard skips 100 docs on their partial result set skip_by_mongos - mongos skips of 100 docs sort_by_shards - each shard sorts their partial result set sort_by_mongos - mongos does a merge sort on the received documents\n",
    "\n",
    "\n",
    "Which of the following has the right steps, and in the right order?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcd8341a",
   "metadata": {},
   "source": [
    "(O)4. route, sort_by_shard, limit_by_shard, sort_by_mongos, skip_by_mongos, limit_by_mongos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d182553b",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "# route, sort_by_shard, limit_by_shard, sort_by_mongos, skip_by_mongos, limit_by_mongos\n",
    "\n",
    "Out of all the steps, the shards are not going to skip documents, because skipping the first X documents only make sense on the final result set.\n",
    "\n",
    "Remember the importance of having the shards responsible to sort their set, because they likely have an index to produce the ordered set. The mongos, a lighter process than the mongod, performs a merge sort, which is a rather inexpensive operation compare to a complete sort.\n",
    "\n",
    "The shards must limit to not only 20 documents, but also returned the potentially skipped documents. For this reason, they will limit to the sum of the limit() and skip() values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1add4",
   "metadata": {},
   "source": [
    "### 問題10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "817ef57b",
   "metadata": {},
   "source": [
    "When is it most beneficial to use a hashed shard key?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb2d69bf",
   "metadata": {},
   "source": [
    "(X)1. for geographically zoned sharding\n",
    "(O)2. for monotonically decreasing or increasing shard key values\n",
    "(X)3. for fast sorts using the shard key"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b249975",
   "metadata": {},
   "source": [
    "Detailed Answer\n",
    "\n",
    "# for a monotonically changing shard key\n",
    "All other answers are incorrect since a hashed shard key will not be able to support either geographically zoned sharding or fast sorts on the shard key."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
