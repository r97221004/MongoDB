{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection Pooling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this lesson we're going to cover connection pooling in MongoDB."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reusing database connections."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So what is connection pooling?\n",
    "\n",
    "If we look on Wikipedia, it says \"In software engineering, a connection pool is a cache of database connections maintained so that the connections can be reused when future requests to the database are required.\"\n",
    "\n",
    "What does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.amazonaws.com/edu-static.mongodb.com/lessons/M220/notebook_assets/replica_set_connection_pooling_three_connections.png\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Imagine you run a taxi service ferrying people to and from one point to another. But rather than reuse the same taxi after you transport one customer, you scrap that vehicle and go buy another.\n",
    "\n",
    "When issuing several different requests to the database, we could take the lazy approach and just create a new connection whenever we need to make a request, and when the request's done we just destroy the connection. The issue with this approach is that establishing a database connection requires time and computing resources, to complete the handshake with the server and whatnot. We're essentially paying the cost of waiting for this connection to establish for every request.\n",
    "\n",
    "Connection pooling helps reduce the overhead of creating database connections, by creating a whole bunch right off the bat. Then as requests come in, different connections in the pool are allocated to fulfill those requests.\n",
    "\n",
    "By default, drivers will establish a connection pool with 100 connections to share. So 100 connections will get created off the bat, and then get assigned to different requests as they come in. This default of 100 connections is adequate for most applications.\n",
    "\n",
    "Additionally, if we didn't use a connection pool and we suddently got a whole lot of requests, we might easily reach the limit that our hardware and software could handle, leading to a lot of errors and unhappy developers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Connection pools allow for reuse of connections\n",
    "# Subsequent requests appear faster to the client\n",
    "# Default size of 100\n",
    "\n",
    "So just to recap, connection pools allow connections to be quickly recycled for new requests for the database. To the developer, this will make database operations look faster, because the cost to create the new connection has already been paid, in a sense.\n",
    "\n",
    "And in Mongo drivers, the default connection pool is 100 connections large."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X Multiple database clients can share a connection pool.\n",
    "This is not true. Connection pools are specific to a database client, and the number of connections in the pool is declared when the client is initialized.\n",
    "\n",
    "X The connection pool will persist after the client is terminated.\n",
    "This is not true. All the connections in the pool are dropped when the client object is terminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Client Configuration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this lesson, we're going to discuss ways in which you can make your application's configuration more robust, with respect to how it talks to the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Always use Connection Pooling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You've learned about connection pooling already but it's important so we'll briefly cover it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.amazonaws.com/edu-static.mongodb.com/lessons/M220/notebook_assets/replica_set_connection_pooling_three_connections.png\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Creating a new MongoClient for every request to the database might service your application in the short term, but it will eventually result in the application consuming and depleting available resources that become more and more scarce over time.\n",
    "\n",
    "Connection pooling reduces the total overhead associated with creating a new connection, by allowing the application to recycle and reuse database connections for new requests.\n",
    "\n",
    "The M220 API that you've been given correctly reuses the same class or object for all client communication if you'd like to look at an example of how we did it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Always specify a wtimeout with majority writes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Another way to make a more robust database client is a write timeout, or wtimeout.\n",
    "\n",
    "No matter how well we engineer a system, we should always expect application external resources like queues, networks, and databases to take more time than expected. For application or consumer critical operations, a developer may choose to write with w: majority to ensure that acknowledged writes are written to a majority of replica set nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.amazonaws.com/edu-static.mongodb.com/lessons/M220/notebook_assets/replica_set_primary_secondary_highlighted_w_majority.png\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if there's a problem on the secondary nodes, we might not get acknowledgements back from the server for a while. If more writes than reads are coming into the system and operations aren't being acknowledged, this will eventually lead to system gridlock.\n",
    "\n",
    "To avoid this, follow a simple rule. For any write operation written with majority, always specify a write timeout. The specific length of the timeout will need to be determined based on your network and hardware, but you should always be setting timeouts on these (point) writes.\n",
    "\n",
    "{ w: \"majority\", wtimeout: 5000 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Always configure for and handle serverSelectionTimeout errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.amazonaws.com/edu-static.mongodb.com/lessons/M220/notebook_assets/world_map.png\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, you should always handle a server selection timeout error.\n",
    "\n",
    "This error will be thrown in the event a MongoDB server is unavailable for a write or for a read with a preference that the replica set can't currently fulfill. At the end of the day, MongoDB is a distributed database. So you should expect the system to be running on remote servers, along with all the benefits and constraints that it brings to your application logic.\n",
    "\n",
    "By default, the time before a driver will raise this error is 30 seconds, but you should change this to suit your application's needs. By handling this error you also passively monitor the health of your application stack and can become very quickly aware of any hardware and software problems that haven't recovered in an adequate amount of time.\n",
    "\n",
    "Each driver and programming language has a specific way to deal with errors, and we handle this error in particular in Mflix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Always use connection pooling\n",
    "# Always specify a wtimeout with majority writes\n",
    "# Always handle serverSelectionTimeout errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writes with Error Handling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "At this point we've gotten pretty comfortable writing data to Mongo, creating and updating with different durabilities. We've even configured the driver to change the way our writes are perceived. But there are still times when the writes we send to the server will result in an error, and we've briefly discussed the way our application can deal with these errors.\n",
    "\n",
    "In this lesson we're gonna encounter some of the basic errors in the Pymongo driver, and how to handle these errors in a way that makes our application more consistent and reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, errors\n",
    "uri = \"mongodb+srv://m220student:m220password@mflix.rncav.mongodb.net/test\"\n",
    "mc = MongoClient(uri)\n",
    "lessons = mc.lessons\n",
    "shipments = lessons.shipments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here's a URI string connecting to our Atlas cluster, and I've initialized a client with that string.\n",
    "\n",
    "We're using a new collection called shipments, and the scenario for this lesson is that our application is a clothing manufacturer that also handles the shipping for their clothing items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "shipments.drop()\n",
    "\n",
    "cities = [ \"Atlanta\", \"New York\", \"Miami\", \"Chicago\", \"Los Angeles\", \"Seattle\", \"Dallas\" ]\n",
    "products = [ \"shoes\", \"pants\", \"shirts\", \"hats\", \"socks\" ]\n",
    "quantities = [ 10, 20, 40, 80, 160, 320, 640, 1280, 2560 ]\n",
    "docs = []\n",
    "\n",
    "for truck_id in range(30):\n",
    "    source = random.choice(cities)\n",
    "    destination = random.choice([c for c in cities if c != source])\n",
    "    product = random.choice(products)\n",
    "    quantity = random.choice(quantities)\n",
    "    \n",
    "    doc = {\n",
    "        \"truck_id\": truck_id,\n",
    "        \"source\": source,\n",
    "        \"destination\": destination,\n",
    "        \"product\": product,\n",
    "        \"quantity\": quantity\n",
    "    }\n",
    "    \n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_response = shipments.insert_many(docs)\n",
    "shipments.count_documents({})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is a short script that's gonna create some test data for the clothing manufacturer. This is included in this notebook so you can test it out yourself.\n",
    "\n",
    "You can see the documents we're producing have 5 fields each, with this truck_id determined by the iteration of our loop (point to truck_id). The (point) source and destination are both derived from this cities array, and this (point to destination) part will make sure that the destination city is different from the source.\n",
    "\n",
    "Each shipment also has a product and a quantity, but the part we're gonna focus on is this (point) truck_id field. This is gonna record the truck currently allocated for this shipment, so that truck can be considered unavailable for any another shipments. This way when a new shipment comes in, we can make sure the truck that gets assigned to that shipment isn't already doing another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6274a2b8af11371d14f95e44'),\n",
       " 'truck_id': 0,\n",
       " 'source': 'Atlanta',\n",
       " 'destination': 'Miami',\n",
       " 'product': 'pants',\n",
       " 'quantity': 2560}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shipments.find_one()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Right now this loop only has 30 iterations (point to the loop) so we have exactly 30 documents in the shipments collection. If we take a look at one of them...\n",
    "\n",
    "(run command)\n",
    "\n",
    "Then we can see that they each have these five fields. The assumption I'm making for this data is that, while this (point) document exists in the collection, the shipment is still ongoing. When this shipment is complete, we would delete this document, or maybe add a flag to the document like { completed: True }.\n",
    "\n",
    "This means that 30 documents in the shipments collection means 30 shipments that are happening right now. And if we tried to insert a new shipment, it has to have a unique truck_id (point). This way each truck is only assigned to one shipment at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truck_id_1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shipments.create_index(\"truck_id\", unique=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So this is the way we're gonna enforce uniqueness among these truck_ids. This is called a unique index, which will create an index on the truck_id field, and also make sure that there are no duplicate truck_ids.\n",
    "\n",
    "(enter command)\n",
    "\n",
    "And it created this index called truck_id_1, the 1 meaning that the index is sorted in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truck #4 is currently performing a shipment. Please select another truck.\n"
     ]
    }
   ],
   "source": [
    "doc = {\n",
    "    \"source\": \"New York\",\n",
    "    \"destination\": \"Atlanta\",\n",
    "    \"truck_id\": 4,\n",
    "    \"product\": \"socks\",\n",
    "    \"quantity\": 40\n",
    "}\n",
    "\n",
    "try:\n",
    "    res = shipments.insert_one(doc)\n",
    "    print(res.inserted_id)\n",
    "except errors.DuplicateKeyError:\n",
    "    truck_id = doc[\"truck_id\"]\n",
    "    print(f\"Truck #{truck_id} is currently performing a shipment. Please select another truck.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here's an example of a shipment being added to our collection. We want to ship 40 socks from New York to Atlanta, and we've chosen to assign truck 4 to perform this shipment. This (point) truck number could have been user input, or something determined by our application, but either way this is going to cause a DuplicateKeyError because we already have a shipment assigned to truck (point) 4.\n",
    "\n",
    "(enter command)\n",
    "\n",
    "So using the try-except block, our program prints out a message when a DuplicateKeyError is thrown. The message tells us that the truck we wanted to use has already been sent out. So the application allows the insert to fail, and then sends an error message up to the user to choose another truck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "trucks = lessons.trucks\n",
    "trucks.drop()\n",
    "\n",
    "trucks.insert_many([\n",
    "    { \"_id\": i, \"license\": \"\".join(random.choice(string.ascii_uppercase + string.digits) for _ in range(7)) } for i in range(50)\n",
    "])\n",
    "trucks.count_documents({})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "But we can actually be a little more proactive in handling this error, if we know about the other trucks who are available for this job.\n",
    "\n",
    "Here's a new collection called trucks, which we're gonna use to find another available truck. This should insert exactly 50 documents into this collection...\n",
    "\n",
    "(enter command)\n",
    "\n",
    "And it looks like it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 0, 'license': '1IQ1VC2'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trucks.find_one()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The documents each only have two fields: an _id from 0 to 49 (point), which will relate to the truck_id from the shipments collection. And I've assigned a random string of 7 uppercase letters and numbers to be the license plate number, although actually some US states only allow 6 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truck #4 is currently performing a shipment. Truck #48 has been sent out instead.\n"
     ]
    }
   ],
   "source": [
    "doc = {\n",
    "    \"source\": \"New York\",\n",
    "    \"destination\": \"Atlanta\",\n",
    "    \"truck_id\": 4,\n",
    "    \"product\": \"socks\",\n",
    "    \"quantity\": 40\n",
    "}\n",
    "\n",
    "try:\n",
    "    res = shipments.insert_one(doc)\n",
    "    print(res.inserted_id)\n",
    "except errors.DuplicateKeyError:\n",
    "    busy_trucks = set(shipments.distinct(\"truck_id\"))\n",
    "    all_trucks = set(trucks.distinct(\"_id\"))\n",
    "    available_trucks = all_trucks.difference(busy_trucks)\n",
    "    old_truck_id = doc[\"truck_id\"]\n",
    "    if available_trucks:\n",
    "        chosen_truck = random.choice(list(available_trucks))\n",
    "        new_truck_id = doc[\"truck_id\"] = chosen_truck\n",
    "        res = shipments.insert_one(doc)\n",
    "        print(f\"Truck #{old_truck_id} is currently performing a shipment. Truck #{new_truck_id} has been sent out instead.\")\n",
    "    else:\n",
    "        print(f\"Truck #{old_truck_id} is currently performing a shipment. Could not find another truck.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So the error handling now is a little more proactive.\n",
    "\n",
    "Instead of just surfacing an error to the user, the application actually chooses a new truck, sends out that truck, and then alerted the user that the action was performed, just by a different vehicle.\n",
    "\n",
    "(enter command)\n",
    "\n",
    "In this case we tried to send truck number 4 out, but it wasn't available. So we decided to try sending another truck.\n",
    "\n",
    "But this time we were a little more careful. We performed a couple queries to figure out all the vehicles that are available for this shipment.\n",
    "\n",
    "We pulled the truck_ids from all the trucks into a set, and then pulled all the truck_ids from shipments into a set, and then took the difference to figure out which truck_ids were not already out on a shipment.\n",
    "\n",
    "This check, to see which trucks are available, is actually somewhat expensive as these two distinct() queries require two database round trips. Because of this, the application takes a pretty lazy approach here assigning trucks to shipments, and doesn't do any round trips until the truck it tries to send out comes up unavailable.\n",
    "\n",
    "This might be suitable if the collisions won't occur very often. Which is to say, trucks are usually available when we request them. But on the rare occasions they are not available, we do a little extra work, and then send out a truck that we KNOW, with some certainty, will be available."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DuplicateKeyError can occur on _id as well as fields in unique indexes\n",
    "# When handling errors, determine how fatal the error is\n",
    "  - Should this error be returned to the user?\n",
    "  - Can we react to this error in a useful way?\n",
    "  \n",
    "So in this lesson we demonstrated how to handle a specific DuplicateKeyError, and it's important to remember that this error usually occurs on _id, which is unique by default. But it also pertains to fields contained in a unique index, like the index we had on truck_id.\n",
    "\n",
    "Really when handling these errors we want to think about how much we can do after receiving the error. If there's nothing we can do in response, if this error is truly fatal, we should just return it to the user.\n",
    "\n",
    "But if we can do something, as was the case with the shipments collection, we should try to handle the error in a more flexible way. In the example, the error was that the truck we tried to reserve was already in use. But at that time, the program actually had the resources to determine which trucks were still available, so it sent one of those trucks out instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle of Least Privilege"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "> Every program and every privileged user of the system should operate using the least amount of privilege necessary to complete the job. > > — Jerome Saltzer, Communications of the ACM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this lesson we're going to talk about the Principle of Least Privilege."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.amazonaws.com/edu-static.mongodb.com/lessons/M220/notebook_assets/polp.png\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Security is a multi-tiered effort.\n",
    "\n",
    "Atlas ensures the traffic being transmitted from the application to the database is encrypted in transit. We also make sure to hash mflix user passwords before storing them in the database.\n",
    "\n",
    "At the appication layer, we make sure that certain resources are only available to logged in users, and those users have permissions to perform an action, such as deleting only their own comments.\n",
    "\n",
    "But why stop there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![noun_lock](https://s3.amazonaws.com/edu-static.mongodb.com/lessons/M220/notebook_assets/noun_lock.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MongoDB offers robust user management at the database level, and we should use it. And since we are using Atlas, this is made even easier because of the graphical interface.\n",
    "\n",
    "By creating a database user specifically for the application, we can, in a more granular way, select the privileges and resources MFlix has access to.\n",
    "\n",
    "Should the application have the ability to create indexes, new collections, or drop the entire database?\n",
    "\n",
    "Questions like these aren't always fun to ask and answer, but they are absolutely necessary.\n",
    "\n",
    "That's all for now. We highly recommend that you take our MongoDB Security course to learn more to help secure and harden your own MongoDB deployments."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Engineer systems with the principle of least privilege in mind\n",
    "Consider what kinds of users and what permission they will have.\n",
    "  - Application users that log into the application itself\n",
    "  - Database users\n",
    "       Administrative database users that can create indexes, import data, and so on\n",
    "       Application database users that only have priveleges they require."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Streams"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this lesson, we're going to use change streams to track real-time changes to the data that our application's using.\n",
    "\n",
    " - Report changes at the collection level\n",
    " - Accept pipelines to transform change events"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As of MongoDB 3.6, change streams report changes at the collection level, so we open a change stream against a specific collection.\n",
    "\n",
    "But by default it will return any change to the data in that collection regardless of what it is, so we can also pass a pipeline to transform the change events we get back from the stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, errors\n",
    "uri = \"mongodb+srv://m220student:m220password@mflix.rncav.mongodb.net/test\"\n",
    "client = MongoClient(uri)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So here I'm just initializing my MongoClient object,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('6274db9baf11371d14f95e65'),\n",
       "  'type': 'strawberries',\n",
       "  'quantity': 100},\n",
       " {'_id': ObjectId('6274db9baf11371d14f95e66'),\n",
       "  'type': 'bananas',\n",
       "  'quantity': 100},\n",
       " {'_id': ObjectId('6274db9baf11371d14f95e67'),\n",
       "  'type': 'apples',\n",
       "  'quantity': 100}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lessons = client.lessons\n",
    "inventory = lessons.inventory\n",
    "inventory.drop()\n",
    "\n",
    "fruits = [ \"strawberries\", \"bananas\", \"apples\" ]\n",
    "for fruit in fruits:\n",
    "    inventory.insert_one( { \"type\": fruit, \"quantity\": 100 } )\n",
    "    \n",
    "list(inventory.find())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "And I'm using a new collection for this lesson, inventory. If you imagine we have a store that sells fruits, this collection will store the total quanities of every fruit that we have in stock.\n",
    "\n",
    "In this case, we have a very small store that only sells three types of fruits, and I've just updated the inventory to reflect that we just got a shipment for 100 of each fruit.\n",
    "\n",
    "Now I'm just going to verify that our collection looks the way we expect.\n",
    "\n",
    "(run cell)\n",
    "\n",
    "And it looks like we have 100 of each fruit in the collection.\n",
    "\n",
    "But people will start buying them, cause you know, people like fruit. They'll go pretty quickly, and we want to make sure we don't run out. So I'm going to open a change stream against this collection, and track data changes to the inventory collection in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': {'_data': '826274DD9F000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826079, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 99}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 99}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDA0000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826080, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 98}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 98}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDA1000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826081, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 94}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 94}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDA2000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826082, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 91}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 91}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDA3000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826083, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 92}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 92}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDA5000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826085, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 93}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 93}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDA6000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826086, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 87}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 87}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDA7000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826087, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 91}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 91}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDA8000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826088, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 86}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 86}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDA9000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826089, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 83}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 83}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDAA000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826090, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 85}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 85}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDAB000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826091, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 82}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 82}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDAC000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826092, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 74}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 74}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDAD000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826093, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 85}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 85}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDAE000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826094, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 84}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 84}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDB0000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826096, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 83}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 83}, 'removedFields': [], 'truncatedArrays': []}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': {'_data': '826274DDB1000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826097, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 83}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 83}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDB2000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826098, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 82}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 82}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDB3000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826099, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 72}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 72}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDB4000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826100, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 80}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 80}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDB5000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826101, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 81}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 81}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDB6000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826102, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 64}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 64}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDB7000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826103, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 63}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 63}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDB8000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826104, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 72}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 72}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDB9000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826105, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 68}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 68}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDBA000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826106, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 79}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 79}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDBB000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826107, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 77}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 77}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDBD000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826109, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 73}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 73}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDBE000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826110, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 55}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 55}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDBF000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826111, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 65}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 65}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDC0000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826112, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 60}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 60}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDC1000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826113, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 54}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 54}, 'removedFields': [], 'truncatedArrays': []}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': {'_data': '826274DDC2000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826114, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 59}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 59}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDC3000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826115, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 55}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 55}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDC4000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826116, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 61}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 61}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDC5000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826117, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 53}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 53}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDC6000000122B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826118, 18), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 45}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 45}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDC7000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826119, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 46}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 46}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDC9000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826121, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 37}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 37}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDCA000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826122, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 47}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 47}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDCB000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826123, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 38}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 38}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDCC000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826124, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 43}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 43}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDCD000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826125, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 39}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 39}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDCE000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826126, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 37}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 37}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDCF000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826127, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 35}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 35}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDD0000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826128, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 35}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 35}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDD1000000022B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E670004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826129, 2), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e67'), 'type': 'apples', 'quantity': 31}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e67')}, 'updateDescription': {'updatedFields': {'quantity': 31}, 'removedFields': [], 'truncatedArrays': []}}\n",
      "{'_id': {'_data': '826274DDD2000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E660004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826130, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e66'), 'type': 'bananas', 'quantity': 29}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e66')}, 'updateDescription': {'updatedFields': {'quantity': 29}, 'removedFields': [], 'truncatedArrays': []}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': {'_data': '826274DDD3000000012B022C0100296E5A100472E17B54E28F4701BB8D81CB07547A4646645F696400646274DB9BAF11371D14F95E650004'}, 'operationType': 'update', 'clusterTime': Timestamp(1651826131, 1), 'fullDocument': {'_id': ObjectId('6274db9baf11371d14f95e65'), 'type': 'strawberries', 'quantity': 27}, 'ns': {'db': 'lessons', 'coll': 'inventory'}, 'documentKey': {'_id': ObjectId('6274db9baf11371d14f95e65')}, 'updateDescription': {'updatedFields': {'quantity': 27}, 'removedFields': [], 'truncatedArrays': []}}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pymongo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ba80c9215a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0minventory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_document\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'updateLookup'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mchange_stream_cursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata_change\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchange_stream_cursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_change\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\change_stream.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                 \u001b[0mchange\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionFailure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\command_cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__killed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\command_cursor.py\u001b[0m in \u001b[0;36m_refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m                                     self.__max_await_time_ms))\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Cursor id is zero nothing else to return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\command_cursor.py\u001b[0m in \u001b[0;36m__send_message\u001b[1;34m(self, operation)\u001b[0m\n\u001b[0;32m    137\u001b[0m             response = client._send_message_with_response(\n\u001b[1;32m--> 138\u001b[1;33m                 operation, address=self.__address)\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAutoReconnect\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_send_message_with_response\u001b[1;34m(self, operation, exhaust, address)\u001b[0m\n\u001b[0;32m   1144\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_listeners\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m             exhaust)\n\u001b[0m\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_reset_on_error\u001b[1;34m(self, server, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mNetworkTimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\server.py\u001b[0m in \u001b[0;36msend_message_with_response\u001b[1;34m(self, operation, set_slave_okay, all_credentials, listeners, exhaust)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0msock_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_doc_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m                 \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreceive_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36mreceive_message\u001b[1;34m(self, request_id)\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_connection_failure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36m_raise_connection_failure\u001b[1;34m(self, error)\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36mreceive_message\u001b[1;34m(self, request_id)\u001b[0m\n\u001b[0;32m    609\u001b[0m             return receive_message(self.sock, request_id,\n\u001b[1;32m--> 610\u001b[1;33m                                    self.max_message_size)\n\u001b[0m\u001b[0;32m    611\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\network.py\u001b[0m in \u001b[0;36mreceive_message\u001b[1;34m(sock, request_id, max_message_size)\u001b[0m\n\u001b[0;32m    172\u001b[0m     length, _, response_to, op_code = _UNPACK_HEADER(\n\u001b[1;32m--> 173\u001b[1;33m         _receive_data_on_socket(sock, 16))\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;31m# No request_id for exhaust cursor \"getMore\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\network.py\u001b[0m in \u001b[0;36m_receive_data_on_socket\u001b[1;34m(sock, length)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 \u001b[0mchunk_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbytes_read\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1011\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1012\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    873\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ba80c9215a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata_change\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchange_stream_cursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_change\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mexcept\u001b[0m \u001b[0mpymongo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyMongoError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Change stream closed because of an error.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pymongo' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with inventory.watch(full_document='updateLookup') as change_stream_cursor:\n",
    "        for data_change in change_stream_cursor:\n",
    "            print(data_change)\n",
    "except pymongo.errors.PyMongoError:\n",
    "    print('Change stream closed because of an error.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So here I'm opening a change stream against the inventory (point) collection, using the watch() method. watch() (point) returns a cursor object, so we can iterate through it in Python to return whatever document is next in the cursor.\n",
    "\n",
    "We've wrapped this in a try-catch block so if something happens to the connection used for the change stream, we'll know immediately.\n",
    "\n",
    "(start the while loop)\n",
    "\n",
    "(go to updates_every_one_second notebook and start up process)\n",
    "\n",
    "(come back here)\n",
    "\n",
    "So the change stream cursor is just gonna spit out anything it gets, with no filter. Any change to the data in the inventory collection will appear in this output.\n",
    "\n",
    "But really, this is noise. We don't care when the quantity drops to 71 (point) or 60 (point), we only want to know when it's close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are only 19 units left of bananas!\n",
      "There are only 11 units left of bananas!\n",
      "There are only 3 units left of bananas!\n",
      "There are only 17 units left of apples!\n",
      "There are only 15 units left of apples!\n",
      "There are only 11 units left of apples!\n",
      "There are only 10 units left of apples!\n",
      "There are only 18 units left of strawberries!\n",
      "There are only 14 units left of strawberries!\n",
      "There are only 10 units left of strawberries!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pymongo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4b354f44acbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0minventory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlow_quantity_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_document\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'updateLookup'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mchange_stream_cursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata_change\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchange_stream_cursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[0mcurrent_quantity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_change\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fullDocument\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"quantity\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\change_stream.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                 \u001b[0mchange\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionFailure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\command_cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__killed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\command_cursor.py\u001b[0m in \u001b[0;36m_refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m                                     self.__max_await_time_ms))\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Cursor id is zero nothing else to return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\command_cursor.py\u001b[0m in \u001b[0;36m__send_message\u001b[1;34m(self, operation)\u001b[0m\n\u001b[0;32m    137\u001b[0m             response = client._send_message_with_response(\n\u001b[1;32m--> 138\u001b[1;33m                 operation, address=self.__address)\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAutoReconnect\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_send_message_with_response\u001b[1;34m(self, operation, exhaust, address)\u001b[0m\n\u001b[0;32m   1144\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_listeners\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m             exhaust)\n\u001b[0m\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_reset_on_error\u001b[1;34m(self, server, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mNetworkTimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\server.py\u001b[0m in \u001b[0;36msend_message_with_response\u001b[1;34m(self, operation, set_slave_okay, all_credentials, listeners, exhaust)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0msock_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_doc_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m                 \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreceive_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36mreceive_message\u001b[1;34m(self, request_id)\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_connection_failure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36m_raise_connection_failure\u001b[1;34m(self, error)\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36mreceive_message\u001b[1;34m(self, request_id)\u001b[0m\n\u001b[0;32m    609\u001b[0m             return receive_message(self.sock, request_id,\n\u001b[1;32m--> 610\u001b[1;33m                                    self.max_message_size)\n\u001b[0m\u001b[0;32m    611\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\network.py\u001b[0m in \u001b[0;36mreceive_message\u001b[1;34m(sock, request_id, max_message_size)\u001b[0m\n\u001b[0;32m    172\u001b[0m     length, _, response_to, op_code = _UNPACK_HEADER(\n\u001b[1;32m--> 173\u001b[1;33m         _receive_data_on_socket(sock, 16))\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;31m# No request_id for exhaust cursor \"getMore\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pymongo\\network.py\u001b[0m in \u001b[0;36m_receive_data_on_socket\u001b[1;34m(sock, length)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 \u001b[0mchunk_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbytes_read\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1011\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1012\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    873\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4b354f44acbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"There are only {0} units left of {1}!\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_quantity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfruit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mexcept\u001b[0m \u001b[0mpymongo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyMongoError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Change stream closed because of an error.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pymongo' is not defined"
     ]
    }
   ],
   "source": [
    "low_quantity_pipeline = [ { \"$match\": { \"fullDocument.quantity\": { \"$lt\": 20 } } } ]\n",
    "\n",
    "try:\n",
    "    with inventory.watch(pipeline=low_quantity_pipeline, full_document='updateLookup') as change_stream_cursor:\n",
    "        for data_change in change_stream_cursor:\n",
    "            current_quantity = data_change[\"fullDocument\"].get(\"quantity\")\n",
    "            fruit = data_change[\"fullDocument\"].get(\"type\")\n",
    "            msg = \"There are only {0} units left of {1}!\".format(current_quantity, fruit)\n",
    "            print(msg)\n",
    "except pymongo.errors.PyMongoError:\n",
    "    logging.error('Change stream closed because of an error.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's say we want to know if any of our quantities (point to quantity values) dip below 20 units, so we know when to buy more.\n",
    "\n",
    "Here I've defined a pipeline for the change event documents returned by the cursor. In this case, if the cursor returns a change event to me, it's because that event caused one of our quantities to fall below 10 units.\n",
    "\n",
    "(open the change stream)\n",
    "\n",
    "(go to updates_every_one_second and start the third cell)\n",
    "\n",
    "(come back here)\n",
    "\n",
    "So if we just wait for the customers to go about their business...\n",
    "\n",
    "(wait for a print statement)\n",
    "\n",
    "And now we know that we need to buy more strawberries!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Change streams can be opened against a collection\n",
    "  - Tracks data changes in real time\n",
    "# Aggregation pipelines can be used to transform change event documents\n",
    "\n",
    "So change streams are a great way to track changes to the data in a collection. And if you're using Mongo 4.0, you can open a change stream against a whole database, and even a whole cluster.\n",
    "\n",
    "We also have the flexibility to pass an aggregation pipeline to the change stream, to transform or filter out some of the change event documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
